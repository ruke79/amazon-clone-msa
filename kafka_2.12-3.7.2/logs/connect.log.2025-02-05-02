[2025-02-05 02:12:26,297] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-02-05 02:12:26,302] INFO WorkerInfo values: 
	jvm.args = -Xmx256M, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2/logs, -Dlog4j.configuration=file:E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2/config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 17.0.10, 17.0.10+11-LTS-240
	jvm.classpath = E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\activation-1.1.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\aopalliance-repackaged-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\argparse4j-0.7.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\audience-annotations-0.12.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\caffeine-2.9.3.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\checker-qual-3.19.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-beanutils-1.9.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-cli-1.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-collections-3.2.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-digester-2.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-io-2.14.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-lang3-3.8.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-logging-1.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-validator-1.7.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-api-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-basic-auth-extension-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-file-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-json-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-mirror-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-mirror-client-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-runtime-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-transforms-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\error_prone_annotations-2.10.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-api-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-locator-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-utils-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-annotations-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-core-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-databind-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-dataformat-csv-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-datatype-jdk8-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-jaxrs-base-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-jaxrs-json-provider-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-module-jaxb-annotations-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-module-scala_2.12-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.activation-api-1.2.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.annotation-api-1.3.5.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.inject-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.validation-api-2.0.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.ws.rs-api-2.1.6.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.xml.bind-api-2.3.3.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javassist-3.29.2-GA.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.activation-api-1.2.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.annotation-api-1.3.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.servlet-api-3.1.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.ws.rs-api-2.1.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jaxb-api-2.3.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-client-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-common-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-container-servlet-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-container-servlet-core-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-hk2-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-server-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-client-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-continuation-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-http-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-io-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-security-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-server-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-servlet-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-servlets-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-util-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-util-ajax-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jline-3.25.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jopt-simple-5.0.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jose4j-0.9.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jsr305-3.0.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-clients-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-group-coordinator-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-log4j-appender-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-metadata-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-raft-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-server-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-server-common-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-shell-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-storage-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-storage-api-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-examples-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-scala_2.12-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-test-utils-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-tools-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-tools-api-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka_2.12-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\lz4-java-1.8.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\maven-artifact-3.8.8.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\metrics-core-2.2.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\metrics-core-4.1.12.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-buffer-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-codec-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-common-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-handler-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-resolver-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-classes-epoll-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-native-epoll-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-native-unix-common-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\opentelemetry-proto-1.0.0-alpha.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\osgi-resource-locator-1.0.3.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\paranamer-2.8.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\pcollections-4.0.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\plexus-utils-3.3.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\protobuf-java-3.25.5.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\reflections-0.10.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\reload4j-1.2.25.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\rocksdbjni-7.9.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-collection-compat_2.12-2.10.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-java8-compat_2.12-1.0.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-library-2.12.18.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-logging_2.12-3.9.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-reflect-2.12.18.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\slf4j-api-1.7.36.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\slf4j-reload4j-1.7.36.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\snappy-java-1.1.10.5.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\swagger-annotations-2.2.8.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\trogdor-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zookeeper-3.8.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zookeeper-jute-3.8.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zstd-jni-1.5.6-4.jar;
	os.spec = Windows 11, amd64, 10.0
	os.vcpus = 12
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-02-05 02:12:26,307] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-02-05 02:12:26,345] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\bin (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:12:26,536] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/bin/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:12:26,538] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\config (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:12:26,545] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/config/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:12:26,545] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:12:26,557] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:12:26,558] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:12:26,711] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:12:26,712] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\licenses (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:12:26,718] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/licenses/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:12:26,718] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\logs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:12:26,724] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/logs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:12:26,725] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\site-docs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:12:26,732] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/site-docs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:12:26,733] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:12:26,739] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@2b193f2d (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:12:26,740] INFO Scanning plugins with ServiceLoaderScanner took 397 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-02-05 02:12:26,741] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\bin (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:12:26,761] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/bin/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:12:26,763] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\config (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:12:26,765] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/config/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:12:26,766] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:12:27,018] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:12:27,019] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:12:28,315] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:12:28,317] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\licenses (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:12:28,320] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/licenses/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:12:28,320] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\logs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:12:28,322] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/logs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:12:28,323] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\site-docs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:12:28,325] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/site-docs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:12:28,326] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:12:29,016] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@2b193f2d (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:12:29,016] INFO Scanning plugins with ReflectionScanner took 2275 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-02-05 02:12:29,028] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/	com.mongodb.kafka.connect.MongoSinkConnector	sink	1.11.0
file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/	com.mongodb.kafka.connect.MongoSourceConnector	source	1.11.0
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-02-05 02:12:29,031] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,031] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,031] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,031] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,033] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,033] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,033] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,034] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,034] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,034] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,034] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,035] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,035] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,035] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,035] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,036] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,036] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,036] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,036] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,036] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,037] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,037] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,037] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,037] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,038] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,038] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,038] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,039] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,039] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,039] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,039] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,040] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,040] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,040] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,040] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,041] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,041] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,041] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,041] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,041] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,041] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,041] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,042] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,042] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,042] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,042] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,043] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,043] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,043] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,043] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,043] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,043] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,045] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:12:29,047] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,047] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,048] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,048] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,049] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,049] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,050] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,050] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,050] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,051] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,051] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,051] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,052] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,052] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,052] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,053] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,053] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,054] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,054] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,054] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,055] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,055] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,055] INFO Added alias 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,056] INFO Added alias 'MongoSinkConnector' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,056] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,056] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,057] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,057] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,057] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,058] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,058] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,058] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,059] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,059] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,059] INFO Added alias 'MongoSourceConnector' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,060] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,060] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,061] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,061] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,062] INFO Added alias 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,062] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,062] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,063] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,063] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,064] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,064] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,064] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,065] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,065] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,065] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,066] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,066] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,066] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,066] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,066] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,068] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:12:29,116] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-02-05 02:12:29,126] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-02-05 02:12:29,129] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-02-05 02:12:29,218] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-02-05 02:12:29,219] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:12:29,219] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:12:29,219] INFO Kafka startTimeMs: 1738689149219 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:12:29,525] INFO Kafka cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-02-05 02:12:29,526] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-05 02:12:29,533] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-05 02:12:29,535] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:12:29,535] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-05 02:12:29,539] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-02-05 02:12:29,553] INFO Logging initialized @3790ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-02-05 02:12:29,592] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-02-05 02:12:29,593] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-02-05 02:12:29,614] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 17.0.10+11-LTS-240 (org.eclipse.jetty.server.Server:375)
[2025-02-05 02:12:29,645] INFO Started http_8083@2148b47e{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-02-05 02:12:29,645] INFO Started @3881ms (org.eclipse.jetty.server.Server:415)
[2025-02-05 02:12:29,667] INFO Advertised URI: http://192.168.231.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-05 02:12:29,667] INFO REST server listening at http://192.168.231.1:8083/, advertising URL http://192.168.231.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-02-05 02:12:29,668] INFO Advertised URI: http://192.168.231.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-05 02:12:29,668] INFO REST admin endpoints at http://192.168.231.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-02-05 02:12:29,669] INFO Advertised URI: http://192.168.231.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-05 02:12:29,670] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-02-05 02:12:29,674] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-02-05 02:12:29,690] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:12:29,691] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:12:29,691] INFO Kafka startTimeMs: 1738689149690 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:12:29,697] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-02-05 02:12:29,699] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-02-05 02:12:29,718] INFO Advertised URI: http://192.168.231.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-05 02:12:29,750] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:12:29,750] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:12:29,751] INFO Kafka startTimeMs: 1738689149750 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:12:29,754] INFO Kafka Connect worker initialization took 3454ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-02-05 02:12:29,754] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-02-05 02:12:29,756] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-02-05 02:12:29,756] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:369)
[2025-02-05 02:12:29,758] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:231)
[2025-02-05 02:12:29,758] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:240)
[2025-02-05 02:12:29,759] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-02-05 02:12:29,760] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-02-05 02:12:29,773] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-02-05 02:12:29,773] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:12:29,774] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:12:29,774] INFO Kafka startTimeMs: 1738689149773 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:12:29,796] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-02-05 02:12:29,838] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-02-05 02:12:29,839] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-02-05 02:12:29,840] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2025-02-05 02:12:30,300] INFO Started o.e.j.s.ServletContextHandler@3ba815ee{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-02-05 02:12:30,300] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-02-05 02:12:30,301] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-02-05 02:12:30,644] INFO Created topic (name=connect-offsets, numPartitions=25, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:9092 (org.apache.kafka.connect.util.TopicAdmin:445)
[2025-02-05 02:12:30,651] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-02-05 02:12:30,675] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-05 02:12:30,696] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-02-05 02:12:30,697] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:12:30,698] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:12:30,698] INFO Kafka startTimeMs: 1738689150697 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:12:30,706] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-05 02:12:30,708] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.clients.Metadata:356)
[2025-02-05 02:12:30,726] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-05 02:12:30,759] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-05 02:12:30,759] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:12:30,760] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:12:30,760] INFO Kafka startTimeMs: 1738689150759 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:12:30,771] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.clients.Metadata:356)
[2025-02-05 02:12:30,782] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-02-05 02:12:30,787] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,788] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,788] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,788] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,789] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,789] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,789] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,790] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,790] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,790] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,790] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,792] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,792] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,792] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,792] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,793] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,793] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,793] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,794] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,794] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,794] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,796] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:30,853] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,854] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,855] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,855] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,857] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,857] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,858] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,858] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,859] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,859] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,860] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,860] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,860] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,860] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,861] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,862] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,862] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,862] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,863] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,863] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,864] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,865] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,865] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,865] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,866] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:30,867] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-02-05 02:12:30,868] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-02-05 02:12:30,868] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:257)
[2025-02-05 02:12:30,869] INFO Worker started (org.apache.kafka.connect.runtime.Worker:241)
[2025-02-05 02:12:30,869] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-02-05 02:12:31,056] INFO Created topic (name=connect-status, numPartitions=5, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:9092 (org.apache.kafka.connect.util.TopicAdmin:445)
[2025-02-05 02:12:31,057] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-02-05 02:12:31,061] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-05 02:12:31,067] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-02-05 02:12:31,068] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:12:31,068] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:12:31,068] INFO Kafka startTimeMs: 1738689151068 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:12:31,069] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-05 02:12:31,073] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.clients.Metadata:356)
[2025-02-05 02:12:31,075] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-05 02:12:31,083] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-05 02:12:31,083] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:12:31,084] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:12:31,084] INFO Kafka startTimeMs: 1738689151083 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:12:31,089] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.clients.Metadata:356)
[2025-02-05 02:12:31,090] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-02-05 02:12:31,090] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:31,091] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:31,091] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:31,091] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:31,091] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:31,103] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:31,103] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:31,104] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:31,104] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:31,105] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:31,105] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-02-05 02:12:31,106] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-02-05 02:12:31,109] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:379)
[2025-02-05 02:12:31,109] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-02-05 02:12:31,181] INFO Created topic (name=connect-configs, numPartitions=1, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:9092 (org.apache.kafka.connect.util.TopicAdmin:445)
[2025-02-05 02:12:31,183] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-02-05 02:12:31,189] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-05 02:12:31,194] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-02-05 02:12:31,194] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:12:31,195] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:12:31,195] INFO Kafka startTimeMs: 1738689151194 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:12:31,197] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-05 02:12:31,200] INFO [Producer clientId=connect-cluster-configs] Cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.clients.Metadata:356)
[2025-02-05 02:12:31,204] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-05 02:12:31,210] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-05 02:12:31,210] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:12:31,210] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:12:31,210] INFO Kafka startTimeMs: 1738689151210 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:12:31,222] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.clients.Metadata:356)
[2025-02-05 02:12:31,238] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-02-05 02:12:31,239] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:12:31,259] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:12:31,260] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-02-05 02:12:31,260] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-02-05 02:12:31,260] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:403)
[2025-02-05 02:12:31,260] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:376)
[2025-02-05 02:12:31,276] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.clients.Metadata:356)
[2025-02-05 02:12:32,685] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Discovered group coordinator DESKTOP-EJEJQKM:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-02-05 02:12:32,687] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-02-05 02:12:32,688] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-02-05 02:12:32,707] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-02-05 02:12:32,728] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=1, memberId='connect-192.168.231.1:8083-495ff1e9-5c48-4e16-8c49-d88c03bba0e8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-02-05 02:12:32,793] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=1, memberId='connect-192.168.231.1:8083-495ff1e9-5c48-4e16-8c49-d88c03bba0e8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-02-05 02:12:32,794] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Joined group at generation 1 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-192.168.231.1:8083-495ff1e9-5c48-4e16-8c49-d88c03bba0e8', leaderUrl='http://192.168.231.1:8083/', offset=-1, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-02-05 02:12:32,795] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset -1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-02-05 02:12:32,795] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-02-05 02:12:32,864] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2442)
[2025-02-05 02:12:39,184] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = chat
	database = chat
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = chat
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2025-02-05 02:12:39,191] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = chat
	database = chat
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = chat
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2025-02-05 02:12:39,276] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.7.2"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/17.0.10+11-LTS-240"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='admin', source='admin', password=<hidden>, mechanismProperties=<hidden>}, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@1b21ea9c]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[com.mongodb.kafka.connect.util.ConnectionValidator$1@4141c8ac]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2025-02-05 02:12:39,294] INFO Opened connection [connectionId{localValue:1, serverValue:2}] to localhost:27017 (org.mongodb.driver.connection:71)
[2025-02-05 02:12:39,294] INFO Opened connection [connectionId{localValue:2, serverValue:1}] to localhost:27017 (org.mongodb.driver.connection:71)
[2025-02-05 02:12:39,294] INFO Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=32419500} (org.mongodb.driver.cluster:71)
[2025-02-05 02:12:39,348] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-02-05 02:12:39,396] INFO [0:0:0:0:0:0:0:1] - - [04/2/2025:17:12:39 +0000] "POST /connectors/ HTTP/1.1" 400 413 "-" "curl/8.9.1" 359 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-05 02:17:29,797] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:21:30,762] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:21:30,822] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:21:31,142] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:21:31,280] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:21:31,372] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:21:31,571] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:21:31,571] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:22:29,820] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:27:29,937] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:27:37,245] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2025-02-05 02:27:37,246] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:354)
[2025-02-05 02:27:37,251] INFO Stopped http_8083@2148b47e{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2025-02-05 02:27:37,251] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2025-02-05 02:27:37,253] INFO Stopped o.e.j.s.ServletContextHandler@3ba815ee{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2025-02-05 02:27:37,253] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:383)
[2025-02-05 02:27:37,255] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:831)
[2025-02-05 02:27:37,255] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2025-02-05 02:27:37,255] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Member connect-192.168.231.1:8083-495ff1e9-5c48-4e16-8c49-d88c03bba0e8 sending LeaveGroup request to coordinator DESKTOP-EJEJQKM:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1163)
[2025-02-05 02:27:37,256] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1055)
[2025-02-05 02:27:37,257] WARN [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1140)
[2025-02-05 02:27:37,257] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-05 02:27:37,258] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:27:37,258] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-05 02:27:37,260] INFO App info kafka.connect for connect-192.168.231.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-05 02:27:37,261] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:299)
[2025-02-05 02:27:37,261] INFO [Producer clientId=connect-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2025-02-05 02:27:37,265] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-05 02:27:37,266] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:27:37,266] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:27:37,266] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-05 02:27:37,267] INFO App info kafka.producer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-05 02:27:37,270] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-02-05 02:27:37,270] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-02-05 02:27:37,750] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-05 02:27:37,750] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:27:37,751] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:27:37,751] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-05 02:27:37,754] INFO App info kafka.consumer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-05 02:27:37,755] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:323)
[2025-02-05 02:27:37,755] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:408)
[2025-02-05 02:27:37,755] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:299)
[2025-02-05 02:27:37,756] INFO [Producer clientId=connect-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2025-02-05 02:27:37,759] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-05 02:27:37,760] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:27:37,760] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:27:37,760] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-05 02:27:37,761] INFO App info kafka.producer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-05 02:27:37,761] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-02-05 02:27:37,761] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-02-05 02:27:38,241] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-05 02:27:38,241] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:27:38,241] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:27:38,241] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-05 02:27:38,244] INFO App info kafka.consumer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-05 02:27:38,244] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:323)
[2025-02-05 02:27:38,244] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:414)
[2025-02-05 02:27:38,244] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:248)
[2025-02-05 02:27:38,245] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:269)
[2025-02-05 02:27:38,245] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:299)
[2025-02-05 02:27:38,245] INFO [Producer clientId=connect-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2025-02-05 02:27:38,248] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-05 02:27:38,248] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:27:38,248] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:27:38,249] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-05 02:27:38,249] INFO App info kafka.producer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-05 02:27:38,249] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-02-05 02:27:38,250] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-02-05 02:27:38,756] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-05 02:27:38,756] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:27:38,756] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:27:38,756] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-05 02:27:38,759] INFO App info kafka.consumer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-05 02:27:38,759] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:323)
[2025-02-05 02:27:38,759] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:277)
[2025-02-05 02:27:38,760] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-05 02:27:38,760] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:27:38,760] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-05 02:27:38,760] INFO App info kafka.connect for 192.168.231.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-05 02:27:38,760] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:269)
[2025-02-05 02:27:38,761] INFO App info kafka.admin.client for connect-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-05 02:27:38,762] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-05 02:27:38,763] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:27:38,763] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-05 02:27:38,763] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:386)
[2025-02-05 02:27:38,765] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:838)
[2025-02-05 02:27:38,765] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2025-02-05 02:32:16,208] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-02-05 02:32:16,214] INFO WorkerInfo values: 
	jvm.args = -Xmx256M, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2/logs, -Dlog4j.configuration=file:E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2/config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 17.0.10, 17.0.10+11-LTS-240
	jvm.classpath = E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\activation-1.1.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\aopalliance-repackaged-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\argparse4j-0.7.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\audience-annotations-0.12.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\caffeine-2.9.3.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\checker-qual-3.19.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-beanutils-1.9.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-cli-1.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-collections-3.2.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-digester-2.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-io-2.14.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-lang3-3.8.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-logging-1.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-validator-1.7.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-api-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-basic-auth-extension-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-file-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-json-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-mirror-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-mirror-client-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-runtime-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-transforms-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\error_prone_annotations-2.10.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-api-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-locator-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-utils-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-annotations-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-core-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-databind-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-dataformat-csv-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-datatype-jdk8-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-jaxrs-base-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-jaxrs-json-provider-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-module-jaxb-annotations-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-module-scala_2.12-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.activation-api-1.2.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.annotation-api-1.3.5.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.inject-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.validation-api-2.0.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.ws.rs-api-2.1.6.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.xml.bind-api-2.3.3.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javassist-3.29.2-GA.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.activation-api-1.2.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.annotation-api-1.3.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.servlet-api-3.1.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.ws.rs-api-2.1.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jaxb-api-2.3.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-client-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-common-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-container-servlet-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-container-servlet-core-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-hk2-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-server-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-client-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-continuation-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-http-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-io-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-security-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-server-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-servlet-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-servlets-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-util-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-util-ajax-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jline-3.25.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jopt-simple-5.0.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jose4j-0.9.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jsr305-3.0.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-clients-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-group-coordinator-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-log4j-appender-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-metadata-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-raft-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-server-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-server-common-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-shell-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-storage-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-storage-api-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-examples-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-scala_2.12-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-test-utils-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-tools-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-tools-api-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka_2.12-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\lz4-java-1.8.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\maven-artifact-3.8.8.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\metrics-core-2.2.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\metrics-core-4.1.12.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-buffer-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-codec-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-common-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-handler-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-resolver-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-classes-epoll-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-native-epoll-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-native-unix-common-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\opentelemetry-proto-1.0.0-alpha.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\osgi-resource-locator-1.0.3.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\paranamer-2.8.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\pcollections-4.0.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\plexus-utils-3.3.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\protobuf-java-3.25.5.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\reflections-0.10.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\reload4j-1.2.25.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\rocksdbjni-7.9.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-collection-compat_2.12-2.10.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-java8-compat_2.12-1.0.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-library-2.12.18.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-logging_2.12-3.9.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-reflect-2.12.18.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\slf4j-api-1.7.36.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\slf4j-reload4j-1.7.36.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\snappy-java-1.1.10.5.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\swagger-annotations-2.2.8.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\trogdor-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zookeeper-3.8.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zookeeper-jute-3.8.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zstd-jni-1.5.6-4.jar;
	os.spec = Windows 11, amd64, 10.0
	os.vcpus = 12
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-02-05 02:32:16,220] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-02-05 02:32:16,265] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\bin (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:32:16,476] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/bin/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:32:16,477] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\config (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:32:16,485] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/config/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:32:16,486] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:32:16,498] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:32:16,499] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:32:16,703] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:32:16,704] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\licenses (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:32:16,710] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/licenses/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:32:16,711] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\logs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:32:16,720] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/logs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:32:16,721] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\site-docs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:32:16,727] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/site-docs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:32:16,728] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:32:16,737] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@2b193f2d (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:32:16,737] INFO Scanning plugins with ServiceLoaderScanner took 474 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-02-05 02:32:16,739] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\bin (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:32:16,766] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/bin/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:32:16,767] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\config (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:32:16,770] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/config/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:32:16,770] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:32:17,049] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:32:17,050] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:32:18,248] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:32:18,249] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\licenses (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:32:18,252] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/licenses/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:32:18,253] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\logs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:32:18,255] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/logs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:32:18,256] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\site-docs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:32:18,258] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/site-docs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:32:18,258] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-05 02:32:19,049] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@2b193f2d (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-05 02:32:19,050] INFO Scanning plugins with ReflectionScanner took 2311 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-02-05 02:32:19,056] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/	com.mongodb.kafka.connect.MongoSinkConnector	sink	1.11.0
file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/	com.mongodb.kafka.connect.MongoSourceConnector	source	1.11.0
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-02-05 02:32:19,058] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,058] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,058] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,060] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,060] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,061] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,061] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,062] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,062] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,062] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,063] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,063] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,063] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,063] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,064] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,064] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,064] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,064] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,065] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,065] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,065] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,065] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,066] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,066] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,067] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,067] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,067] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,068] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,069] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,069] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,069] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,070] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,070] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,070] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,071] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,071] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,071] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,073] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,073] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,073] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,073] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,074] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,074] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,074] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,074] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,074] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,075] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,075] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,075] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,075] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,076] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,076] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,076] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-05 02:32:19,079] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,081] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,082] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,082] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,082] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,083] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,084] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,084] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,085] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,085] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,085] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,086] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,087] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,087] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,088] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,088] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,088] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,089] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,089] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,090] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,091] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,091] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,092] INFO Added alias 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,092] INFO Added alias 'MongoSinkConnector' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,092] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,092] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,093] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,093] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,094] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,094] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,094] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,095] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,095] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,095] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,096] INFO Added alias 'MongoSourceConnector' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,096] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,096] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,097] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,097] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,097] INFO Added alias 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,098] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,098] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,098] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,098] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,099] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,099] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,099] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,101] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,101] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,101] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,102] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,102] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,102] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,102] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,103] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,103] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-05 02:32:19,157] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-02-05 02:32:19,165] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-02-05 02:32:19,169] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-02-05 02:32:19,273] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-02-05 02:32:19,275] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:32:19,275] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:32:19,275] INFO Kafka startTimeMs: 1738690339274 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:32:19,613] INFO Kafka cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-02-05 02:32:19,614] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-05 02:32:19,620] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-05 02:32:19,620] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-05 02:32:19,620] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-05 02:32:19,624] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-02-05 02:32:19,632] INFO Logging initialized @3991ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-02-05 02:32:19,664] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-02-05 02:32:19,666] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-02-05 02:32:19,687] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 17.0.10+11-LTS-240 (org.eclipse.jetty.server.Server:375)
[2025-02-05 02:32:19,722] INFO Started http_8083@7e916dc2{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-02-05 02:32:19,722] INFO Started @4081ms (org.eclipse.jetty.server.Server:415)
[2025-02-05 02:32:19,744] INFO Advertised URI: http://192.168.231.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-05 02:32:19,745] INFO REST server listening at http://192.168.231.1:8083/, advertising URL http://192.168.231.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-02-05 02:32:19,745] INFO Advertised URI: http://192.168.231.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-05 02:32:19,745] INFO REST admin endpoints at http://192.168.231.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-02-05 02:32:19,746] INFO Advertised URI: http://192.168.231.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-05 02:32:19,746] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-02-05 02:32:19,752] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-02-05 02:32:19,770] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:32:19,770] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:32:19,770] INFO Kafka startTimeMs: 1738690339769 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:32:19,775] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-02-05 02:32:19,776] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-02-05 02:32:19,793] INFO Advertised URI: http://192.168.231.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-05 02:32:19,820] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:32:19,820] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:32:19,820] INFO Kafka startTimeMs: 1738690339820 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:32:19,825] INFO Kafka Connect worker initialization took 3614ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-02-05 02:32:19,825] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-02-05 02:32:19,828] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-02-05 02:32:19,828] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:369)
[2025-02-05 02:32:19,830] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:231)
[2025-02-05 02:32:19,830] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:240)
[2025-02-05 02:32:19,831] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-02-05 02:32:19,832] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-02-05 02:32:19,844] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-02-05 02:32:19,845] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:32:19,845] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:32:19,846] INFO Kafka startTimeMs: 1738690339845 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:32:19,869] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-02-05 02:32:19,889] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-02-05 02:32:19,909] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-02-05 02:32:19,910] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-02-05 02:32:19,910] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2025-02-05 02:32:19,924] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-05 02:32:19,947] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-02-05 02:32:19,948] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:32:19,948] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:32:19,948] INFO Kafka startTimeMs: 1738690339948 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:32:19,958] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.clients.Metadata:356)
[2025-02-05 02:32:19,960] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-05 02:32:19,977] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-05 02:32:20,011] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-05 02:32:20,012] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:32:20,012] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:32:20,012] INFO Kafka startTimeMs: 1738690340012 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:32:20,020] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.clients.Metadata:356)
[2025-02-05 02:32:20,025] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-02-05 02:32:20,028] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,029] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,030] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,030] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,030] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,030] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,032] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,032] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,032] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,033] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,033] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,033] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,034] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,034] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,034] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,034] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,036] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,036] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,036] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,037] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,037] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,037] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,038] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,038] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,038] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,079] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,080] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,081] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,082] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,082] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,083] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,083] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,084] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,084] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,085] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,085] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,086] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,086] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,086] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,087] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,088] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,088] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,089] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,089] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,090] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,090] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,090] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,092] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,092] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,093] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,094] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-02-05 02:32:20,094] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-02-05 02:32:20,094] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:257)
[2025-02-05 02:32:20,096] INFO Worker started (org.apache.kafka.connect.runtime.Worker:241)
[2025-02-05 02:32:20,098] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-02-05 02:32:20,106] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-02-05 02:32:20,113] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-05 02:32:20,126] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-02-05 02:32:20,127] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:32:20,127] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:32:20,127] INFO Kafka startTimeMs: 1738690340126 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:32:20,129] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-05 02:32:20,132] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.clients.Metadata:356)
[2025-02-05 02:32:20,138] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-05 02:32:20,146] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-05 02:32:20,147] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:32:20,147] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:32:20,147] INFO Kafka startTimeMs: 1738690340147 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:32:20,153] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.clients.Metadata:356)
[2025-02-05 02:32:20,154] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-02-05 02:32:20,155] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,155] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,155] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,157] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,157] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,167] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,168] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,168] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,170] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,170] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,171] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-02-05 02:32:20,171] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-02-05 02:32:20,174] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:379)
[2025-02-05 02:32:20,175] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-02-05 02:32:20,183] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-02-05 02:32:20,192] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-05 02:32:20,198] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-02-05 02:32:20,198] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:32:20,198] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:32:20,200] INFO Kafka startTimeMs: 1738690340198 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:32:20,201] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-05 02:32:20,203] INFO [Producer clientId=connect-cluster-configs] Cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.clients.Metadata:356)
[2025-02-05 02:32:20,208] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-05 02:32:20,215] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-05 02:32:20,216] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:32:20,217] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:32:20,217] INFO Kafka startTimeMs: 1738690340216 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:32:20,222] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.clients.Metadata:356)
[2025-02-05 02:32:20,223] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-02-05 02:32:20,224] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-05 02:32:20,233] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:32:20,292] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-02-05 02:32:20,292] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-02-05 02:32:20,292] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:403)
[2025-02-05 02:32:20,292] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:376)
[2025-02-05 02:32:20,301] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.clients.Metadata:356)
[2025-02-05 02:32:20,302] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Discovered group coordinator DESKTOP-EJEJQKM:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-02-05 02:32:20,305] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-02-05 02:32:20,305] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-02-05 02:32:20,316] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-02-05 02:32:20,320] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=1, memberId='connect-192.168.231.1:8083-e2f59a7d-2f07-48eb-8ee5-325366c1f4be', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-02-05 02:32:20,346] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=1, memberId='connect-192.168.231.1:8083-e2f59a7d-2f07-48eb-8ee5-325366c1f4be', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-02-05 02:32:20,347] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Joined group at generation 1 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-192.168.231.1:8083-e2f59a7d-2f07-48eb-8ee5-325366c1f4be', leaderUrl='http://192.168.231.1:8083/', offset=1, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-02-05 02:32:20,348] WARN [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1753)
[2025-02-05 02:32:20,348] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 1, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1826)
[2025-02-05 02:32:20,353] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1853)
[2025-02-05 02:32:20,354] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-02-05 02:32:20,354] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-02-05 02:32:20,425] INFO Started o.e.j.s.ServletContextHandler@55f54852{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-02-05 02:32:20,426] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-02-05 02:32:20,426] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-02-05 02:32:23,806] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = chat
	database = chat
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = chat
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2025-02-05 02:32:23,816] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = chat
	database = chat
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = chat
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2025-02-05 02:32:23,903] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.7.2"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/17.0.10+11-LTS-240"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='admin', source='admin', password=<hidden>, mechanismProperties=<hidden>}, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@70ca75d9]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[com.mongodb.kafka.connect.util.ConnectionValidator$1@6c0c981f]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2025-02-05 02:32:23,912] INFO Opened connection [connectionId{localValue:1, serverValue:89}] to localhost:27017 (org.mongodb.driver.connection:71)
[2025-02-05 02:32:23,912] INFO Opened connection [connectionId{localValue:2, serverValue:90}] to localhost:27017 (org.mongodb.driver.connection:71)
[2025-02-05 02:32:23,913] INFO Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=19376300} (org.mongodb.driver.cluster:71)
[2025-02-05 02:32:24,006] INFO Opened connection [connectionId{localValue:3, serverValue:91}] to localhost:27017 (org.mongodb.driver.connection:71)
[2025-02-05 02:32:24,027] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-02-05 02:32:24,065] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-02-05 02:32:24,074] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-02-05 02:32:24,074] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-02-05 02:32:24,078] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=2, memberId='connect-192.168.231.1:8083-e2f59a7d-2f07-48eb-8ee5-325366c1f4be', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-02-05 02:32:24,086] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=2, memberId='connect-192.168.231.1:8083-e2f59a7d-2f07-48eb-8ee5-325366c1f4be', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-02-05 02:32:24,087] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Joined group at generation 2 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-192.168.231.1:8083-e2f59a7d-2f07-48eb-8ee5-325366c1f4be', leaderUrl='http://192.168.231.1:8083/', offset=2, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-02-05 02:32:24,088] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 2 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-02-05 02:32:24,089] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-02-05 02:32:24,094] INFO [chat-connector|worker] Creating connector chat-connector of type com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-02-05 02:32:24,095] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-02-05 02:32:24,096] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-02-05 02:32:24,103] INFO [chat-connector|worker] Instantiated connector chat-connector with version 1.11.0 of type class com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-02-05 02:32:24,104] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-02-05 02:32:24,104] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-02-05 02:32:24,118] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-02-05 02:32:24,120] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-02-05 02:32:24,138] INFO [0:0:0:0:0:0:0:1] - - [04/2/2025:17:32:23 +0000] "POST /connectors/ HTTP/1.1" 201 396 "-" "curl/8.9.1" 475 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-05 02:32:24,151] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-02-05 02:32:24,155] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-02-05 02:32:24,155] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-02-05 02:32:24,159] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=3, memberId='connect-192.168.231.1:8083-e2f59a7d-2f07-48eb-8ee5-325366c1f4be', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-02-05 02:32:24,167] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=3, memberId='connect-192.168.231.1:8083-e2f59a7d-2f07-48eb-8ee5-325366c1f4be', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-02-05 02:32:24,168] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Joined group at generation 3 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-192.168.231.1:8083-e2f59a7d-2f07-48eb-8ee5-325366c1f4be', leaderUrl='http://192.168.231.1:8083/', offset=4, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-02-05 02:32:24,171] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 4 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-02-05 02:32:24,173] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-02-05 02:32:24,177] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-02-05 02:32:24,179] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-02-05 02:32:24,180] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-02-05 02:32:24,182] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.sink.MongoSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-02-05 02:32:24,182] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 1.11.0 of type com.mongodb.kafka.connect.sink.MongoSinkTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-02-05 02:32:24,184] INFO [chat-connector|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-02-05 02:32:24,185] INFO [chat-connector|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-02-05 02:32:24,185] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task chat-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:641)
[2025-02-05 02:32:24,185] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task chat-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:647)
[2025-02-05 02:32:24,187] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-02-05 02:32:24,192] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-02-05 02:32:24,193] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-02-05 02:32:24,194] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-02-05 02:32:24,197] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-05 02:32:24,204] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-05 02:32:24,211] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-05 02:32:24,212] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-05 02:32:24,213] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-05 02:32:24,213] INFO [chat-connector|task-0] Kafka startTimeMs: 1738690344212 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-05 02:32:24,232] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-02-05 02:32:24,232] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-02-05 02:32:24,232] INFO [chat-connector|task-0] Starting MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:66)
[2025-02-05 02:32:24,236] INFO [chat-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = chat
	database = chat
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = chat
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2025-02-05 02:32:24,244] INFO [chat-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|mongo-kafka|sink", "version": "4.7.2|1.11.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/17.0.10+11-LTS-240"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='admin', source='admin', password=<hidden>, mechanismProperties=<hidden>}, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@70ca75d9]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2025-02-05 02:32:24,250] INFO [chat-connector|task-0] Errant record reporter not configured. (com.mongodb.kafka.connect.sink.MongoSinkTask:138)
[2025-02-05 02:32:24,278] INFO [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:330)
[2025-02-05 02:32:24,280] INFO [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:214)
[2025-02-05 02:32:24,293] INFO [chat-connector|task-0] Opened connection [connectionId{localValue:5, serverValue:93}] to localhost:27017 (org.mongodb.driver.connection:71)
[2025-02-05 02:32:24,293] INFO [chat-connector|task-0] Opened connection [connectionId{localValue:4, serverValue:92}] to localhost:27017 (org.mongodb.driver.connection:71)
[2025-02-05 02:32:24,294] INFO [chat-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=6776100} (org.mongodb.driver.cluster:71)
[2025-02-05 02:32:24,318] WARN [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Error while fetching metadata with correlation id 2 : {chat=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1184)
[2025-02-05 02:32:24,319] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Cluster ID: 9B-6lQtVT8usPxx3k8wgQQ (org.apache.kafka.clients.Metadata:356)
[2025-02-05 02:32:24,320] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Discovered group coordinator DESKTOP-EJEJQKM:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-02-05 02:32:24,322] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-02-05 02:32:24,333] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: need to re-join with the given member-id: connector-consumer-chat-connector-0-e1e3f210-a2f7-45a4-9431-6ce055ba9965 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-02-05 02:32:24,334] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-02-05 02:32:24,345] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-chat-connector-0-e1e3f210-a2f7-45a4-9431-6ce055ba9965', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-02-05 02:32:24,459] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Finished assignment for group at generation 1: {connector-consumer-chat-connector-0-e1e3f210-a2f7-45a4-9431-6ce055ba9965=Assignment(partitions=[chat-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:659)
[2025-02-05 02:32:24,466] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-chat-connector-0-e1e3f210-a2f7-45a4-9431-6ce055ba9965', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-02-05 02:32:24,467] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Notifying assignor about the new Assignment(partitions=[chat-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:319)
[2025-02-05 02:32:24,467] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Adding newly assigned partitions: chat-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:56)
[2025-02-05 02:32:24,479] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Found no committed offset for partition chat-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1502)
[2025-02-05 02:32:24,482] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting offset for partition chat-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-EJEJQKM:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-05 02:37:19,857] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:41:20,020] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:41:20,127] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:41:20,188] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:41:20,218] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:41:20,277] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:41:20,368] INFO [Worker clientId=connect-192.168.231.1:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:41:20,700] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:41:24,609] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:42:19,876] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:47:19,997] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:51:20,105] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:51:20,303] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:51:20,303] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:51:24,334] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:52:20,120] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-05 02:57:20,234] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:997)
