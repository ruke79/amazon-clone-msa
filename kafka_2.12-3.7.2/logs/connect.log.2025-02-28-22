[2025-02-28 22:14:27,901] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-02-28 22:14:27,907] INFO WorkerInfo values: 
	jvm.args = -Xmx256M, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2/logs, -Dlog4j.configuration=file:E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2/config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 17.0.11, 17.0.11+7-LTS-207
	jvm.classpath = E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\activation-1.1.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\aopalliance-repackaged-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\argparse4j-0.7.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\audience-annotations-0.12.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\caffeine-2.9.3.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\checker-qual-3.19.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-beanutils-1.9.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-cli-1.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-collections-3.2.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-digester-2.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-io-2.14.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-lang3-3.8.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-logging-1.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-validator-1.7.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-api-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-basic-auth-extension-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-file-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-json-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-mirror-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-mirror-client-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-runtime-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-transforms-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\error_prone_annotations-2.10.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-api-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-locator-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-utils-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-annotations-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-core-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-databind-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-dataformat-csv-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-datatype-jdk8-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-jaxrs-base-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-jaxrs-json-provider-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-module-jaxb-annotations-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-module-scala_2.12-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.activation-api-1.2.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.annotation-api-1.3.5.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.inject-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.validation-api-2.0.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.ws.rs-api-2.1.6.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.xml.bind-api-2.3.3.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javassist-3.29.2-GA.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.activation-api-1.2.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.annotation-api-1.3.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.servlet-api-3.1.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.ws.rs-api-2.1.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jaxb-api-2.3.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-client-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-common-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-container-servlet-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-container-servlet-core-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-hk2-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-server-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-client-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-continuation-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-http-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-io-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-security-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-server-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-servlet-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-servlets-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-util-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-util-ajax-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jline-3.25.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jopt-simple-5.0.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jose4j-0.9.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jsr305-3.0.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-clients-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-group-coordinator-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-log4j-appender-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-metadata-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-raft-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-server-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-server-common-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-shell-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-storage-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-storage-api-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-examples-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-scala_2.12-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-test-utils-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-tools-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-tools-api-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka_2.12-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\lz4-java-1.8.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\maven-artifact-3.8.8.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\metrics-core-2.2.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\metrics-core-4.1.12.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-buffer-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-codec-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-common-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-handler-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-resolver-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-classes-epoll-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-native-epoll-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-native-unix-common-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\opentelemetry-proto-1.0.0-alpha.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\osgi-resource-locator-1.0.3.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\paranamer-2.8.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\pcollections-4.0.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\plexus-utils-3.3.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\protobuf-java-3.25.5.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\reflections-0.10.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\reload4j-1.2.25.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\rocksdbjni-7.9.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-collection-compat_2.12-2.10.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-java8-compat_2.12-1.0.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-library-2.12.18.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-logging_2.12-3.9.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-reflect-2.12.18.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\slf4j-api-1.7.36.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\slf4j-reload4j-1.7.36.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\snappy-java-1.1.10.5.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\swagger-annotations-2.2.8.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\trogdor-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zookeeper-3.8.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zookeeper-jute-3.8.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zstd-jni-1.5.6-4.jar;
	os.spec = Windows 11, amd64, 10.0
	os.vcpus = 24
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-02-28 22:14:27,911] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-02-28 22:14:27,946] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\bin (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:14:28,144] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/bin/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:14:28,146] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\config (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:14:28,153] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/config/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:14:28,154] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:14:28,163] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:14:28,164] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:14:28,294] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:14:28,294] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\licenses (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:14:28,300] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/licenses/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:14:28,300] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\logs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:14:28,307] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/logs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:14:28,307] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\site-docs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:14:28,312] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/site-docs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:14:28,313] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:14:28,318] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@2b193f2d (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:14:28,319] INFO Scanning plugins with ServiceLoaderScanner took 374 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-02-28 22:14:28,320] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\bin (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:14:28,336] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/bin/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:14:28,337] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\config (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:14:28,339] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/config/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:14:28,339] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:14:28,573] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:14:28,575] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:14:29,462] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:14:29,464] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\licenses (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:14:29,465] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/licenses/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:14:29,466] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\logs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:14:29,467] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/logs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:14:29,468] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\site-docs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:14:29,469] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/site-docs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:14:29,470] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:14:30,002] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@2b193f2d (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:14:30,003] INFO Scanning plugins with ReflectionScanner took 1683 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-02-28 22:14:30,007] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/	com.mongodb.kafka.connect.MongoSinkConnector	sink	1.11.0
file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/	com.mongodb.kafka.connect.MongoSourceConnector	source	1.11.0
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-02-28 22:14:30,009] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,009] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,009] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,009] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,010] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,010] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,010] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,011] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,011] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,011] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,011] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,012] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,012] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,012] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,013] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,013] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,013] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,013] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,014] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,014] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,014] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,014] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,015] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,015] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,015] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,015] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,015] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,016] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,016] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,016] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,016] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,017] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,017] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,017] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,017] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,017] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,018] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,018] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,019] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,019] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,019] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,019] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,019] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,020] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,020] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,020] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,020] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,021] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,021] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,021] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,021] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,022] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,022] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:14:30,024] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,024] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,024] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,025] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,025] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,025] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,026] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,026] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,026] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,026] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,027] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,027] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,027] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,028] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,028] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,028] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,028] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,029] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,029] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,029] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,029] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,030] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,030] INFO Added alias 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,030] INFO Added alias 'MongoSinkConnector' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,030] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,031] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,031] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,032] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,032] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,032] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,032] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,033] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,033] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,033] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,033] INFO Added alias 'MongoSourceConnector' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,033] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,034] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,034] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,034] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,035] INFO Added alias 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,035] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,035] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,035] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,036] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,036] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,037] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,037] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,037] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,037] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,037] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,038] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,038] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,038] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,038] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,038] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,039] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:14:30,082] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-02-28 22:14:30,089] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-02-28 22:14:30,091] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-02-28 22:14:30,163] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-02-28 22:14:30,163] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:14:30,164] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:14:30,164] INFO Kafka startTimeMs: 1740748470163 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:14:30,382] INFO Kafka cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-02-28 22:14:30,383] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:14:30,388] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:14:30,388] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:14:30,388] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:14:30,391] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-02-28 22:14:30,397] INFO Logging initialized @2982ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-02-28 22:14:30,424] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-02-28 22:14:30,424] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-02-28 22:14:30,442] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 17.0.11+7-LTS-207 (org.eclipse.jetty.server.Server:375)
[2025-02-28 22:14:30,477] INFO Started http_8083@bc52a41{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-02-28 22:14:30,478] INFO Started @3063ms (org.eclipse.jetty.server.Server:415)
[2025-02-28 22:14:30,494] INFO Advertised URI: http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-28 22:14:30,495] INFO REST server listening at http://211.226.118.18:8083/, advertising URL http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-02-28 22:14:30,495] INFO Advertised URI: http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-28 22:14:30,495] INFO REST admin endpoints at http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-02-28 22:14:30,497] INFO Advertised URI: http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-28 22:14:30,497] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-02-28 22:14:30,502] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-02-28 22:14:30,512] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:14:30,512] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:14:30,512] INFO Kafka startTimeMs: 1740748470512 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:14:30,516] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-02-28 22:14:30,516] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-02-28 22:14:30,528] INFO Advertised URI: http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-28 22:14:30,546] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:14:30,547] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:14:30,547] INFO Kafka startTimeMs: 1740748470546 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:14:30,549] INFO Kafka Connect worker initialization took 2644ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-02-28 22:14:30,549] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-02-28 22:14:30,551] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-02-28 22:14:30,551] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:369)
[2025-02-28 22:14:30,553] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:231)
[2025-02-28 22:14:30,553] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:240)
[2025-02-28 22:14:30,553] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-02-28 22:14:30,554] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-02-28 22:14:30,561] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-02-28 22:14:30,562] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:14:30,562] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:14:30,562] INFO Kafka startTimeMs: 1740748470562 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:14:30,578] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-02-28 22:14:30,602] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-02-28 22:14:30,604] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-02-28 22:14:30,608] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-02-28 22:14:30,609] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2025-02-28 22:14:30,630] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:14:30,650] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-02-28 22:14:30,650] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:14:30,651] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:14:30,651] INFO Kafka startTimeMs: 1740748470650 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:14:30,660] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:14:30,673] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-28 22:14:30,691] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:14:30,718] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-28 22:14:30,719] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:14:30,719] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:14:30,719] INFO Kafka startTimeMs: 1740748470719 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:14:30,725] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:14:30,730] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-02-28 22:14:30,738] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,739] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,740] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,740] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,741] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,741] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,742] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,742] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,742] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,743] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,743] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,743] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,744] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,744] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,744] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,744] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,745] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,745] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,745] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,745] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,746] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,746] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,746] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,746] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,746] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,781] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,783] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,783] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,784] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,784] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,784] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,786] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,786] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,786] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,787] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,787] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,788] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,788] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,788] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,789] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,789] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,790] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,790] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,791] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,791] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,791] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,792] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,792] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,792] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,793] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,793] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-02-28 22:14:30,794] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-02-28 22:14:30,794] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:257)
[2025-02-28 22:14:30,795] INFO Worker started (org.apache.kafka.connect.runtime.Worker:241)
[2025-02-28 22:14:30,795] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-02-28 22:14:30,799] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-02-28 22:14:30,804] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:14:30,811] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-02-28 22:14:30,811] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:14:30,812] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:14:30,812] INFO Kafka startTimeMs: 1740748470811 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:14:30,813] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-28 22:14:30,814] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:14:30,818] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:14:30,832] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-28 22:14:30,833] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:14:30,834] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:14:30,834] INFO Kafka startTimeMs: 1740748470833 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:14:30,837] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:14:30,838] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-02-28 22:14:30,838] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,839] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,839] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,839] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,839] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,845] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,846] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,846] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,847] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,847] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,848] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-02-28 22:14:30,848] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-02-28 22:14:30,852] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:379)
[2025-02-28 22:14:30,852] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-02-28 22:14:30,859] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-02-28 22:14:30,863] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:14:30,867] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-02-28 22:14:30,867] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:14:30,868] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:14:30,868] INFO Kafka startTimeMs: 1740748470867 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:14:30,869] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-28 22:14:30,870] INFO [Producer clientId=connect-cluster-configs] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:14:30,874] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:14:30,879] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-28 22:14:30,879] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:14:30,880] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:14:30,880] INFO Kafka startTimeMs: 1740748470879 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:14:30,884] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:14:30,885] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-02-28 22:14:30,885] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:14:30,892] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:14:30,940] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-02-28 22:14:30,944] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-02-28 22:14:30,944] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:403)
[2025-02-28 22:14:30,944] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:376)
[2025-02-28 22:14:30,953] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:14:30,954] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-02-28 22:14:30,956] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-02-28 22:14:30,957] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-02-28 22:14:30,967] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-02-28 22:14:30,971] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=1, memberId='connect-211.226.118.18:8083-6e2931c3-5232-42ab-bee6-99205c70483f', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-02-28 22:14:30,992] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=1, memberId='connect-211.226.118.18:8083-6e2931c3-5232-42ab-bee6-99205c70483f', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-02-28 22:14:30,993] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Joined group at generation 1 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-211.226.118.18:8083-6e2931c3-5232-42ab-bee6-99205c70483f', leaderUrl='http://211.226.118.18:8083/', offset=6, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-02-28 22:14:30,994] WARN [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1753)
[2025-02-28 22:14:30,994] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 6, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1826)
[2025-02-28 22:14:30,998] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 6 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1853)
[2025-02-28 22:14:30,998] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 6 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-02-28 22:14:30,998] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-02-28 22:14:31,033] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2442)
[2025-02-28 22:14:31,037] INFO Started o.e.j.s.ServletContextHandler@5ca86715{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-02-28 22:14:31,037] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-02-28 22:14:31,037] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-02-28 22:18:10,052] ERROR Uncaught exception in REST call to /connectors/ (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `org.apache.kafka.connect.runtime.rest.entities.CreateConnectorRequest` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('name')
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 2]
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:63)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1754)
	at com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1379)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._deserializeFromString(StdDeserializer.java:311)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromString(BeanDeserializerBase.java:1588)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:197)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:187)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:342)
	at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:2099)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1249)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:801)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:919)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:290)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:842)
[2025-02-28 22:18:10,081] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:18:09 +0000] "POST /connectors/ HTTP/1.1" 500 361 "-" "curl/8.10.1" 88 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:19:30,577] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:23:30,760] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:23:30,883] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:23:30,945] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:23:31,053] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:23:31,146] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:23:31,146] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:23:31,208] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:24:30,588] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:28:19,233] ERROR Uncaught exception in REST call to /connectors/ (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
com.fasterxml.jackson.core.JsonParseException: Unexpected character ('d' (code 100)) in numeric value: expected digit (0-9) to follow minus sign, for valid numeric value
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3]
	at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:2481)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:752)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedNumberChar(ParserMinimalBase.java:568)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleInvalidNumberStart(UTF8StreamJsonParser.java:2931)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._parseSignedNumber(UTF8StreamJsonParser.java:1545)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:891)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:797)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:763)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:919)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:290)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:842)
[2025-02-28 22:28:19,240] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:28:19 +0000] "POST /connectors/ HTTP/1.1" 500 255 "-" "curl/8.10.1" 9 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:29:03,691] ERROR Uncaught exception in REST call to /connectors/ (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
com.fasterxml.jackson.core.JsonParseException: Unexpected character ('d' (code 100)) in numeric value: expected digit (0-9) to follow minus sign, for valid numeric value
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3]
	at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:2481)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:752)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedNumberChar(ParserMinimalBase.java:568)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleInvalidNumberStart(UTF8StreamJsonParser.java:2931)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._parseSignedNumber(UTF8StreamJsonParser.java:1545)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:891)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:797)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:763)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:919)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:290)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:842)
[2025-02-28 22:29:03,696] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:29:03 +0000] "POST /connectors/ HTTP/1.1" 500 255 "-" "curl/8.10.1" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:29:30,701] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:29:46,994] ERROR Uncaught exception in REST call to /connectors/ (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
com.fasterxml.jackson.core.JsonParseException: Unexpected character ('d' (code 100)) in numeric value: expected digit (0-9) to follow minus sign, for valid numeric value
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3]
	at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:2481)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:752)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedNumberChar(ParserMinimalBase.java:568)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleInvalidNumberStart(UTF8StreamJsonParser.java:2931)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._parseSignedNumber(UTF8StreamJsonParser.java:1545)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:891)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:797)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:763)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:919)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:290)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:842)
[2025-02-28 22:29:46,999] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:29:46 +0000] "POST /connectors/ HTTP/1.1" 500 255 "-" "curl/8.10.1" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:32:28,516] ERROR Uncaught exception in REST call to /connectors/ (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
com.fasterxml.jackson.core.JsonParseException: Unexpected character ('d' (code 100)) in numeric value: expected digit (0-9) to follow minus sign, for valid numeric value
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3]
	at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:2481)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:752)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedNumberChar(ParserMinimalBase.java:568)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleInvalidNumberStart(UTF8StreamJsonParser.java:2931)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._parseSignedNumber(UTF8StreamJsonParser.java:1545)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:891)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:797)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:763)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:919)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:290)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:842)
[2025-02-28 22:32:28,521] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:32:28 +0000] "POST /connectors/ HTTP/1.1" 500 255 "-" "curl/8.10.1" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:32:30,280] ERROR Uncaught exception in REST call to /connectors/ (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.debezium.connector.mysql.MySqlConnector, available connectors are: PluginDesc{klass=class com.mongodb.kafka.connect.MongoSinkConnector, name='com.mongodb.kafka.connect.MongoSinkConnector', version='1.11.0', encodedVersion=1.11.0, type=sink, typeName='sink', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/'}, PluginDesc{klass=class com.mongodb.kafka.connect.MongoSourceConnector, name='com.mongodb.kafka.connect.MongoSourceConnector', version='1.11.0', encodedVersion=1.11.0, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.7.2', encodedVersion=3.7.2, type=sink, typeName='sink', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.7.2', encodedVersion=3.7.2, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:320)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:291)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$7(AbstractHerder.java:756)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1708)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:756)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:501)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$3(AbstractHerder.java:413)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
[2025-02-28 22:32:30,283] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:32:30 +0000] "POST /connectors/ HTTP/1.1" 500 3309 "-" "curl/8.10.1" 14 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:33:30,953] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:33:30,953] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:33:31,032] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:34:30,816] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:35:50,902] ERROR Uncaught exception in REST call to /connectors/ (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.debezium.connector.mysql.MySqlConnector, available connectors are: PluginDesc{klass=class com.mongodb.kafka.connect.MongoSinkConnector, name='com.mongodb.kafka.connect.MongoSinkConnector', version='1.11.0', encodedVersion=1.11.0, type=sink, typeName='sink', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/'}, PluginDesc{klass=class com.mongodb.kafka.connect.MongoSourceConnector, name='com.mongodb.kafka.connect.MongoSourceConnector', version='1.11.0', encodedVersion=1.11.0, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.7.2', encodedVersion=3.7.2, type=sink, typeName='sink', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.7.2', encodedVersion=3.7.2, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:320)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:291)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$7(AbstractHerder.java:756)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1708)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:756)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:501)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$3(AbstractHerder.java:413)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
[2025-02-28 22:35:50,904] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:35:50 +0000] "POST /connectors/ HTTP/1.1" 500 3309 "-" "curl/8.10.1" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:36:45,109] ERROR Uncaught exception in REST call to /connectors/ (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.debezium.connector.mysql.MySqlConnector, available connectors are: PluginDesc{klass=class com.mongodb.kafka.connect.MongoSinkConnector, name='com.mongodb.kafka.connect.MongoSinkConnector', version='1.11.0', encodedVersion=1.11.0, type=sink, typeName='sink', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/'}, PluginDesc{klass=class com.mongodb.kafka.connect.MongoSourceConnector, name='com.mongodb.kafka.connect.MongoSourceConnector', version='1.11.0', encodedVersion=1.11.0, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.7.2', encodedVersion=3.7.2, type=sink, typeName='sink', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.7.2', encodedVersion=3.7.2, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:320)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:291)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$7(AbstractHerder.java:756)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1708)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:756)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:501)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$3(AbstractHerder.java:413)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
[2025-02-28 22:36:45,112] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:36:45 +0000] "POST /connectors/ HTTP/1.1" 500 3309 "-" "curl/8.10.1" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:37:05,522] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2025-02-28 22:37:05,522] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:354)
[2025-02-28 22:37:05,526] INFO Stopped http_8083@bc52a41{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2025-02-28 22:37:05,527] INFO Stopped o.e.j.s.ServletContextHandler@5ca86715{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2025-02-28 22:37:05,527] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2025-02-28 22:37:05,529] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:383)
[2025-02-28 22:37:05,529] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:831)
[2025-02-28 22:37:05,529] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2025-02-28 22:37:05,530] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Member connect-211.226.118.18:8083-6e2931c3-5232-42ab-bee6-99205c70483f sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1163)
[2025-02-28 22:37:05,530] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1055)
[2025-02-28 22:37:05,530] WARN [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1140)
[2025-02-28 22:37:05,531] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:37:05,531] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:37:05,531] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:37:05,532] INFO App info kafka.connect for connect-211.226.118.18:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:37:05,533] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:299)
[2025-02-28 22:37:05,533] INFO [Producer clientId=connect-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2025-02-28 22:37:05,536] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:37:05,536] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:37:05,536] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:37:05,536] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:37:05,537] INFO App info kafka.producer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:37:05,538] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-02-28 22:37:05,538] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-02-28 22:37:05,571] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:37:05,571] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:37:05,572] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:37:05,572] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:37:05,574] INFO App info kafka.consumer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:37:05,574] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:323)
[2025-02-28 22:37:05,574] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:408)
[2025-02-28 22:37:05,574] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:299)
[2025-02-28 22:37:05,574] INFO [Producer clientId=connect-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2025-02-28 22:37:05,577] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:37:05,577] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:37:05,577] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:37:05,578] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:37:05,578] INFO App info kafka.producer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:37:05,578] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-02-28 22:37:05,578] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-02-28 22:37:06,083] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:37:06,084] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:37:06,084] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:37:06,084] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:37:06,085] INFO App info kafka.consumer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:37:06,085] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:323)
[2025-02-28 22:37:06,086] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:414)
[2025-02-28 22:37:06,086] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:248)
[2025-02-28 22:37:06,086] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:269)
[2025-02-28 22:37:06,087] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:299)
[2025-02-28 22:37:06,087] INFO [Producer clientId=connect-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2025-02-28 22:37:06,089] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:37:06,090] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:37:06,090] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:37:06,090] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:37:06,090] INFO App info kafka.producer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:37:06,091] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-02-28 22:37:06,091] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-02-28 22:37:06,598] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:37:06,598] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:37:06,599] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:37:06,599] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:37:06,600] INFO App info kafka.consumer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:37:06,601] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:323)
[2025-02-28 22:37:06,601] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:277)
[2025-02-28 22:37:06,601] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:37:06,601] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:37:06,601] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:37:06,601] INFO App info kafka.connect for 211.226.118.18:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:37:06,601] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:269)
[2025-02-28 22:37:06,602] INFO App info kafka.admin.client for connect-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:37:06,602] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:37:06,603] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:37:06,603] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:37:06,603] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:386)
[2025-02-28 22:37:06,603] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:838)
[2025-02-28 22:37:06,604] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2025-02-28 22:37:12,094] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-02-28 22:37:12,097] INFO WorkerInfo values: 
	jvm.args = -Xmx256M, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2/logs, -Dlog4j.configuration=file:E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2/config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 17.0.11, 17.0.11+7-LTS-207
	jvm.classpath = E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\activation-1.1.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\aopalliance-repackaged-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\argparse4j-0.7.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\audience-annotations-0.12.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\caffeine-2.9.3.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\checker-qual-3.19.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-beanutils-1.9.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-cli-1.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-collections-3.2.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-digester-2.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-io-2.14.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-lang3-3.8.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-logging-1.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-validator-1.7.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-api-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-basic-auth-extension-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-file-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-json-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-mirror-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-mirror-client-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-runtime-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-transforms-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\error_prone_annotations-2.10.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-api-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-locator-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-utils-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-annotations-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-core-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-databind-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-dataformat-csv-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-datatype-jdk8-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-jaxrs-base-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-jaxrs-json-provider-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-module-jaxb-annotations-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-module-scala_2.12-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.activation-api-1.2.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.annotation-api-1.3.5.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.inject-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.validation-api-2.0.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.ws.rs-api-2.1.6.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.xml.bind-api-2.3.3.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javassist-3.29.2-GA.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.activation-api-1.2.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.annotation-api-1.3.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.servlet-api-3.1.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.ws.rs-api-2.1.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jaxb-api-2.3.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-client-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-common-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-container-servlet-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-container-servlet-core-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-hk2-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-server-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-client-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-continuation-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-http-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-io-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-security-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-server-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-servlet-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-servlets-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-util-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-util-ajax-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jline-3.25.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jopt-simple-5.0.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jose4j-0.9.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jsr305-3.0.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-clients-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-group-coordinator-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-log4j-appender-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-metadata-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-raft-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-server-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-server-common-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-shell-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-storage-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-storage-api-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-examples-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-scala_2.12-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-test-utils-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-tools-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-tools-api-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka_2.12-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\lz4-java-1.8.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\maven-artifact-3.8.8.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\metrics-core-2.2.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\metrics-core-4.1.12.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-buffer-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-codec-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-common-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-handler-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-resolver-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-classes-epoll-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-native-epoll-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-native-unix-common-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\opentelemetry-proto-1.0.0-alpha.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\osgi-resource-locator-1.0.3.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\paranamer-2.8.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\pcollections-4.0.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\plexus-utils-3.3.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\protobuf-java-3.25.5.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\reflections-0.10.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\reload4j-1.2.25.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\rocksdbjni-7.9.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-collection-compat_2.12-2.10.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-java8-compat_2.12-1.0.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-library-2.12.18.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-logging_2.12-3.9.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-reflect-2.12.18.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\slf4j-api-1.7.36.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\slf4j-reload4j-1.7.36.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\snappy-java-1.1.10.5.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\swagger-annotations-2.2.8.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\trogdor-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zookeeper-3.8.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zookeeper-jute-3.8.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zstd-jni-1.5.6-4.jar;
	os.spec = Windows 11, amd64, 10.0
	os.vcpus = 24
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-02-28 22:37:12,100] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-02-28 22:37:12,141] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\bin (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:37:12,295] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/bin/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:37:12,296] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\config (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:37:12,303] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/config/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:37:12,304] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:37:12,310] ERROR Failed to discover SourceConnector in E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:183)
java.lang.NoClassDefFoundError: io/debezium/connector/binlog/BinlogConnector
	at java.base/java.lang.ClassLoader.defineClass1(Native Method)
	at java.base/java.lang.ClassLoader.defineClass(ClassLoader.java:1012)
	at java.base/java.security.SecureClassLoader.defineClass(SecureClassLoader.java:150)
	at java.base/java.net.URLClassLoader.defineClass(URLClassLoader.java:524)
	at java.base/java.net.URLClassLoader$1.run(URLClassLoader.java:427)
	at java.base/java.net.URLClassLoader$1.run(URLClassLoader.java:421)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:420)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:116)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:520)
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.nextProviderClass(ServiceLoader.java:1217)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1228)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:176)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:132)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:60)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:79)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:67)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:83)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:75)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:64)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:94)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:116)
Caused by: java.lang.ClassNotFoundException: io.debezium.connector.binlog.BinlogConnector
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:587)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:520)
	... 28 more
[2025-02-28 22:37:12,318] ERROR Failed to get plugin version for class io.debezium.connector.mysql.transforms.ReadToInsertEvent (org.apache.kafka.connect.runtime.isolation.PluginScanner:201)
java.lang.NoClassDefFoundError: io/debezium/util/IoUtil
	at io.debezium.connector.mysql.Module.<clinit>(Module.java:19)
	at io.debezium.connector.mysql.transforms.ReadToInsertEvent.version(ReadToInsertEvent.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.versionFor(PluginScanner.java:198)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:148)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.getTransformationPluginDesc(ServiceLoaderScanner.java:78)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:63)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:79)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:67)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:83)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:75)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:64)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:94)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:116)
Caused by: java.lang.ClassNotFoundException: io.debezium.util.IoUtil
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:587)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:520)
	... 14 more
[2025-02-28 22:37:12,336] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:37:12,342] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:37:12,467] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:37:12,468] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\licenses (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:37:12,473] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/licenses/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:37:12,474] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\logs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:37:12,479] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/logs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:37:12,480] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\site-docs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:37:12,484] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/site-docs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:37:12,484] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:37:12,487] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@2b193f2d (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:37:12,488] INFO Scanning plugins with ServiceLoaderScanner took 349 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-02-28 22:37:12,490] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\bin (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:37:12,508] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/bin/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:37:12,509] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\config (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:37:12,510] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/config/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:37:12,511] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:37:12,888] ERROR Failed to get plugin version for class io.debezium.connector.mysql.transforms.ReadToInsertEvent (org.apache.kafka.connect.runtime.isolation.PluginScanner:201)
java.lang.NoClassDefFoundError: Could not initialize class io.debezium.connector.mysql.Module
	at io.debezium.connector.mysql.transforms.ReadToInsertEvent.version(ReadToInsertEvent.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.versionFor(PluginScanner.java:198)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.versionFor(ReflectionScanner.java:74)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getPluginDesc(ReflectionScanner.java:136)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getTransformationPluginDesc(ReflectionScanner.java:106)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.scanPlugins(ReflectionScanner.java:91)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:79)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:67)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:91)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:75)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:64)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:94)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:116)
Caused by: java.lang.ExceptionInInitializerError: Exception java.lang.NoClassDefFoundError: io/debezium/util/IoUtil [in thread "main"]
	at io.debezium.connector.mysql.Module.<clinit>(Module.java:19)
	at io.debezium.connector.mysql.transforms.ReadToInsertEvent.version(ReadToInsertEvent.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.versionFor(PluginScanner.java:198)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:148)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.getTransformationPluginDesc(ServiceLoaderScanner.java:78)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:63)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:79)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:67)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:83)
	... 5 more
[2025-02-28 22:37:12,893] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:37:12,894] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:37:13,662] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:37:13,662] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\licenses (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:37:13,664] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/licenses/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:37:13,664] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\logs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:37:13,666] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/logs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:37:13,666] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\site-docs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:37:13,667] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/site-docs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:37:13,668] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:37:14,150] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@2b193f2d (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:37:14,150] INFO Scanning plugins with ReflectionScanner took 1660 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-02-28 22:37:14,155] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/	com.mongodb.kafka.connect.MongoSinkConnector	sink	1.11.0
file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/	com.mongodb.kafka.connect.MongoSourceConnector	source	1.11.0
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-02-28 22:37:14,158] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,159] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,159] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,160] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,160] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,161] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,161] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,161] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,162] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,163] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,164] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,164] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,164] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,165] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,165] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,166] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,166] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,166] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,167] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,167] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,167] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,167] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,168] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,168] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,168] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,169] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,169] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,169] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,169] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,170] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,171] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,171] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,171] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,171] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,172] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,172] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,172] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,172] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,172] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,173] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,173] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,173] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,173] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,174] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,174] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,174] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,174] INFO Added plugin 'io.debezium.connector.mysql.rest.DebeziumMySqlConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,174] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,174] INFO Added plugin 'io.debezium.connector.mysql.transforms.ReadToInsertEvent' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,175] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,175] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,176] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,176] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,176] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,177] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:37:14,179] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,179] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,179] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,179] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,180] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,180] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,181] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,181] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,181] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,182] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,182] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,182] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,182] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,182] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,183] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,183] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,183] INFO Added alias 'ReadToInsertEvent' to plugin 'io.debezium.connector.mysql.transforms.ReadToInsertEvent' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,184] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,184] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,184] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,184] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,185] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,185] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,186] INFO Added alias 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,186] INFO Added alias 'MongoSinkConnector' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,186] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,186] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,186] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,187] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,187] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,188] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,188] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,189] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,189] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,190] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,190] INFO Added alias 'DebeziumMySql' to plugin 'io.debezium.connector.mysql.rest.DebeziumMySqlConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,190] INFO Added alias 'MongoSourceConnector' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,191] INFO Added alias 'DebeziumMySqlConnectRestExtension' to plugin 'io.debezium.connector.mysql.rest.DebeziumMySqlConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,191] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,192] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,192] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,192] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,193] INFO Added alias 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,193] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,193] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,193] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,193] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,194] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,194] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,194] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,195] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,195] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,196] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,196] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,196] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,196] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,196] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,197] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,197] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:37:14,233] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-02-28 22:37:14,239] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-02-28 22:37:14,242] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-02-28 22:37:14,315] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-02-28 22:37:14,316] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:37:14,316] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:37:14,317] INFO Kafka startTimeMs: 1740749834316 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:37:14,543] INFO Kafka cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-02-28 22:37:14,544] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:37:14,547] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:37:14,548] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:37:14,548] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:37:14,550] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-02-28 22:37:14,558] INFO Logging initialized @2982ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-02-28 22:37:14,584] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-02-28 22:37:14,584] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-02-28 22:37:14,600] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 17.0.11+7-LTS-207 (org.eclipse.jetty.server.Server:375)
[2025-02-28 22:37:14,635] INFO Started http_8083@d08f85a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-02-28 22:37:14,635] INFO Started @3060ms (org.eclipse.jetty.server.Server:415)
[2025-02-28 22:37:14,657] INFO Advertised URI: http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-28 22:37:14,657] INFO REST server listening at http://211.226.118.18:8083/, advertising URL http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-02-28 22:37:14,657] INFO Advertised URI: http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-28 22:37:14,658] INFO REST admin endpoints at http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-02-28 22:37:14,658] INFO Advertised URI: http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-28 22:37:14,658] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-02-28 22:37:14,663] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-02-28 22:37:14,672] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:37:14,673] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:37:14,673] INFO Kafka startTimeMs: 1740749834672 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:37:14,677] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-02-28 22:37:14,677] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-02-28 22:37:14,687] INFO Advertised URI: http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-28 22:37:14,709] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:37:14,709] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:37:14,709] INFO Kafka startTimeMs: 1740749834709 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:37:14,711] INFO Kafka Connect worker initialization took 2617ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-02-28 22:37:14,711] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-02-28 22:37:14,714] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-02-28 22:37:14,714] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:369)
[2025-02-28 22:37:14,717] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:231)
[2025-02-28 22:37:14,717] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:240)
[2025-02-28 22:37:14,717] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-02-28 22:37:14,718] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-02-28 22:37:14,727] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-02-28 22:37:14,727] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:37:14,727] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:37:14,728] INFO Kafka startTimeMs: 1740749834727 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:37:14,744] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-02-28 22:37:14,752] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-02-28 22:37:14,773] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-02-28 22:37:14,773] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-02-28 22:37:14,774] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2025-02-28 22:37:14,774] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:37:14,797] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-02-28 22:37:14,798] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:37:14,798] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:37:14,798] INFO Kafka startTimeMs: 1740749834798 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:37:14,811] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:37:14,816] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-28 22:37:14,827] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:37:14,848] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-28 22:37:14,848] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:37:14,848] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:37:14,848] INFO Kafka startTimeMs: 1740749834848 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:37:14,853] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:37:14,860] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-02-28 22:37:14,864] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,866] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,866] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,866] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,867] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,867] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,867] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,867] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,867] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,868] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,868] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,868] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,868] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,868] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,869] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,869] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,869] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,869] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,870] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,870] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,870] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,870] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,871] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,871] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,871] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,905] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,906] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,906] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,906] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,907] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,907] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,907] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,908] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,908] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,908] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,909] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,909] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,910] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,910] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,910] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,911] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,911] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,911] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,912] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,912] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,912] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,913] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,913] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,913] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,913] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,914] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-02-28 22:37:14,914] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-02-28 22:37:14,914] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:257)
[2025-02-28 22:37:14,917] INFO Worker started (org.apache.kafka.connect.runtime.Worker:241)
[2025-02-28 22:37:14,917] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-02-28 22:37:14,927] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-02-28 22:37:14,932] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:37:14,937] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-02-28 22:37:14,938] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:37:14,938] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:37:14,939] INFO Kafka startTimeMs: 1740749834938 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:37:14,939] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-28 22:37:14,941] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:37:14,944] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:37:14,950] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-28 22:37:14,951] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:37:14,951] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:37:14,952] INFO Kafka startTimeMs: 1740749834951 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:37:14,955] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:37:14,956] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-02-28 22:37:14,956] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,957] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,957] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,957] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,958] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:14,964] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,964] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,966] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,966] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,967] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:14,968] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-02-28 22:37:14,968] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-02-28 22:37:14,973] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:379)
[2025-02-28 22:37:14,973] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-02-28 22:37:14,978] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-02-28 22:37:14,983] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:37:14,988] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-02-28 22:37:14,989] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:37:14,989] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:37:14,989] INFO Kafka startTimeMs: 1740749834989 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:37:14,990] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-28 22:37:14,992] INFO [Producer clientId=connect-cluster-configs] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:37:14,995] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:37:14,999] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-28 22:37:14,999] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:37:15,000] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:37:15,000] INFO Kafka startTimeMs: 1740749834999 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:37:15,003] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:37:15,004] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-02-28 22:37:15,004] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:37:15,010] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:37:15,054] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-02-28 22:37:15,054] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-02-28 22:37:15,055] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:403)
[2025-02-28 22:37:15,055] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:376)
[2025-02-28 22:37:15,064] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:37:15,065] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-02-28 22:37:15,069] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-02-28 22:37:15,069] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-02-28 22:37:15,081] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-02-28 22:37:15,083] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=3, memberId='connect-211.226.118.18:8083-19f4b355-c514-4f30-a6fe-ec6e414e266c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-02-28 22:37:15,113] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=3, memberId='connect-211.226.118.18:8083-19f4b355-c514-4f30-a6fe-ec6e414e266c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-02-28 22:37:15,114] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Joined group at generation 3 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-211.226.118.18:8083-19f4b355-c514-4f30-a6fe-ec6e414e266c', leaderUrl='http://211.226.118.18:8083/', offset=7, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-02-28 22:37:15,114] WARN [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1753)
[2025-02-28 22:37:15,114] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 7, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1826)
[2025-02-28 22:37:15,118] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 7 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1853)
[2025-02-28 22:37:15,118] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 7 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-02-28 22:37:15,119] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-02-28 22:37:15,223] INFO Started o.e.j.s.ServletContextHandler@a2fb8a5{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-02-28 22:37:15,223] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-02-28 22:37:15,224] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-02-28 22:39:22,086] ERROR Uncaught exception in REST call to /connectors (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
java.lang.NullPointerException: Cannot invoke "org.apache.kafka.connect.runtime.rest.entities.CreateConnectorRequest.name()" because "createRequest" is null
	at org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource.createConnector(ConnectorsResource.java:143)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:842)
[2025-02-28 22:39:22,135] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:39:22 +0000] "POST /connectors HTTP/1.1" 500 159 "-" "curl/8.10.1" 83 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:40:08,746] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:40:08 +0000] "GET /connectors HTTP/1.1" 200 2 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36" 8 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:40:08,898] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:40:08 +0000] "GET /favicon.ico HTTP/1.1" 404 49 "http://localhost:8083/connectors" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:40:39,032] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:40:39 +0000] "GET /connectors HTTP/1.1" 200 2 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:41:02,140] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = chat
	database = chat
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = chat
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2025-02-28 22:41:02,145] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = chat
	database = chat
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = chat
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2025-02-28 22:41:02,192] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.7.2"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/17.0.11+7-LTS-207"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='admin', source='admin', password=<hidden>, mechanismProperties=<hidden>}, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@1294af0d]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[com.mongodb.kafka.connect.util.ConnectionValidator$1@20e3727e]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2025-02-28 22:41:02,210] INFO Opened connection [connectionId{localValue:1, serverValue:2}] to localhost:27017 (org.mongodb.driver.connection:71)
[2025-02-28 22:41:02,210] INFO Opened connection [connectionId{localValue:2, serverValue:1}] to localhost:27017 (org.mongodb.driver.connection:71)
[2025-02-28 22:41:02,210] INFO Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=21769700} (org.mongodb.driver.cluster:71)
[2025-02-28 22:41:02,300] INFO Opened connection [connectionId{localValue:3, serverValue:3}] to localhost:27017 (org.mongodb.driver.connection:71)
[2025-02-28 22:41:02,320] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-02-28 22:41:02,337] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-02-28 22:41:02,342] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-02-28 22:41:02,344] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-02-28 22:41:02,346] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=4, memberId='connect-211.226.118.18:8083-19f4b355-c514-4f30-a6fe-ec6e414e266c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-02-28 22:41:02,351] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=4, memberId='connect-211.226.118.18:8083-19f4b355-c514-4f30-a6fe-ec6e414e266c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-02-28 22:41:02,351] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Joined group at generation 4 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-211.226.118.18:8083-19f4b355-c514-4f30-a6fe-ec6e414e266c', leaderUrl='http://211.226.118.18:8083/', offset=8, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-02-28 22:41:02,351] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:41:02 +0000] "POST /connectors/ HTTP/1.1" 201 396 "-" "curl/8.10.1" 275 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:41:02,351] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 8 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-02-28 22:41:02,353] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-02-28 22:41:02,355] INFO [chat-connector|worker] Creating connector chat-connector of type com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-02-28 22:41:02,355] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-02-28 22:41:02,356] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-02-28 22:41:02,359] INFO [chat-connector|worker] Instantiated connector chat-connector with version 1.11.0 of type class com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-02-28 22:41:02,359] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-02-28 22:41:02,360] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-02-28 22:41:02,365] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-02-28 22:41:02,366] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-02-28 22:41:02,375] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-02-28 22:41:02,376] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-02-28 22:41:02,377] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-02-28 22:41:02,378] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=5, memberId='connect-211.226.118.18:8083-19f4b355-c514-4f30-a6fe-ec6e414e266c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-02-28 22:41:02,382] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=5, memberId='connect-211.226.118.18:8083-19f4b355-c514-4f30-a6fe-ec6e414e266c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-02-28 22:41:02,383] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Joined group at generation 5 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-211.226.118.18:8083-19f4b355-c514-4f30-a6fe-ec6e414e266c', leaderUrl='http://211.226.118.18:8083/', offset=10, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-02-28 22:41:02,384] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 10 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-02-28 22:41:02,385] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-02-28 22:41:02,387] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-02-28 22:41:02,387] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-02-28 22:41:02,388] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-02-28 22:41:02,389] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.sink.MongoSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-02-28 22:41:02,389] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 1.11.0 of type com.mongodb.kafka.connect.sink.MongoSinkTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-02-28 22:41:02,390] INFO [chat-connector|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-02-28 22:41:02,390] INFO [chat-connector|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-02-28 22:41:02,391] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task chat-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:641)
[2025-02-28 22:41:02,391] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task chat-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:647)
[2025-02-28 22:41:02,391] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-02-28 22:41:02,393] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-02-28 22:41:02,394] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-02-28 22:41:02,395] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-02-28 22:41:02,396] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-28 22:41:02,402] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:41:02,410] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-28 22:41:02,410] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:41:02,411] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:41:02,411] INFO [chat-connector|task-0] Kafka startTimeMs: 1740750062410 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:41:02,418] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-02-28 22:41:02,418] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-02-28 22:41:02,418] INFO [chat-connector|task-0] Starting MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:66)
[2025-02-28 22:41:02,419] INFO [chat-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = chat
	database = chat
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = chat
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2025-02-28 22:41:02,423] INFO [chat-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|mongo-kafka|sink", "version": "4.7.2|1.11.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/17.0.11+7-LTS-207"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='admin', source='admin', password=<hidden>, mechanismProperties=<hidden>}, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@1294af0d]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2025-02-28 22:41:02,426] INFO [chat-connector|task-0] Errant record reporter not configured. (com.mongodb.kafka.connect.sink.MongoSinkTask:138)
[2025-02-28 22:41:02,426] INFO [chat-connector|task-0] Opened connection [connectionId{localValue:5, serverValue:4}] to localhost:27017 (org.mongodb.driver.connection:71)
[2025-02-28 22:41:02,426] INFO [chat-connector|task-0] Opened connection [connectionId{localValue:4, serverValue:5}] to localhost:27017 (org.mongodb.driver.connection:71)
[2025-02-28 22:41:02,427] INFO [chat-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=2473300} (org.mongodb.driver.cluster:71)
[2025-02-28 22:41:02,431] INFO [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:330)
[2025-02-28 22:41:02,432] INFO [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:214)
[2025-02-28 22:41:02,436] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:41:02,436] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-02-28 22:41:02,437] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-02-28 22:41:02,442] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: need to re-join with the given member-id: connector-consumer-chat-connector-0-e273b05e-a213-45d9-a696-e5b122b82a4b (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-02-28 22:41:02,443] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-02-28 22:41:02,444] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-chat-connector-0-e273b05e-a213-45d9-a696-e5b122b82a4b', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-02-28 22:41:02,450] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Finished assignment for group at generation 1: {connector-consumer-chat-connector-0-e273b05e-a213-45d9-a696-e5b122b82a4b=Assignment(partitions=[chat-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:659)
[2025-02-28 22:41:02,453] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-chat-connector-0-e273b05e-a213-45d9-a696-e5b122b82a4b', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-02-28 22:41:02,453] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Notifying assignor about the new Assignment(partitions=[chat-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:319)
[2025-02-28 22:41:02,453] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Adding newly assigned partitions: chat-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:56)
[2025-02-28 22:41:02,456] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Found no committed offset for partition chat-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1502)
[2025-02-28 22:41:02,459] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting offset for partition chat-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:41:11,047] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:41:11 +0000] "GET /connectors HTTP/1.1" 200 18 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:41:34,988] ERROR Uncaught exception in REST call to /connectors/ (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.debezium.connector.mysql.MySqlConnector, available connectors are: PluginDesc{klass=class com.mongodb.kafka.connect.MongoSinkConnector, name='com.mongodb.kafka.connect.MongoSinkConnector', version='1.11.0', encodedVersion=1.11.0, type=sink, typeName='sink', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/'}, PluginDesc{klass=class com.mongodb.kafka.connect.MongoSourceConnector, name='com.mongodb.kafka.connect.MongoSourceConnector', version='1.11.0', encodedVersion=1.11.0, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.7.2', encodedVersion=3.7.2, type=sink, typeName='sink', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.7.2', encodedVersion=3.7.2, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:320)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:291)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$7(AbstractHerder.java:756)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1708)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:756)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:501)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$3(AbstractHerder.java:413)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
[2025-02-28 22:41:34,991] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:41:34 +0000] "POST /connectors/ HTTP/1.1" 500 3309 "-" "curl/8.10.1" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:42:14,747] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:43:06,755] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:43:06 +0000] "GET /connectors-plugin HTTP/1.1" 404 49 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:43:09,404] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:43:09 +0000] "GET /connectors-plugins HTTP/1.1" 404 49 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:43:56,162] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:43:56 +0000] "GET /connector-plugins HTTP/1.1" 200 692 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:45:10,785] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2025-02-28 22:45:10,785] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:354)
[2025-02-28 22:45:10,788] INFO Stopped http_8083@d08f85a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2025-02-28 22:45:10,788] INFO Stopped o.e.j.s.ServletContextHandler@a2fb8a5{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2025-02-28 22:45:10,789] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2025-02-28 22:45:10,790] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:383)
[2025-02-28 22:45:10,790] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:831)
[2025-02-28 22:45:10,791] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2025-02-28 22:45:10,791] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-02-28 22:45:10,791] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-02-28 22:45:10,791] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-02-28 22:45:10,793] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-02-28 22:45:10,793] INFO [chat-connector|task-0] Stopping MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:124)
[2025-02-28 22:45:10,795] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Revoke previously assigned partitions chat-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:78)
[2025-02-28 22:45:10,795] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Member connector-consumer-chat-connector-0-e273b05e-a213-45d9-a696-e5b122b82a4b sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1163)
[2025-02-28 22:45:10,796] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-02-28 22:45:10,796] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-02-28 22:45:11,131] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:45:11,132] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:11,132] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:11,132] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:45:11,134] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:45:11,136] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Member connect-211.226.118.18:8083-19f4b355-c514-4f30-a6fe-ec6e414e266c sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1163)
[2025-02-28 22:45:11,136] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1055)
[2025-02-28 22:45:11,136] WARN [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1140)
[2025-02-28 22:45:11,136] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:45:11,136] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:11,137] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:45:11,137] INFO App info kafka.connect for connect-211.226.118.18:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:45:11,139] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:299)
[2025-02-28 22:45:11,139] INFO [Producer clientId=connect-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2025-02-28 22:45:11,141] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:45:11,141] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:11,141] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:11,142] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:45:11,142] INFO App info kafka.producer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:45:11,142] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-02-28 22:45:11,143] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-02-28 22:45:11,643] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:45:11,643] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:11,643] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:11,644] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:45:11,646] INFO App info kafka.consumer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:45:11,646] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:323)
[2025-02-28 22:45:11,647] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:408)
[2025-02-28 22:45:11,647] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:299)
[2025-02-28 22:45:11,647] INFO [Producer clientId=connect-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2025-02-28 22:45:11,649] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:45:11,649] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:11,649] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:11,649] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:45:11,649] INFO App info kafka.producer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:45:11,650] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-02-28 22:45:11,650] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-02-28 22:45:12,157] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:45:12,157] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:12,157] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:12,157] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:45:12,159] INFO App info kafka.consumer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:45:12,159] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:323)
[2025-02-28 22:45:12,159] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:414)
[2025-02-28 22:45:12,160] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:248)
[2025-02-28 22:45:12,160] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:269)
[2025-02-28 22:45:12,161] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:299)
[2025-02-28 22:45:12,161] INFO [Producer clientId=connect-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2025-02-28 22:45:12,163] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:45:12,163] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:12,163] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:12,163] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:45:12,164] INFO App info kafka.producer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:45:12,164] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-02-28 22:45:12,164] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-02-28 22:45:12,556] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:45:12,557] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:12,557] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:12,557] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:45:12,559] INFO App info kafka.consumer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:45:12,559] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:323)
[2025-02-28 22:45:12,559] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:277)
[2025-02-28 22:45:12,559] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:45:12,559] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:12,559] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:45:12,560] INFO App info kafka.connect for 211.226.118.18:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:45:12,560] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:269)
[2025-02-28 22:45:12,561] INFO App info kafka.admin.client for connect-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:45:12,562] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:45:12,562] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:12,562] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:45:12,562] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:386)
[2025-02-28 22:45:12,563] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:838)
[2025-02-28 22:45:12,563] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2025-02-28 22:45:31,345] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-02-28 22:45:31,349] INFO WorkerInfo values: 
	jvm.args = -Xmx256M, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2/logs, -Dlog4j.configuration=file:E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2/config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 17.0.11, 17.0.11+7-LTS-207
	jvm.classpath = E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\activation-1.1.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\aopalliance-repackaged-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\argparse4j-0.7.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\audience-annotations-0.12.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\caffeine-2.9.3.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\checker-qual-3.19.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-beanutils-1.9.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-cli-1.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-collections-3.2.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-digester-2.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-io-2.14.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-lang3-3.8.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-logging-1.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-validator-1.7.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-api-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-basic-auth-extension-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-file-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-json-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-mirror-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-mirror-client-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-runtime-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-transforms-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\error_prone_annotations-2.10.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-api-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-locator-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-utils-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-annotations-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-core-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-databind-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-dataformat-csv-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-datatype-jdk8-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-jaxrs-base-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-jaxrs-json-provider-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-module-jaxb-annotations-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-module-scala_2.12-2.16.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.activation-api-1.2.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.annotation-api-1.3.5.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.inject-2.6.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.validation-api-2.0.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.ws.rs-api-2.1.6.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.xml.bind-api-2.3.3.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javassist-3.29.2-GA.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.activation-api-1.2.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.annotation-api-1.3.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.servlet-api-3.1.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.ws.rs-api-2.1.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jaxb-api-2.3.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-client-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-common-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-container-servlet-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-container-servlet-core-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-hk2-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-server-2.39.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-client-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-continuation-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-http-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-io-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-security-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-server-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-servlet-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-servlets-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-util-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-util-ajax-9.4.56.v20240826.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jline-3.25.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jopt-simple-5.0.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jose4j-0.9.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jsr305-3.0.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-clients-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-group-coordinator-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-log4j-appender-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-metadata-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-raft-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-server-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-server-common-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-shell-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-storage-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-storage-api-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-examples-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-scala_2.12-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-test-utils-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-tools-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-tools-api-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka_2.12-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\lz4-java-1.8.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\maven-artifact-3.8.8.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\metrics-core-2.2.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\metrics-core-4.1.12.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-buffer-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-codec-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-common-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-handler-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-resolver-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-classes-epoll-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-native-epoll-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-native-unix-common-4.1.115.Final.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\opentelemetry-proto-1.0.0-alpha.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\osgi-resource-locator-1.0.3.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\paranamer-2.8.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\pcollections-4.0.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\plexus-utils-3.3.1.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\protobuf-java-3.25.5.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\reflections-0.10.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\reload4j-1.2.25.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\rocksdbjni-7.9.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-collection-compat_2.12-2.10.0.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-java8-compat_2.12-1.0.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-library-2.12.18.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-logging_2.12-3.9.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-reflect-2.12.18.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\slf4j-api-1.7.36.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\slf4j-reload4j-1.7.36.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\snappy-java-1.1.10.5.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\swagger-annotations-2.2.8.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\trogdor-3.7.2.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zookeeper-3.8.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zookeeper-jute-3.8.4.jar;E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zstd-jni-1.5.6-4.jar;
	os.spec = Windows 11, amd64, 10.0
	os.vcpus = 24
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-02-28 22:45:31,353] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-02-28 22:45:31,390] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\bin (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:45:31,532] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/bin/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:45:31,533] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\config (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:45:31,538] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/config/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:45:31,539] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:45:31,569] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2025-02-28 22:45:31,604] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:45:31,607] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:45:31,730] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:45:31,730] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\licenses (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:45:31,734] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/licenses/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:45:31,735] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\logs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:45:31,739] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/logs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:45:31,739] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\site-docs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:45:31,744] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/site-docs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:45:31,745] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:45:31,750] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@2b193f2d (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:45:31,751] INFO Scanning plugins with ServiceLoaderScanner took 362 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-02-28 22:45:31,753] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\bin (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:45:31,771] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/bin/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:45:31,772] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\config (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:45:31,774] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/config/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:45:31,774] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:45:32,535] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:45:32,536] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:45:33,322] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:45:33,323] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\licenses (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:45:33,324] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/licenses/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:45:33,324] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\logs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:45:33,325] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/logs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:45:33,325] INFO Loading plugin from: E:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\site-docs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:45:33,326] INFO Registered loader: PluginClassLoader{pluginLocation=file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/site-docs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:45:33,327] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-02-28 22:45:33,837] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@2b193f2d (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-02-28 22:45:33,838] INFO Scanning plugins with ReflectionScanner took 2085 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-02-28 22:45:33,843] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/	com.mongodb.kafka.connect.MongoSinkConnector	sink	1.11.0
file:/E:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/	com.mongodb.kafka.connect.MongoSourceConnector	source	1.11.0
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-02-28 22:45:33,846] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,846] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,846] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,847] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,847] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,847] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,847] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,848] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,848] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,848] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,848] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,849] INFO Added plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,849] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,849] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,849] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,850] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,850] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,850] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,851] INFO Added plugin 'io.debezium.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,851] INFO Added plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,852] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,852] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,852] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,852] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,853] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,853] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,853] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,853] INFO Added plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,854] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,854] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,854] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,855] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,855] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,855] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,855] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,856] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,856] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,856] INFO Added plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,856] INFO Added plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,857] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,857] INFO Added plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,857] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,857] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,858] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,858] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,858] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,858] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,859] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,859] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,859] INFO Added plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,860] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,860] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,861] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,861] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,861] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,862] INFO Added plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,862] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,862] INFO Added plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,862] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,862] INFO Added plugin 'io.debezium.connector.mysql.rest.DebeziumMySqlConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,863] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,863] INFO Added plugin 'io.debezium.connector.mysql.transforms.ReadToInsertEvent' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,863] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,863] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,864] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,864] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,864] INFO Added plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,864] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,865] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-02-28 22:45:33,868] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,868] INFO Added alias 'CloudEventsConverter' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,868] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,868] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,868] INFO Added alias 'MySql' to plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,868] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,868] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,868] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,869] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,869] INFO Added alias 'MySqlConnector' to plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,869] INFO Added alias 'HeaderToValue' to plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,869] INFO Added alias 'PartitionRouting' to plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,869] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,870] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,870] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,870] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,870] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,870] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,871] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,871] INFO Added alias 'ExtractSchemaToNewRecord' to plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,871] INFO Added alias 'BinaryData' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,872] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,872] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,873] INFO Added alias 'ReadToInsertEvent' to plugin 'io.debezium.connector.mysql.transforms.ReadToInsertEvent' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,873] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,874] INFO Added alias 'CloudEvents' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,874] INFO Added alias 'TimezoneConverter' to plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,874] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,874] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,874] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,875] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,875] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,876] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,876] INFO Added alias 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,876] INFO Added alias 'MongoSinkConnector' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,876] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,876] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,877] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,877] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,877] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,877] INFO Added alias 'ExtractChangedRecordState' to plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,877] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,878] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,878] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,878] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,878] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,879] INFO Added alias 'DebeziumMySql' to plugin 'io.debezium.connector.mysql.rest.DebeziumMySqlConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,879] INFO Added alias 'MongoSourceConnector' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,879] INFO Added alias 'DebeziumMySqlConnectRestExtension' to plugin 'io.debezium.connector.mysql.rest.DebeziumMySqlConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,879] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,879] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,880] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,880] INFO Added alias 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,880] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,880] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,881] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,881] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,881] INFO Added alias 'SchemaChangeEventFilter' to plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,881] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,882] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,882] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,882] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,882] INFO Added alias 'ActivateTracingSpan' to plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,883] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,883] INFO Added alias 'BinaryDataConverter' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,883] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,883] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,883] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,883] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,884] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,884] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,884] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,884] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-02-28 22:45:33,914] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-02-28 22:45:33,920] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-02-28 22:45:33,922] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-02-28 22:45:34,015] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-02-28 22:45:34,016] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:45:34,016] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:45:34,017] INFO Kafka startTimeMs: 1740750334016 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:45:34,213] INFO Kafka cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-02-28 22:45:34,214] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-02-28 22:45:34,218] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-02-28 22:45:34,218] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-02-28 22:45:34,218] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-02-28 22:45:34,224] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-02-28 22:45:34,230] INFO Logging initialized @3376ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-02-28 22:45:34,264] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-02-28 22:45:34,265] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-02-28 22:45:34,289] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 17.0.11+7-LTS-207 (org.eclipse.jetty.server.Server:375)
[2025-02-28 22:45:34,328] INFO Started http_8083@e0f2686{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-02-28 22:45:34,328] INFO Started @3473ms (org.eclipse.jetty.server.Server:415)
[2025-02-28 22:45:34,345] INFO Advertised URI: http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-28 22:45:34,346] INFO REST server listening at http://211.226.118.18:8083/, advertising URL http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-02-28 22:45:34,346] INFO Advertised URI: http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-28 22:45:34,346] INFO REST admin endpoints at http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-02-28 22:45:34,347] INFO Advertised URI: http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-28 22:45:34,347] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-02-28 22:45:34,354] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-02-28 22:45:34,366] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:45:34,366] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:45:34,366] INFO Kafka startTimeMs: 1740750334366 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:45:34,369] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-02-28 22:45:34,370] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-02-28 22:45:34,382] INFO Advertised URI: http://211.226.118.18:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-02-28 22:45:34,399] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:45:34,400] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:45:34,400] INFO Kafka startTimeMs: 1740750334399 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:45:34,401] INFO Kafka Connect worker initialization took 3055ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-02-28 22:45:34,402] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-02-28 22:45:34,404] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-02-28 22:45:34,404] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:369)
[2025-02-28 22:45:34,405] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:231)
[2025-02-28 22:45:34,405] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:240)
[2025-02-28 22:45:34,405] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-02-28 22:45:34,406] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-02-28 22:45:34,415] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-02-28 22:45:34,416] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:45:34,416] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:45:34,416] INFO Kafka startTimeMs: 1740750334416 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:45:34,430] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-02-28 22:45:34,445] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-02-28 22:45:34,467] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-02-28 22:45:34,468] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-02-28 22:45:34,468] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2025-02-28 22:45:34,472] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:45:34,496] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-02-28 22:45:34,496] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:45:34,497] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:45:34,497] INFO Kafka startTimeMs: 1740750334496 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:45:34,508] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:45:34,513] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-28 22:45:34,528] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:45:34,557] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-28 22:45:34,557] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:45:34,558] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:45:34,558] INFO Kafka startTimeMs: 1740750334557 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:45:34,564] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:45:34,568] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-02-28 22:45:34,573] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,574] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,574] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,574] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,574] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,574] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,575] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,575] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,576] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,576] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,576] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,577] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,577] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,578] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,578] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,579] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,579] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,579] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,580] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,580] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,580] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,581] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,581] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,581] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,581] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,614] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,615] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,615] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,615] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,616] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,616] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,616] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,616] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,617] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,617] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,617] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,617] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,617] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,619] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,619] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,619] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,619] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,619] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,619] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,620] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,620] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,620] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,620] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,621] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,621] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,622] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-02-28 22:45:34,622] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-02-28 22:45:34,622] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:257)
[2025-02-28 22:45:34,623] INFO Worker started (org.apache.kafka.connect.runtime.Worker:241)
[2025-02-28 22:45:34,623] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-02-28 22:45:34,627] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-02-28 22:45:34,633] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:45:34,638] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-02-28 22:45:34,638] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:45:34,638] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:45:34,639] INFO Kafka startTimeMs: 1740750334638 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:45:34,639] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-28 22:45:34,640] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:45:34,643] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:45:34,649] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-28 22:45:34,649] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:45:34,649] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:45:34,650] INFO Kafka startTimeMs: 1740750334649 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:45:34,653] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:45:34,654] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-02-28 22:45:34,654] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,654] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,655] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,655] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,655] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,660] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,661] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,661] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,662] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,662] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,699] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-02-28 22:45:34,699] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-02-28 22:45:34,702] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:379)
[2025-02-28 22:45:34,702] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-02-28 22:45:34,707] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-02-28 22:45:34,711] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:45:34,717] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-02-28 22:45:34,718] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:45:34,718] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:45:34,718] INFO Kafka startTimeMs: 1740750334718 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:45:34,719] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-28 22:45:34,720] INFO [Producer clientId=connect-cluster-configs] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:45:34,723] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:45:34,728] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-28 22:45:34,729] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:45:34,729] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:45:34,729] INFO Kafka startTimeMs: 1740750334729 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:45:34,733] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:45:34,733] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-02-28 22:45:34,734] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-02-28 22:45:34,738] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:45:34,747] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-02-28 22:45:34,747] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-02-28 22:45:34,748] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:403)
[2025-02-28 22:45:34,748] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:376)
[2025-02-28 22:45:34,753] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:45:34,754] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-02-28 22:45:34,758] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-02-28 22:45:34,758] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-02-28 22:45:34,768] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-02-28 22:45:34,771] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=7, memberId='connect-211.226.118.18:8083-0f61ec4e-b23b-4a11-86aa-6995c778833a', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-02-28 22:45:34,801] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=7, memberId='connect-211.226.118.18:8083-0f61ec4e-b23b-4a11-86aa-6995c778833a', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-02-28 22:45:34,802] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Joined group at generation 7 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-211.226.118.18:8083-0f61ec4e-b23b-4a11-86aa-6995c778833a', leaderUrl='http://211.226.118.18:8083/', offset=10, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-02-28 22:45:34,804] WARN [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1753)
[2025-02-28 22:45:34,804] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 10, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1826)
[2025-02-28 22:45:34,807] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 10 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1853)
[2025-02-28 22:45:34,807] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 10 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-02-28 22:45:34,808] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-02-28 22:45:34,809] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-02-28 22:45:34,822] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-02-28 22:45:34,822] INFO [chat-connector|worker] Creating connector chat-connector of type com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-02-28 22:45:34,823] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-02-28 22:45:34,823] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-02-28 22:45:34,826] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-02-28 22:45:34,826] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-02-28 22:45:34,829] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.sink.MongoSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-02-28 22:45:34,830] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 1.11.0 of type com.mongodb.kafka.connect.sink.MongoSinkTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-02-28 22:45:34,832] INFO [chat-connector|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-02-28 22:45:34,833] INFO [chat-connector|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-02-28 22:45:34,833] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task chat-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:641)
[2025-02-28 22:45:34,834] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task chat-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:647)
[2025-02-28 22:45:34,834] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-02-28 22:45:34,835] INFO [chat-connector|worker] Instantiated connector chat-connector with version 1.11.0 of type class com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-02-28 22:45:34,836] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-02-28 22:45:34,838] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-02-28 22:45:34,840] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-02-28 22:45:34,841] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-02-28 22:45:34,844] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-02-28 22:45:34,849] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-02-28 22:45:34,854] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-02-28 22:45:34,855] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-02-28 22:45:34,855] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-02-28 22:45:34,855] INFO [chat-connector|task-0] Kafka startTimeMs: 1740750334855 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-02-28 22:45:34,870] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-02-28 22:45:34,871] INFO [chat-connector|task-0] Starting MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:66)
[2025-02-28 22:45:34,872] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-02-28 22:45:34,877] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-02-28 22:45:34,878] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-02-28 22:45:34,922] INFO Started o.e.j.s.ServletContextHandler@578781f7{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-02-28 22:45:34,923] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-02-28 22:45:34,923] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-02-28 22:45:34,950] INFO [chat-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = chat
	database = chat
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = chat
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2025-02-28 22:45:35,001] INFO [chat-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|mongo-kafka|sink", "version": "4.7.2|1.11.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/17.0.11+7-LTS-207"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='admin', source='admin', password=<hidden>, mechanismProperties=<hidden>}, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@119625ce]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2025-02-28 22:45:35,004] INFO [chat-connector|task-0] Errant record reporter not configured. (com.mongodb.kafka.connect.sink.MongoSinkTask:138)
[2025-02-28 22:45:35,011] INFO [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:330)
[2025-02-28 22:45:35,012] INFO [chat-connector|task-0] Opened connection [connectionId{localValue:1, serverValue:7}] to localhost:27017 (org.mongodb.driver.connection:71)
[2025-02-28 22:45:35,012] INFO [chat-connector|task-0] Opened connection [connectionId{localValue:2, serverValue:6}] to localhost:27017 (org.mongodb.driver.connection:71)
[2025-02-28 22:45:35,012] INFO [chat-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=13033100} (org.mongodb.driver.cluster:71)
[2025-02-28 22:45:35,013] INFO [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:214)
[2025-02-28 22:45:35,015] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Cluster ID: LKOzFE5wSfqrQbz5XXHkDQ (org.apache.kafka.clients.Metadata:356)
[2025-02-28 22:45:35,016] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-02-28 22:45:35,018] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-02-28 22:45:35,024] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: need to re-join with the given member-id: connector-consumer-chat-connector-0-e93ef8fe-8a95-4c96-88b2-fb74cc511ebd (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-02-28 22:45:35,025] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-02-28 22:45:35,026] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-chat-connector-0-e93ef8fe-8a95-4c96-88b2-fb74cc511ebd', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-02-28 22:45:35,031] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Finished assignment for group at generation 3: {connector-consumer-chat-connector-0-e93ef8fe-8a95-4c96-88b2-fb74cc511ebd=Assignment(partitions=[chat-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:659)
[2025-02-28 22:45:35,036] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Successfully synced group in generation Generation{generationId=3, memberId='connector-consumer-chat-connector-0-e93ef8fe-8a95-4c96-88b2-fb74cc511ebd', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-02-28 22:45:35,036] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Notifying assignor about the new Assignment(partitions=[chat-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:319)
[2025-02-28 22:45:35,036] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Adding newly assigned partitions: chat-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:56)
[2025-02-28 22:45:35,039] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Found no committed offset for partition chat-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1502)
[2025-02-28 22:45:35,042] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting offset for partition chat-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-02-28 22:46:22,245] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:46:22 +0000] "GET /connector-plugins HTTP/1.1" 200 787 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36" 58 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:46:33,162] INFO Loading the custom source info struct maker plugin: io.debezium.connector.mysql.MySqlSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2025-02-28 22:46:33,380] INFO Using 'SHOW MASTER STATUS' to get binary log status (io.debezium.connector.mysql.jdbc.MySqlConnection:41)
[2025-02-28 22:46:33,382] ERROR Failed testing connection for jdbc:mysql://localhost:3306/?useInformationSchema=true&nullCatalogMeansCurrent=false&useUnicode=true&characterEncoding=UTF-8&characterSetResults=UTF-8&zeroDateTimeBehavior=CONVERT_TO_NULL&connectTimeout=30000 with user 'admin' (io.debezium.connector.binlog.BinlogConnector:70)
java.sql.SQLException: The server time zone value '????? ???' is unrecognized or represents more than one time zone. You must configure either the server or JDBC driver (via the 'connectionTimeZone' configuration property) to use a more specific time zone value if you want to utilize time zone support.
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:89)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:81)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:55)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:65)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:67)
	at com.mysql.cj.jdbc.StatementImpl.executeInternal(StatementImpl.java:837)
	at com.mysql.cj.jdbc.StatementImpl.execute(StatementImpl.java:685)
	at io.debezium.jdbc.JdbcConnection.lambda$execute$3(JdbcConnection.java:431)
	at io.debezium.jdbc.JdbcConnection.execute(JdbcConnection.java:452)
	at io.debezium.jdbc.JdbcConnection.execute(JdbcConnection.java:425)
	at io.debezium.connector.binlog.BinlogConnector.validateConnection(BinlogConnector.java:65)
	at io.debezium.connector.common.RelationalBaseSourceConnector.validate(RelationalBaseSourceConnector.java:42)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:553)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$3(AbstractHerder.java:413)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: com.mysql.cj.exceptions.InvalidConnectionAttributeException: The server time zone value '????? ???' is unrecognized or represents more than one time zone. You must configure either the server or JDBC driver (via the 'connectionTimeZone' configuration property) to use a more specific time zone value if you want to utilize time zone support.
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)
	at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:52)
	at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:76)
	at com.mysql.cj.util.TimeUtil.getCanonicalTimeZone(TimeUtil.java:170)
	at com.mysql.cj.protocol.a.NativeServerSession.getSessionTimeZone(NativeServerSession.java:348)
	at com.mysql.cj.jdbc.StatementImpl.executeInternal(StatementImpl.java:752)
	... 13 more
[2025-02-28 22:46:33,388] INFO Connection gracefully closed (io.debezium.jdbc.JdbcConnection:983)
[2025-02-28 22:46:33,389] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-02-28 22:46:33,401] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:46:33 +0000] "POST /connectors/ HTTP/1.1" 400 523 "-" "curl/8.10.1" 298 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:47:10,528] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:47:10 +0000] "GET /connector-plugins HTTP/1.1" 200 787 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:47:14,157] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:47:14 +0000] "GET /connector-plugins HTTP/1.1" 200 787 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:47:17,030] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:47:17 +0000] "GET /connector-plugins HTTP/1.1" 200 787 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:47:29,080] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:47:29 +0000] "GET /connector-plugins HTTP/1.1" 200 787 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:50:34,437] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:54:34,592] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:54:34,592] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:54:34,730] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:54:34,792] INFO [Worker clientId=connect-211.226.118.18:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:54:34,808] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:54:34,839] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:54:34,839] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:54:35,354] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:55:34,454] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-02-28 22:56:45,935] INFO Loading the custom source info struct maker plugin: io.debezium.connector.mysql.MySqlSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2025-02-28 22:56:45,956] INFO Using 'SHOW MASTER STATUS' to get binary log status (io.debezium.connector.mysql.jdbc.MySqlConnection:41)
[2025-02-28 22:56:45,957] ERROR Failed testing connection for jdbc:mysql://localhost:3306/?useInformationSchema=true&nullCatalogMeansCurrent=false&useUnicode=true&characterEncoding=UTF-8&characterSetResults=UTF-8&zeroDateTimeBehavior=CONVERT_TO_NULL&connectTimeout=30000 with user 'admin' (io.debezium.connector.binlog.BinlogConnector:70)
java.sql.SQLException: The server time zone value '????? ???' is unrecognized or represents more than one time zone. You must configure either the server or JDBC driver (via the 'connectionTimeZone' configuration property) to use a more specific time zone value if you want to utilize time zone support.
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:89)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:81)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:55)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:65)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:67)
	at com.mysql.cj.jdbc.StatementImpl.executeInternal(StatementImpl.java:837)
	at com.mysql.cj.jdbc.StatementImpl.execute(StatementImpl.java:685)
	at io.debezium.jdbc.JdbcConnection.lambda$execute$3(JdbcConnection.java:431)
	at io.debezium.jdbc.JdbcConnection.execute(JdbcConnection.java:452)
	at io.debezium.jdbc.JdbcConnection.execute(JdbcConnection.java:425)
	at io.debezium.connector.binlog.BinlogConnector.validateConnection(BinlogConnector.java:65)
	at io.debezium.connector.common.RelationalBaseSourceConnector.validate(RelationalBaseSourceConnector.java:42)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:553)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$3(AbstractHerder.java:413)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: com.mysql.cj.exceptions.InvalidConnectionAttributeException: The server time zone value '????? ???' is unrecognized or represents more than one time zone. You must configure either the server or JDBC driver (via the 'connectionTimeZone' configuration property) to use a more specific time zone value if you want to utilize time zone support.
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)
	at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:52)
	at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:76)
	at com.mysql.cj.util.TimeUtil.getCanonicalTimeZone(TimeUtil.java:170)
	at com.mysql.cj.protocol.a.NativeServerSession.getSessionTimeZone(NativeServerSession.java:348)
	at com.mysql.cj.jdbc.StatementImpl.executeInternal(StatementImpl.java:752)
	... 13 more
[2025-02-28 22:56:45,961] INFO Connection gracefully closed (io.debezium.jdbc.JdbcConnection:983)
[2025-02-28 22:56:45,962] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-02-28 22:56:45,964] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:56:45 +0000] "POST /connectors/ HTTP/1.1" 400 523 "-" "curl/8.10.1" 32 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-02-28 22:59:12,957] INFO Loading the custom source info struct maker plugin: io.debezium.connector.mysql.MySqlSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2025-02-28 22:59:12,973] INFO Using 'SHOW MASTER STATUS' to get binary log status (io.debezium.connector.mysql.jdbc.MySqlConnection:41)
[2025-02-28 22:59:12,973] ERROR Failed testing connection for jdbc:mysql://127.0.0.1:3306/?useInformationSchema=true&nullCatalogMeansCurrent=false&useUnicode=true&characterEncoding=UTF-8&characterSetResults=UTF-8&zeroDateTimeBehavior=CONVERT_TO_NULL&connectTimeout=30000 with user 'admin' (io.debezium.connector.binlog.BinlogConnector:70)
java.sql.SQLException: The server time zone value '????? ???' is unrecognized or represents more than one time zone. You must configure either the server or JDBC driver (via the 'connectionTimeZone' configuration property) to use a more specific time zone value if you want to utilize time zone support.
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:89)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:81)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:55)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:65)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:67)
	at com.mysql.cj.jdbc.StatementImpl.executeInternal(StatementImpl.java:837)
	at com.mysql.cj.jdbc.StatementImpl.execute(StatementImpl.java:685)
	at io.debezium.jdbc.JdbcConnection.lambda$execute$3(JdbcConnection.java:431)
	at io.debezium.jdbc.JdbcConnection.execute(JdbcConnection.java:452)
	at io.debezium.jdbc.JdbcConnection.execute(JdbcConnection.java:425)
	at io.debezium.connector.binlog.BinlogConnector.validateConnection(BinlogConnector.java:65)
	at io.debezium.connector.common.RelationalBaseSourceConnector.validate(RelationalBaseSourceConnector.java:42)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:553)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$3(AbstractHerder.java:413)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: com.mysql.cj.exceptions.InvalidConnectionAttributeException: The server time zone value '????? ???' is unrecognized or represents more than one time zone. You must configure either the server or JDBC driver (via the 'connectionTimeZone' configuration property) to use a more specific time zone value if you want to utilize time zone support.
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)
	at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:52)
	at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:76)
	at com.mysql.cj.util.TimeUtil.getCanonicalTimeZone(TimeUtil.java:170)
	at com.mysql.cj.protocol.a.NativeServerSession.getSessionTimeZone(NativeServerSession.java:348)
	at com.mysql.cj.jdbc.StatementImpl.executeInternal(StatementImpl.java:752)
	... 13 more
[2025-02-28 22:59:12,977] INFO Connection gracefully closed (io.debezium.jdbc.JdbcConnection:983)
[2025-02-28 22:59:12,977] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-02-28 22:59:12,980] INFO [0:0:0:0:0:0:0:1] - - [28/2/2025:13:59:12 +0000] "POST /connectors/ HTTP/1.1" 400 523 "-" "curl/8.10.1" 26 (org.apache.kafka.connect.runtime.rest.RestServer:62)
