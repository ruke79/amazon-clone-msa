[2025-01-28 19:04:09,597] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:29:15,657] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-01-28 19:29:15,709] INFO WorkerInfo values: 
	jvm.args = -Xmx256M, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2/logs, -Dlog4j.configuration=file:F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2/config/connect-log4j.properties
	jvm.spec = Eclipse Adoptium, OpenJDK 64-Bit Server VM, 17.0.12, 17.0.12+7
	jvm.classpath = F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\activation-1.1.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\aopalliance-repackaged-2.6.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\argparse4j-0.7.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\audience-annotations-0.12.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\caffeine-2.9.3.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\checker-qual-3.19.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-beanutils-1.9.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-cli-1.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-collections-3.2.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-digester-2.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-io-2.14.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-lang3-3.8.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-logging-1.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-validator-1.7.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-api-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-basic-auth-extension-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-file-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-json-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-mirror-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-mirror-client-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-runtime-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-transforms-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\error_prone_annotations-2.10.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-api-2.6.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-locator-2.6.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-utils-2.6.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-annotations-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-core-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-databind-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-dataformat-csv-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-datatype-jdk8-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-jaxrs-base-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-jaxrs-json-provider-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-module-jaxb-annotations-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-module-scala_2.12-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.activation-api-1.2.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.annotation-api-1.3.5.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.inject-2.6.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.validation-api-2.0.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.ws.rs-api-2.1.6.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.xml.bind-api-2.3.3.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javassist-3.29.2-GA.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.activation-api-1.2.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.annotation-api-1.3.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.servlet-api-3.1.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.ws.rs-api-2.1.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jaxb-api-2.3.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-client-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-common-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-container-servlet-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-container-servlet-core-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-hk2-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-server-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-client-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-continuation-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-http-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-io-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-security-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-server-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-servlet-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-servlets-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-util-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-util-ajax-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jline-3.25.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jopt-simple-5.0.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jose4j-0.9.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jsr305-3.0.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-clients-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-group-coordinator-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-log4j-appender-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-metadata-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-raft-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-server-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-server-common-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-shell-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-storage-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-storage-api-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-examples-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-scala_2.12-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-test-utils-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-tools-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-tools-api-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka_2.12-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\lz4-java-1.8.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\maven-artifact-3.8.8.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\metrics-core-2.2.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\metrics-core-4.1.12.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-buffer-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-codec-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-common-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-handler-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-resolver-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-classes-epoll-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-native-epoll-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-native-unix-common-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\opentelemetry-proto-1.0.0-alpha.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\osgi-resource-locator-1.0.3.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\paranamer-2.8.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\pcollections-4.0.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\plexus-utils-3.3.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\protobuf-java-3.25.5.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\reflections-0.10.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\reload4j-1.2.25.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\rocksdbjni-7.9.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-collection-compat_2.12-2.10.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-java8-compat_2.12-1.0.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-library-2.12.18.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-logging_2.12-3.9.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-reflect-2.12.18.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\slf4j-api-1.7.36.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\slf4j-reload4j-1.7.36.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\snappy-java-1.1.10.5.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\swagger-annotations-2.2.8.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\trogdor-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zookeeper-3.8.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zookeeper-jute-3.8.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zstd-jni-1.5.6-4.jar;
	os.spec = Windows 10, amd64, 10.0
	os.vcpus = 6
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-01-28 19:29:15,719] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-01-28 19:29:16,476] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\bin (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:29:16,825] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/bin/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:29:16,827] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\config (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:29:16,835] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/config/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:29:16,836] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:29:17,463] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2025-01-28 19:29:17,529] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:29:17,534] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:29:17,682] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:29:17,682] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\licenses (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:29:17,688] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/licenses/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:29:17,688] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\logs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:29:17,709] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/logs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:29:17,710] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\site-docs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:29:17,715] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/site-docs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:29:17,715] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:29:17,723] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@66d3c617 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:29:17,724] INFO Scanning plugins with ServiceLoaderScanner took 1249 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-01-28 19:29:17,727] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\bin (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:29:17,755] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/bin/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:29:17,756] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\config (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:29:17,758] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/config/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:29:17,759] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:29:18,040] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:29:18,041] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:29:20,274] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:29:20,275] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\licenses (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:29:20,276] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/licenses/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:29:20,277] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\logs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:29:20,278] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/logs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:29:20,279] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\site-docs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:29:20,280] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/site-docs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:29:20,281] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:29:20,973] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@66d3c617 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:29:20,974] INFO Scanning plugins with ReflectionScanner took 3247 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-01-28 19:29:20,978] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/	io.debezium.connector.mongodb.MongoDbSinkConnector	sink	3.0.2.Final
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-01-28 19:29:20,983] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,985] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,986] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,986] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,986] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,987] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,989] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,991] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,992] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,992] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,993] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,993] INFO Added plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,995] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,995] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,996] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,996] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,996] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,997] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,997] INFO Added plugin 'io.debezium.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,998] INFO Added plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,998] INFO Added plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,998] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,998] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,999] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:20,999] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,000] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,000] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,001] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,001] INFO Added plugin 'io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,001] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,002] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,002] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,002] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,003] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,003] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,003] INFO Added plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,004] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,004] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,004] INFO Added plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,004] INFO Added plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,005] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,006] INFO Added plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,006] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,006] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,006] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,007] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,008] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,008] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,009] INFO Added plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,009] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,009] INFO Added plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,010] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,010] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,010] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,010] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,011] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,011] INFO Added plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,011] INFO Added plugin 'io.debezium.connector.mongodb.transforms.ExtractNewDocumentState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,011] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,012] INFO Added plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,012] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,012] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,013] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,013] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,013] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,013] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,014] INFO Added plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,014] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,015] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:29:21,017] INFO Added alias 'ExtractNewDocumentState' to plugin 'io.debezium.connector.mongodb.transforms.ExtractNewDocumentState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,018] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,018] INFO Added alias 'CloudEventsConverter' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,018] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,019] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,019] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,019] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,021] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,021] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,021] INFO Added alias 'HeaderToValue' to plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,022] INFO Added alias 'PartitionRouting' to plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,022] INFO Added alias 'MongoDbSink' to plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,022] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,022] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,023] INFO Added alias 'MongoDbConnector' to plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,023] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,023] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,024] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,024] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,024] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,024] INFO Added alias 'ExtractSchemaToNewRecord' to plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,025] INFO Added alias 'BinaryData' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,025] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,025] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,026] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,026] INFO Added alias 'CloudEvents' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,026] INFO Added alias 'TimezoneConverter' to plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,026] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,027] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,027] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,027] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,027] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,028] INFO Added alias 'DebeziumMongoDb' to plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,028] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,028] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,028] INFO Added alias 'DebeziumMongoDbConnectRestExtension' to plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,029] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,029] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,029] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,029] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,029] INFO Added alias 'ExtractChangedRecordState' to plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,030] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,030] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,030] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,030] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,031] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,031] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,031] INFO Added alias 'MongoDbSinkConnector' to plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,032] INFO Added alias 'MongoDb' to plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,032] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,032] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,033] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,033] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,034] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,034] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,034] INFO Added alias 'SchemaChangeEventFilter' to plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,036] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,037] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,037] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,037] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,038] INFO Added alias 'ActivateTracingSpan' to plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,038] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,038] INFO Added alias 'BinaryDataConverter' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,039] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,039] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,039] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,039] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,040] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,040] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,041] INFO Added alias 'MongoEventRouter' to plugin 'io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,041] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,042] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:29:21,136] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-01-28 19:29:21,145] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-01-28 19:29:21,147] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-01-28 19:29:21,225] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-01-28 19:29:21,226] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:29:21,227] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:29:21,227] INFO Kafka startTimeMs: 1738060161226 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:29:21,512] INFO Kafka cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-01-28 19:29:21,513] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:29:21,518] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:29:21,518] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:29:21,518] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:29:21,521] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-01-28 19:29:21,529] INFO Logging initialized @6427ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-01-28 19:29:21,556] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-01-28 19:29:21,556] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-01-28 19:29:21,572] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 17.0.12+7 (org.eclipse.jetty.server.Server:375)
[2025-01-28 19:29:21,593] INFO Started http_8083@136a5572{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-01-28 19:29:21,594] INFO Started @6492ms (org.eclipse.jetty.server.Server:415)
[2025-01-28 19:29:21,617] INFO Advertised URI: http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-01-28 19:29:21,617] INFO REST server listening at http://121.178.140.30:8083/, advertising URL http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-01-28 19:29:21,618] INFO Advertised URI: http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-01-28 19:29:21,618] INFO REST admin endpoints at http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-01-28 19:29:21,619] INFO Advertised URI: http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-01-28 19:29:21,619] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-01-28 19:29:21,624] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:29:21,636] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:29:21,636] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:29:21,637] INFO Kafka startTimeMs: 1738060161636 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:29:21,641] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:29:21,642] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:29:21,658] INFO Advertised URI: http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-01-28 19:29:21,681] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:29:21,682] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:29:21,682] INFO Kafka startTimeMs: 1738060161681 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:29:21,685] INFO Kafka Connect worker initialization took 6026ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-01-28 19:29:21,685] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-01-28 19:29:21,687] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-01-28 19:29:21,687] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:369)
[2025-01-28 19:29:21,689] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:231)
[2025-01-28 19:29:21,689] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:240)
[2025-01-28 19:29:21,690] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-01-28 19:29:21,690] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-01-28 19:29:21,701] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-01-28 19:29:21,701] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:29:21,701] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:29:21,702] INFO Kafka startTimeMs: 1738060161701 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:29:21,716] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-01-28 19:29:21,744] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-01-28 19:29:21,746] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-01-28 19:29:21,752] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-01-28 19:29:21,753] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2025-01-28 19:29:21,771] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:29:21,790] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-01-28 19:29:21,791] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:29:21,792] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:29:21,792] INFO Kafka startTimeMs: 1738060161791 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:29:21,799] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 19:29:21,800] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:29:21,818] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:29:21,861] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:29:21,862] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:29:21,862] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:29:21,862] INFO Kafka startTimeMs: 1738060161862 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:29:21,874] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 19:29:21,879] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-01-28 19:29:21,884] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,885] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,885] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,886] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,886] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,886] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,887] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,887] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,887] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,888] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,890] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,890] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,892] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,893] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,893] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,893] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,894] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,894] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,894] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,895] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,895] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,895] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,896] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,896] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,896] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:21,947] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,949] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,950] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,951] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,952] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,953] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,953] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,956] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,957] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,958] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,959] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,963] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,963] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,966] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,967] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,968] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,970] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,971] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,973] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,973] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,973] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,974] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,974] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,975] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,977] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:21,978] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-01-28 19:29:21,994] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-01-28 19:29:22,013] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:257)
[2025-01-28 19:29:22,024] INFO Worker started (org.apache.kafka.connect.runtime.Worker:241)
[2025-01-28 19:29:22,025] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-01-28 19:29:22,031] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-01-28 19:29:22,043] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:29:22,051] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-01-28 19:29:22,055] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:29:22,061] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:29:22,064] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 19:29:22,072] INFO Kafka startTimeMs: 1738060162055 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:29:22,077] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:29:22,092] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:29:22,099] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:29:22,109] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:29:22,109] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:29:22,109] INFO Kafka startTimeMs: 1738060162109 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:29:22,116] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 19:29:22,121] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-01-28 19:29:22,121] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:22,122] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:22,122] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:22,123] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:22,123] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:22,134] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:22,135] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:22,135] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:22,136] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:22,136] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:22,194] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-01-28 19:29:22,194] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-01-28 19:29:22,199] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:379)
[2025-01-28 19:29:22,199] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-01-28 19:29:22,212] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-01-28 19:29:22,223] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:29:22,232] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-01-28 19:29:22,244] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:29:22,245] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:29:22,279] INFO Kafka startTimeMs: 1738060162244 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:29:22,266] INFO [Producer clientId=connect-cluster-configs] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 19:29:22,281] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:29:22,328] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:29:22,332] INFO Started o.e.j.s.ServletContextHandler@63513c1c{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-01-28 19:29:22,333] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-01-28 19:29:22,333] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-01-28 19:29:22,337] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:29:22,337] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:29:22,340] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:29:22,340] INFO Kafka startTimeMs: 1738060162337 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:29:22,346] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 19:29:22,348] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-01-28 19:29:22,349] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:29:22,364] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:29:22,383] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,389] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,390] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,391] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,393] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,395] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,396] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,399] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,399] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,399] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,400] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,400] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,400] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,401] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,401] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,402] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,402] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,402] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,403] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,403] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,405] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:22,406] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-01-28 19:29:22,406] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-01-28 19:29:22,407] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:403)
[2025-01-28 19:29:22,407] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:376)
[2025-01-28 19:29:22,421] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 19:29:22,422] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Discovered group coordinator 121.178.140.30:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-01-28 19:29:22,424] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:29:22,424] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:29:22,440] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:29:22,498] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=101, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:29:22,518] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=101, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:29:22,519] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 101 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=140, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:29:22,521] WARN [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1753)
[2025-01-28 19:29:22,521] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 140, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1826)
[2025-01-28 19:29:22,525] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 140 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1853)
[2025-01-28 19:29:22,525] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 140 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:29:22,534] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 19:29:22,535] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 19:29:22,539] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 19:29:22,541] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 19:29:22,543] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:29:22,543] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 19:29:22,546] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 19:29:22,547] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 19:29:22,548] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:29:22,549] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 19:29:22,549] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:29:22,549] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 19:29:22,550] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 19:29:22,553] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:29:22,553] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 19:29:22,560] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:29:22,560] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:29:22,562] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:29:22,567] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 19:29:22,568] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:29:22,568] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 19:29:22,578] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:29:22,583] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:29:22,583] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:29:22,583] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:29:22,583] INFO [chat-connector|task-0] Kafka startTimeMs: 1738060162583 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:29:22,590] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:29:22,630] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 19:29:22,632] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:29:22,640] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:29:22,639] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 19:29:22,666] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 19:29:22,676] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 19:29:22,680] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:29:22,680] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:29:22,690] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:29:22,690] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:29:22,691] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:29:22,692] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:29:22,694] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:29:50,327] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:29:50,328] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 19:29:50,328] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 19:29:50,329] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:29:50,329] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 19:29:50,330] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 19:29:50,331] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:29:50,331] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:29:50,335] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=102, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:29:50,339] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=102, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:29:50,343] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:29:50,344] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 19:29:50,343] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 19:29:50,345] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 19:29:50,347] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 19:29:50,349] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 19:29:50,350] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 102 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=142, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:29:50,351] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 142 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:29:50,352] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:29:50,353] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:29:50,353] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:29:50,358] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=103, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:29:50,378] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:29:50 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 85 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:29:50,382] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=103, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:29:50,384] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 103 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=142, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:29:50,385] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 142 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:29:50,386] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:29:55,239] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:29:55,246] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 19:29:55,246] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:29:55,247] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:29:55,249] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=104, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:29:55,253] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=104, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:29:55,253] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 104 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=143, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:29:55,254] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 143 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:29:55,255] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 19:29:55,255] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 19:29:55,256] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:29:55,258] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:29:55,260] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 19:29:55,260] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 19:29:55,261] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:29:55,261] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:29:55,263] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:29:55,266] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:29:55 +0000] "POST /connectors/ HTTP/1.1" 201 266 "-" "curl/8.9.1" 65 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:29:55,277] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 19:29:55,279] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:29:55,279] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:29:55,281] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=105, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:29:55,287] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=105, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:29:55,287] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 105 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=145, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:29:55,288] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 145 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:29:55,289] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 19:29:55,290] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 19:29:55,290] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 19:29:55,291] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:29:55,292] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 19:29:55,293] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 19:29:55,293] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:29:55,294] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 19:29:55,294] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:29:55,295] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 19:29:55,295] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 19:29:55,295] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 19:29:55,296] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:29:55,297] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:29:55,300] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:29:55,307] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:29:55,312] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:29:55,315] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:29:55,316] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:29:55,316] INFO [chat-connector|task-0] Kafka startTimeMs: 1738060195315 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:29:55,318] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 19:29:55,320] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 19:29:55,320] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 19:29:55,318] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:29:55,322] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 19:29:55,322] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:29:55,323] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:29:55,323] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:29:55,323] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:29:55,323] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:29:55,324] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:29:55,325] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:30:17,357] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:30:17,357] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 19:30:17,357] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 19:30:17,358] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:30:17,358] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 19:30:17,358] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:30:17 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:30:17,358] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 19:30:17,359] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:30:17,359] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:30:17,366] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=106, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:30:17,369] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=106, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:30:17,370] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:30:17,371] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 19:30:17,371] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 19:30:17,371] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 19:30:17,372] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 19:30:17,372] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 19:30:17,372] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 106 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=147, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:30:17,373] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 147 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:30:17,373] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:30:17,374] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:30:17,374] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:30:17,378] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=107, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:30:17,383] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=107, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:30:17,384] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 107 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=147, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:30:17,385] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 147 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:30:17,385] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:33:02,790] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:33:02 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 404 65 "-" "PostmanRuntime/7.43.0" 12 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:34:21,715] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:35:43,176] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:35:43 +0000] "GET /connector-plugins%20 HTTP/1.1" 404 49 "-" "PostmanRuntime/7.43.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:35:50,295] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:35:50 +0000] "GET /connector-plugins HTTP/1.1" 200 708 "-" "PostmanRuntime/7.43.0" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:36:54,384] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:36:54 +0000] "GET /connector-plugins HTTP/1.1" 200 708 "-" "curl/8.9.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:37:34,428] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:37:34 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 404 65 "-" "PostmanRuntime/7.43.0" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:37:39,724] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:37:39 +0000] "GET /connector-plugins HTTP/1.1" 200 708 "-" "curl/8.9.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:38:18,986] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:38:18,988] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:38:18 +0000] "POST /connectors/ HTTP/1.1" 400 309 "-" "curl/8.9.1" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:38:21,893] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:38:21,955] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:38:22,157] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:38:22,173] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:38:22,362] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:38:22,424] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:38:22,660] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:38:53,811] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:38:53 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 404 65 "-" "PostmanRuntime/7.43.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:38:57,381] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:38:57,386] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 19:38:57,386] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:38:57,387] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:38:57,387] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:38:57 +0000] "POST /connectors/ HTTP/1.1" 201 172 "-" "curl/8.9.1" 8 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:38:57,394] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=108, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:38:57,398] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=108, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:38:57,399] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 108 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=148, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:38:57,400] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 148 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:38:57,400] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 19:38:57,400] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 19:38:57,401] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:38:57,403] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:38:57,405] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 19:38:57,405] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 19:38:57,405] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:38:57,407] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:38:57,409] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:38:57,421] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 19:38:57,421] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:38:57,422] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:38:57,424] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=109, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:38:57,427] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=109, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:38:57,428] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 109 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=150, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:38:57,429] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 150 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:38:57,429] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 19:38:57,430] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 19:38:57,430] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 19:38:57,432] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:38:57,434] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 19:38:57,434] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 19:38:57,435] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:38:57,435] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 19:38:57,436] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:38:57,436] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 19:38:57,436] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 19:38:57,437] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 19:38:57,437] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:38:57,439] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:38:57,442] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:38:57,449] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:38:57,454] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:38:57,454] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:38:57,459] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:38:57,460] INFO [chat-connector|task-0] Kafka startTimeMs: 1738060737454 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:38:57,462] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:38:57,462] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 19:38:57,462] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 19:38:57,462] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 19:38:57,464] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 19:38:57,464] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:38:57,465] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:38:57,466] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:38:57,466] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:38:57,466] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:38:57,467] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:38:57,469] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:39:56,273] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:39:56,274] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:39:56 +0000] "POST /connectors/ HTTP/1.1" 409 70 "-" "curl/8.9.1" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:40:00,021] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:40:00,022] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 19:40:00,022] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 19:40:00,022] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:40:00,023] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 19:40:00,023] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:40:00 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:40:00,023] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 19:40:00,024] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:40:00,024] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:40:00,026] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=110, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:40:00,030] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=110, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:40:00,030] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:40:00,031] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 19:40:00,033] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 19:40:00,034] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 19:40:00,037] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 19:40:00,037] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 19:40:00,038] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 110 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=152, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:40:00,038] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 152 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:40:00,039] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:40:00,039] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:40:00,039] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:40:00,043] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=111, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:40:00,046] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=111, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:40:00,046] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 111 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=152, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:40:00,047] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 152 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:40:00,047] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:40:03,580] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:40:03,584] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 19:40:03,585] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:40:03,585] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:40:03,586] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:40:03 +0000] "POST /connectors/ HTTP/1.1" 201 172 "-" "curl/8.9.1" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:40:03,588] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=112, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:40:03,590] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=112, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:40:03,591] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 112 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=153, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:40:03,591] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 153 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:40:03,592] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 19:40:03,592] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 19:40:03,593] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:40:03,595] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:40:03,597] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 19:40:03,598] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 19:40:03,598] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:40:03,600] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:40:03,602] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:40:03,612] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 19:40:03,612] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:40:03,613] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:40:03,616] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=113, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:40:03,620] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=113, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:40:03,620] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 113 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=155, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:40:03,621] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 155 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:40:03,621] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 19:40:03,622] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 19:40:03,622] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 19:40:03,623] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:40:03,625] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 19:40:03,625] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 19:40:03,626] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:40:03,627] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 19:40:03,628] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:40:03,629] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 19:40:03,629] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 19:40:03,630] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 19:40:03,632] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:40:03,635] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:40:03,637] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:40:03,644] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:40:03,648] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:40:03,650] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:40:03,650] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:40:03,650] INFO [chat-connector|task-0] Kafka startTimeMs: 1738060803650 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:40:03,652] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:40:03,652] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 19:40:03,653] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 19:40:03,653] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 19:40:03,655] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 19:40:03,655] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:40:03,655] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:40:03,656] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:40:03,656] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:40:03,657] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:40:03,657] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:40:03,659] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:40:18,152] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:40:18,153] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 19:40:18,153] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 19:40:18,153] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:40:18,153] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 19:40:18,154] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:40:18 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:40:18,154] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 19:40:18,155] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:40:18,156] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:40:18,158] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=114, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:40:18,162] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=114, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:40:18,163] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:40:18,163] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 19:40:18,164] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 19:40:18,165] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 19:40:18,169] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 19:40:18,170] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 19:40:18,170] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 114 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=157, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:40:18,171] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 157 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:40:18,171] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:40:18,172] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:40:18,172] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:40:18,175] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=115, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:40:18,178] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=115, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:40:18,179] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 115 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=157, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:40:18,179] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 157 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:40:18,180] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:40:33,480] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:40:33,485] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 19:40:33,485] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:40:33,485] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:40:33,486] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:40:33 +0000] "POST /connectors/ HTTP/1.1" 201 228 "-" "curl/8.9.1" 8 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:40:33,489] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=116, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:40:33,495] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=116, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:40:33,496] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 116 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=158, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:40:33,497] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 158 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:40:33,498] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 19:40:33,498] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 19:40:33,499] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:40:33,505] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:40:33,508] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 19:40:33,510] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 19:40:33,510] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:40:33,511] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:40:33,512] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:40:33,524] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 19:40:33,525] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:40:33,525] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:40:33,528] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=117, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:40:33,531] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=117, memberId='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:40:33,532] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 117 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603', leaderUrl='http://121.178.140.30:8083/', offset=160, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:40:33,533] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 160 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:40:33,533] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 19:40:33,533] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 19:40:33,534] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 19:40:33,538] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:40:33,539] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 19:40:33,540] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 19:40:33,541] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:40:33,543] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 19:40:33,545] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:40:33,546] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 19:40:33,547] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 19:40:33,549] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 19:40:33,550] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:40:33,553] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:40:33,554] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:40:33,564] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:40:33,568] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:40:33,568] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:40:33,569] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:40:33,569] INFO [chat-connector|task-0] Kafka startTimeMs: 1738060833568 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:40:33,570] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 19:40:33,570] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 19:40:33,570] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 19:40:33,570] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:40:33,572] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 19:40:33,576] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:40:33,577] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:40:33,577] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:40:33,578] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:40:33,578] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:40:33,578] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:40:33,579] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:41:07,256] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2025-01-28 19:41:07,256] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:354)
[2025-01-28 19:41:07,259] INFO Stopped http_8083@136a5572{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2025-01-28 19:41:07,260] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2025-01-28 19:41:07,261] INFO Stopped o.e.j.s.ServletContextHandler@63513c1c{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2025-01-28 19:41:07,261] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:383)
[2025-01-28 19:41:07,261] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:831)
[2025-01-28 19:41:07,262] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2025-01-28 19:41:07,262] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:41:07,262] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 19:41:07,263] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 19:41:07,263] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 19:41:07,264] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Member connect-121.178.140.30:8083-3dbdc6c1-eb08-49ef-b9d5-2eb3357f3603 sending LeaveGroup request to coordinator 121.178.140.30:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1163)
[2025-01-28 19:41:07,264] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1055)
[2025-01-28 19:41:07,265] WARN [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1140)
[2025-01-28 19:41:07,265] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:41:07,265] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:07,266] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:41:07,268] INFO App info kafka.connect for connect-121.178.140.30:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:41:07,268] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:299)
[2025-01-28 19:41:07,268] INFO [Producer clientId=connect-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2025-01-28 19:41:07,274] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:41:07,275] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:07,275] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:07,275] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:41:07,275] INFO App info kafka.producer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:41:07,275] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:41:07,276] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:41:07,797] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:41:07,798] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:07,798] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:07,798] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:41:07,799] INFO App info kafka.consumer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:41:07,800] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:323)
[2025-01-28 19:41:07,800] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:408)
[2025-01-28 19:41:07,800] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:299)
[2025-01-28 19:41:07,801] INFO [Producer clientId=connect-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2025-01-28 19:41:07,802] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:41:07,802] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:07,802] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:07,803] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:41:07,803] INFO App info kafka.producer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:41:07,803] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:41:07,803] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:41:08,148] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:41:08,149] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:08,149] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:08,149] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:41:08,150] INFO App info kafka.consumer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:41:08,151] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:323)
[2025-01-28 19:41:08,151] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:414)
[2025-01-28 19:41:08,151] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:248)
[2025-01-28 19:41:08,152] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:269)
[2025-01-28 19:41:08,152] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:299)
[2025-01-28 19:41:08,152] INFO [Producer clientId=connect-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2025-01-28 19:41:08,154] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:41:08,154] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:08,154] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:08,154] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:41:08,154] INFO App info kafka.producer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:41:08,155] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:41:08,155] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:41:08,397] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:41:08,397] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:08,397] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:08,397] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:41:08,399] INFO App info kafka.consumer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:41:08,399] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:323)
[2025-01-28 19:41:08,399] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:277)
[2025-01-28 19:41:08,399] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:41:08,399] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:08,400] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:41:08,400] INFO App info kafka.connect for 121.178.140.30:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:41:08,400] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:269)
[2025-01-28 19:41:08,401] INFO App info kafka.admin.client for connect-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:41:08,402] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:41:08,402] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:08,402] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:41:08,403] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:386)
[2025-01-28 19:41:08,404] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:838)
[2025-01-28 19:41:08,407] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2025-01-28 19:41:14,301] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-01-28 19:41:14,305] INFO WorkerInfo values: 
	jvm.args = -Xmx256M, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2/logs, -Dlog4j.configuration=file:F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2/config/connect-log4j.properties
	jvm.spec = Eclipse Adoptium, OpenJDK 64-Bit Server VM, 17.0.12, 17.0.12+7
	jvm.classpath = F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\activation-1.1.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\aopalliance-repackaged-2.6.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\argparse4j-0.7.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\audience-annotations-0.12.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\caffeine-2.9.3.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\checker-qual-3.19.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-beanutils-1.9.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-cli-1.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-collections-3.2.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-digester-2.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-io-2.14.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-lang3-3.8.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-logging-1.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-validator-1.7.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-api-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-basic-auth-extension-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-file-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-json-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-mirror-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-mirror-client-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-runtime-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-transforms-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\error_prone_annotations-2.10.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-api-2.6.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-locator-2.6.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-utils-2.6.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-annotations-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-core-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-databind-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-dataformat-csv-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-datatype-jdk8-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-jaxrs-base-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-jaxrs-json-provider-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-module-jaxb-annotations-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-module-scala_2.12-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.activation-api-1.2.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.annotation-api-1.3.5.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.inject-2.6.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.validation-api-2.0.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.ws.rs-api-2.1.6.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.xml.bind-api-2.3.3.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javassist-3.29.2-GA.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.activation-api-1.2.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.annotation-api-1.3.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.servlet-api-3.1.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.ws.rs-api-2.1.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jaxb-api-2.3.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-client-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-common-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-container-servlet-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-container-servlet-core-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-hk2-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-server-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-client-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-continuation-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-http-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-io-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-security-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-server-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-servlet-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-servlets-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-util-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-util-ajax-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jline-3.25.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jopt-simple-5.0.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jose4j-0.9.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jsr305-3.0.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-clients-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-group-coordinator-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-log4j-appender-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-metadata-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-raft-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-server-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-server-common-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-shell-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-storage-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-storage-api-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-examples-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-scala_2.12-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-test-utils-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-tools-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-tools-api-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka_2.12-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\lz4-java-1.8.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\maven-artifact-3.8.8.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\metrics-core-2.2.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\metrics-core-4.1.12.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-buffer-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-codec-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-common-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-handler-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-resolver-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-classes-epoll-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-native-epoll-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-native-unix-common-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\opentelemetry-proto-1.0.0-alpha.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\osgi-resource-locator-1.0.3.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\paranamer-2.8.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\pcollections-4.0.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\plexus-utils-3.3.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\protobuf-java-3.25.5.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\reflections-0.10.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\reload4j-1.2.25.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\rocksdbjni-7.9.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-collection-compat_2.12-2.10.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-java8-compat_2.12-1.0.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-library-2.12.18.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-logging_2.12-3.9.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-reflect-2.12.18.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\slf4j-api-1.7.36.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\slf4j-reload4j-1.7.36.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\snappy-java-1.1.10.5.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\swagger-annotations-2.2.8.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\trogdor-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zookeeper-3.8.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zookeeper-jute-3.8.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zstd-jni-1.5.6-4.jar;
	os.spec = Windows 10, amd64, 10.0
	os.vcpus = 6
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-01-28 19:41:14,311] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-01-28 19:41:14,356] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\bin (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:41:14,523] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/bin/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:41:14,524] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\config (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:41:14,532] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/config/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:41:14,533] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:41:14,583] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2025-01-28 19:41:14,634] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:41:14,634] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:41:14,766] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:41:14,767] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\licenses (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:41:14,772] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/licenses/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:41:14,773] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\logs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:41:14,777] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/logs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:41:14,778] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\site-docs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:41:14,783] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/site-docs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:41:14,784] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:41:14,792] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@66d3c617 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:41:14,796] INFO Scanning plugins with ServiceLoaderScanner took 441 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-01-28 19:41:14,798] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\bin (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:41:14,819] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/bin/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:41:14,820] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\config (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:41:14,822] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/config/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:41:14,822] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:41:15,099] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:41:15,099] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:41:16,374] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:41:16,375] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\licenses (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:41:16,376] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/licenses/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:41:16,377] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\logs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:41:16,378] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/logs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:41:16,378] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\site-docs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:41:16,380] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/site-docs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:41:16,380] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 19:41:17,052] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@66d3c617 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 19:41:17,052] INFO Scanning plugins with ReflectionScanner took 2254 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-01-28 19:41:17,056] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/	io.debezium.connector.mongodb.MongoDbSinkConnector	sink	3.0.2.Final
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-01-28 19:41:17,059] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,060] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,060] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,060] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,061] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,061] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,061] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,062] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,063] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,063] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,063] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,064] INFO Added plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,065] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,066] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,066] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,077] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,078] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,078] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,078] INFO Added plugin 'io.debezium.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,079] INFO Added plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,079] INFO Added plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,079] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,079] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,080] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,080] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,080] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,080] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,081] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,081] INFO Added plugin 'io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,081] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,081] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,082] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,082] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,084] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,089] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,090] INFO Added plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,090] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,091] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,091] INFO Added plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,091] INFO Added plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,092] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,092] INFO Added plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,092] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,093] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,093] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,093] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,094] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,094] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,095] INFO Added plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,095] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,095] INFO Added plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,096] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,097] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,097] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,097] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,097] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,098] INFO Added plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,098] INFO Added plugin 'io.debezium.connector.mongodb.transforms.ExtractNewDocumentState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,103] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,104] INFO Added plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,105] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,105] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,105] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,106] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,106] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,107] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,107] INFO Added plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,107] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,107] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 19:41:17,110] INFO Added alias 'ExtractNewDocumentState' to plugin 'io.debezium.connector.mongodb.transforms.ExtractNewDocumentState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,110] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,110] INFO Added alias 'CloudEventsConverter' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,111] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,111] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,112] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,112] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,112] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,112] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,113] INFO Added alias 'HeaderToValue' to plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,113] INFO Added alias 'PartitionRouting' to plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,113] INFO Added alias 'MongoDbSink' to plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,114] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,114] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,115] INFO Added alias 'MongoDbConnector' to plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,116] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,116] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,116] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,117] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,123] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,126] INFO Added alias 'ExtractSchemaToNewRecord' to plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,126] INFO Added alias 'BinaryData' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,126] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,127] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,127] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,128] INFO Added alias 'CloudEvents' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,128] INFO Added alias 'TimezoneConverter' to plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,128] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,129] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,130] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,130] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,130] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,130] INFO Added alias 'DebeziumMongoDb' to plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,131] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,131] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,131] INFO Added alias 'DebeziumMongoDbConnectRestExtension' to plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,132] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,132] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,132] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,133] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,133] INFO Added alias 'ExtractChangedRecordState' to plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,133] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,134] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,134] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,134] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,134] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,135] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,135] INFO Added alias 'MongoDbSinkConnector' to plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,136] INFO Added alias 'MongoDb' to plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,136] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,136] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,137] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,137] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,138] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,139] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,139] INFO Added alias 'SchemaChangeEventFilter' to plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,140] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,140] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,140] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,140] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,141] INFO Added alias 'ActivateTracingSpan' to plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,141] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,142] INFO Added alias 'BinaryDataConverter' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,142] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,142] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,142] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,143] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,143] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,143] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,143] INFO Added alias 'MongoEventRouter' to plugin 'io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,144] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,144] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 19:41:17,187] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-01-28 19:41:17,198] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-01-28 19:41:17,201] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-01-28 19:41:17,298] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-01-28 19:41:17,298] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:41:17,299] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:41:17,299] INFO Kafka startTimeMs: 1738060877298 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:41:17,551] INFO Kafka cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-01-28 19:41:17,552] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:41:17,557] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:41:17,557] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:17,557] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:41:17,567] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-01-28 19:41:17,577] INFO Logging initialized @4045ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-01-28 19:41:17,621] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-01-28 19:41:17,621] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-01-28 19:41:17,643] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 17.0.12+7 (org.eclipse.jetty.server.Server:375)
[2025-01-28 19:41:17,665] INFO Started http_8083@21143041{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-01-28 19:41:17,666] INFO Started @4134ms (org.eclipse.jetty.server.Server:415)
[2025-01-28 19:41:17,682] INFO Advertised URI: http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-01-28 19:41:17,690] INFO REST server listening at http://121.178.140.30:8083/, advertising URL http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-01-28 19:41:17,690] INFO Advertised URI: http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-01-28 19:41:17,692] INFO REST admin endpoints at http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-01-28 19:41:17,693] INFO Advertised URI: http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-01-28 19:41:17,693] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-01-28 19:41:17,697] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:41:17,709] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:41:17,710] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:41:17,710] INFO Kafka startTimeMs: 1738060877709 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:41:17,714] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:41:17,714] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:41:17,729] INFO Advertised URI: http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-01-28 19:41:17,756] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:41:17,756] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:41:17,757] INFO Kafka startTimeMs: 1738060877756 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:41:17,759] INFO Kafka Connect worker initialization took 3457ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-01-28 19:41:17,759] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-01-28 19:41:17,761] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-01-28 19:41:17,762] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:369)
[2025-01-28 19:41:17,763] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:231)
[2025-01-28 19:41:17,763] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:240)
[2025-01-28 19:41:17,763] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-01-28 19:41:17,764] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-01-28 19:41:17,776] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-01-28 19:41:17,777] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:41:17,777] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:41:17,777] INFO Kafka startTimeMs: 1738060877777 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:41:17,791] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-01-28 19:41:17,810] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-01-28 19:41:17,831] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-01-28 19:41:17,832] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-01-28 19:41:17,832] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2025-01-28 19:41:17,840] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:41:17,866] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-01-28 19:41:17,870] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:41:17,872] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:41:17,873] INFO Kafka startTimeMs: 1738060877870 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:41:17,883] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 19:41:17,893] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:41:17,914] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:41:17,944] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:41:17,945] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:41:17,945] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:41:17,946] INFO Kafka startTimeMs: 1738060877945 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:41:17,958] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 19:41:17,962] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-01-28 19:41:17,977] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,978] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,978] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,978] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,979] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,979] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,979] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,979] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,980] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,980] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,981] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,981] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,981] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,981] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,982] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,982] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,984] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,986] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,986] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,987] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,987] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,987] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,988] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,988] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:17,988] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:18,026] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,027] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,027] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,028] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,029] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,029] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,030] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,030] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,030] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,031] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,031] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,034] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,036] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,036] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,036] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,037] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,037] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,038] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,047] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,048] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,049] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,050] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,050] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,051] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,052] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,052] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-01-28 19:41:18,053] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-01-28 19:41:18,054] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:257)
[2025-01-28 19:41:18,056] INFO Worker started (org.apache.kafka.connect.runtime.Worker:241)
[2025-01-28 19:41:18,056] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-01-28 19:41:18,065] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-01-28 19:41:18,075] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:41:18,081] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-01-28 19:41:18,098] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:41:18,099] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:41:18,099] INFO Kafka startTimeMs: 1738060878098 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:41:18,102] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:41:18,110] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:41:18,116] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:41:18,118] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 19:41:18,120] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:41:18,123] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:41:18,124] INFO Kafka startTimeMs: 1738060878120 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:41:18,131] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 19:41:18,132] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-01-28 19:41:18,132] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:18,133] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:18,133] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:18,134] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:18,139] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:18,154] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,155] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,158] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,158] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,158] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,301] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-01-28 19:41:18,302] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-01-28 19:41:18,308] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:379)
[2025-01-28 19:41:18,309] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-01-28 19:41:18,327] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-01-28 19:41:18,335] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:41:18,348] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-01-28 19:41:18,355] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:41:18,355] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:41:18,355] INFO Kafka startTimeMs: 1738060878354 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:41:18,356] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:41:18,371] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:41:18,442] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:41:18,451] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:41:18,452] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:41:18,452] INFO Kafka startTimeMs: 1738060878451 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:41:18,457] INFO [Producer clientId=connect-cluster-configs] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 19:41:18,459] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 19:41:18,461] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-01-28 19:41:18,461] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 19:41:18,515] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 19:41:18,555] INFO Started o.e.j.s.ServletContextHandler@3f1dadeb{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-01-28 19:41:18,556] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-01-28 19:41:18,556] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-01-28 19:41:18,577] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,579] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,579] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,580] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,581] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,583] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,584] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,587] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,587] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,588] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,588] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,589] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,590] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,590] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,591] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,591] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,592] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,593] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,593] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,596] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,597] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,599] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,600] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,602] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,602] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:41:18,603] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-01-28 19:41:18,614] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-01-28 19:41:18,616] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:403)
[2025-01-28 19:41:18,616] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:376)
[2025-01-28 19:41:18,645] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 19:41:18,658] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Discovered group coordinator 121.178.140.30:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-01-28 19:41:18,661] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:41:18,662] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:41:18,677] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:41:18,680] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=119, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:41:18,729] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=119, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:41:18,730] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 119 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=160, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:41:18,731] WARN [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1753)
[2025-01-28 19:41:18,732] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 160, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1826)
[2025-01-28 19:41:18,745] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 160 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1853)
[2025-01-28 19:41:18,745] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 160 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:41:18,759] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 19:41:18,759] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 19:41:18,770] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 19:41:18,770] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 19:41:18,772] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:41:18,774] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 19:41:18,776] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:41:18,776] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:41:18,778] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 19:41:18,779] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 19:41:18,781] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:41:18,782] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 19:41:18,783] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:41:18,789] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 19:41:18,790] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 19:41:18,783] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 19:41:18,795] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 19:41:18,797] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 19:41:18,806] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:41:18,808] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:41:18,813] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:41:18,822] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:41:18,829] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:41:18,837] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:41:18,839] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:41:18,841] INFO [chat-connector|task-0] Kafka startTimeMs: 1738060878834 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:41:18,870] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:41:18,873] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:41:18,877] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:41:18,916] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 19:41:18,919] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 19:41:18,935] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 19:41:18,942] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 19:41:18,955] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:41:18,956] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:41:18,959] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:41:18,960] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:18,961] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:41:18,961] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:41:18,963] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:43:04,949] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:43:04,950] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 19:43:04,952] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 19:43:04,953] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:43:04,953] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 19:43:04,953] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 19:43:04,955] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:43:04,955] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:43:04,959] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=120, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:43:04,963] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=120, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:43:04,965] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:43:04,965] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 19:43:04,970] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 19:43:04,971] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 19:43:04,972] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 19:43:04,974] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 19:43:04,974] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 120 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=162, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:43:04,975] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 162 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:43:04,981] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:43:04 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 63 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:43:04,986] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:43:05,005] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:43:05,006] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:43:05,013] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=121, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:43:05,025] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=121, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:43:05,026] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 121 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=162, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:43:05,026] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 162 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:43:05,027] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:43:09,097] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:43:09,103] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 19:43:09,104] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:43:09,104] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:43:09,106] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=122, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:43:09,109] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=122, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:43:09,110] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 122 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=163, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:43:09,111] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 163 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:43:09,128] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:43:09 +0000] "POST /connectors/ HTTP/1.1" 201 217 "-" "curl/8.9.1" 70 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:43:09,140] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 19:43:09,145] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 19:43:09,148] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:43:09,158] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:43:09,161] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 19:43:09,163] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 19:43:09,166] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:43:09,168] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:43:09,170] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:43:09,191] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 19:43:09,192] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:43:09,193] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:43:09,194] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=123, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:43:09,208] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=123, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:43:09,208] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 123 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=165, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:43:09,209] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 165 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:43:09,212] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 19:43:09,212] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 19:43:09,213] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 19:43:09,214] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:43:09,221] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 19:43:09,222] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 19:43:09,224] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:43:09,225] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 19:43:09,225] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:43:09,226] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 19:43:09,226] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 19:43:09,227] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 19:43:09,227] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:43:09,229] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:43:09,231] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:43:09,242] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:43:09,248] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:43:09,261] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:43:09,263] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:43:09,263] INFO [chat-connector|task-0] Kafka startTimeMs: 1738060989261 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:43:09,264] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:43:09,275] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 19:43:09,276] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 19:43:09,276] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 19:43:09,278] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 19:43:09,278] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:43:09,278] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:43:09,279] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:43:09,279] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:43:09,279] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:43:09,280] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:43:09,282] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:44:41,497] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:44:41,508] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:44:41 +0000] "POST /connectors/ HTTP/1.1" 409 70 "-" "curl/8.9.1" 14 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:44:46,715] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:44:46,715] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 19:44:46,715] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 19:44:46,716] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:44:46,716] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 19:44:46,716] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:44:46 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:44:46,717] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 19:44:46,719] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:44:46,719] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:44:46,722] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=124, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:44:46,725] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=124, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:44:46,726] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:44:46,726] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 19:44:46,727] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 19:44:46,727] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 19:44:46,728] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 19:44:46,728] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 19:44:46,728] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 124 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=167, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:44:46,729] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 167 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:44:46,729] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:44:46,730] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:44:46,730] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:44:46,733] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=125, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:44:46,739] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=125, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:44:46,740] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 125 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=167, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:44:46,742] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 167 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:44:46,743] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:46:17,784] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:46:45,310] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:46:45,314] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 19:46:45,315] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:46:45,315] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:46:45,316] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:46:45 +0000] "POST /connectors/ HTTP/1.1" 201 233 "-" "curl/8.9.1" 8 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:46:45,317] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=126, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:46:45,319] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=126, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:46:45,320] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 126 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=168, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:46:45,321] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 168 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:46:45,321] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 19:46:45,321] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 19:46:45,322] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:46:45,324] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:46:45,326] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 19:46:45,327] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 19:46:45,328] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:46:45,341] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:46:45,345] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:46:45,358] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 19:46:45,359] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:46:45,359] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:46:45,362] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=127, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:46:45,364] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=127, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:46:45,364] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 127 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=170, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:46:45,365] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 170 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:46:45,365] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 19:46:45,366] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 19:46:45,366] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 19:46:45,368] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:46:45,369] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 19:46:45,370] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 19:46:45,370] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:46:45,371] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 19:46:45,373] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:46:45,374] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 19:46:45,375] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 19:46:45,377] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 19:46:45,383] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:46:45,385] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:46:45,387] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:46:45,394] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:46:45,401] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:46:45,402] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:46:45,402] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:46:45,403] INFO [chat-connector|task-0] Kafka startTimeMs: 1738061205402 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:46:45,404] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:46:45,404] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 19:46:45,404] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 19:46:45,405] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 19:46:45,406] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 19:46:45,406] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:46:45,407] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:46:45,407] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:46:45,407] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:46:45,408] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:46:45,408] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:46:45,409] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:47:03,856] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:47:03,856] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 19:47:03,857] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 19:47:03,857] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:47:03,857] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 19:47:03,857] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:47:03 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:47:03,858] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 19:47:03,859] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:47:03,859] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:47:03,861] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=128, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:47:03,865] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=128, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:47:03,866] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:47:03,867] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 19:47:03,867] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 19:47:03,866] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 19:47:03,868] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 19:47:03,868] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 19:47:03,869] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 128 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=172, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:47:03,869] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 172 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:47:03,870] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:47:03,870] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:47:03,870] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:47:03,873] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=129, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:47:03,875] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=129, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:47:03,875] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 129 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=172, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:47:03,876] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 172 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:47:03,876] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:48:03,192] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:48:03 +0000] "GET /connectors/status HTTP/1.1" 404 57 "-" "curl/8.9.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:48:09,156] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:48:09 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 404 65 "-" "PostmanRuntime/7.43.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:48:13,104] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:48:13,109] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 19:48:13,109] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:48:13,109] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:48:13,110] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:48:13 +0000] "POST /connectors/ HTTP/1.1" 201 233 "-" "curl/8.9.1" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:48:13,113] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=130, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:48:13,115] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=130, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:48:13,116] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 130 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=173, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:48:13,116] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 173 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:48:13,117] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 19:48:13,117] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 19:48:13,118] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:48:13,120] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:48:13,122] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 19:48:13,122] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 19:48:13,124] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:48:13,128] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:48:13,130] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:48:13,145] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 19:48:13,146] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:48:13,146] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:48:13,148] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=131, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:48:13,150] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=131, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:48:13,150] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 131 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=175, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:48:13,151] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 175 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:48:13,152] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 19:48:13,153] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 19:48:13,153] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 19:48:13,155] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:48:13,157] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 19:48:13,157] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 19:48:13,158] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:48:13,159] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 19:48:13,159] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:48:13,160] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 19:48:13,160] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 19:48:13,161] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 19:48:13,161] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:48:13,163] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:48:13,164] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:48:13,176] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:48:13,180] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:48:13,180] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:48:13,181] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:48:13,181] INFO [chat-connector|task-0] Kafka startTimeMs: 1738061293180 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:48:13,182] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:48:13,182] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 19:48:13,182] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 19:48:13,183] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 19:48:13,184] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 19:48:13,184] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:48:13,186] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:48:13,187] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:48:13,187] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:48:13,187] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:48:13,187] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:48:13,188] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:48:17,977] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:48:17 +0000] "GET /connectors/status HTTP/1.1" 404 57 "-" "curl/8.9.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:48:30,225] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:48:30 +0000] "GET /connectors/chat-connector/status HTTP/1.1" 200 1576 "-" "curl/8.9.1" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:49:06,663] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:49:06,664] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 19:49:06,664] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 19:49:06,664] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:49:06,665] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 19:49:06,665] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:49:06 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:49:06,666] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 19:49:06,667] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:49:06,668] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:49:06,673] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=132, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:49:06,675] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=132, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:49:06,676] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 19:49:06,676] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:49:06,678] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 19:49:06,679] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 19:49:06,679] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 19:49:06,679] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 19:49:06,680] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 132 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=177, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:49:06,680] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 177 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:49:06,681] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:49:06,681] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:49:06,681] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:49:06,689] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=133, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:49:06,693] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=133, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:49:06,694] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 133 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=177, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:49:06,694] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 177 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:49:06,694] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:49:45,376] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:49:45,381] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 19:49:45,381] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:49:45,382] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:49:45,382] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:49:45 +0000] "POST /connectors/ HTTP/1.1" 201 228 "-" "curl/8.9.1" 11 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:49:45,387] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=134, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:49:45,390] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=134, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:49:45,391] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 134 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=178, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:49:45,392] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 178 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:49:45,395] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 19:49:45,395] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 19:49:45,396] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:49:45,397] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:49:45,398] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 19:49:45,401] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 19:49:45,404] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:49:45,404] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:49:45,406] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:49:45,433] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 19:49:45,434] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:49:45,435] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:49:45,437] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=135, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:49:45,440] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=135, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:49:45,440] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 135 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=180, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:49:45,441] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 180 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:49:45,441] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 19:49:45,442] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 19:49:45,442] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 19:49:45,444] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:49:45,446] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 19:49:45,447] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 19:49:45,448] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:49:45,448] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 19:49:45,449] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:49:45,451] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 19:49:45,451] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 19:49:45,452] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 19:49:45,452] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:49:45,454] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:49:45,456] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:49:45,464] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:49:45,469] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:49:45,469] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:49:45,470] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:49:45,470] INFO [chat-connector|task-0] Kafka startTimeMs: 1738061385469 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:49:45,472] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:49:45,473] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 19:49:45,473] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 19:49:45,474] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 19:49:45,477] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 19:49:45,478] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:49:45,478] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:49:45,479] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:49:45,479] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:49:45,479] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:49:45,480] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:49:45,480] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:49:55,468] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:49:55 +0000] "GET /connectors/chat-connector/status HTTP/1.1" 200 1576 "-" "curl/8.9.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:50:17,258] ERROR Uncaught exception in REST call to /connectors/chat-connector/status (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
javax.ws.rs.NotAllowedException: HTTP 405 Method Not Allowed
	at org.glassfish.jersey.server.internal.routing.MethodSelectingRouter.getMethodRouter(MethodSelectingRouter.java:408)
	at org.glassfish.jersey.server.internal.routing.MethodSelectingRouter.access$000(MethodSelectingRouter.java:73)
	at org.glassfish.jersey.server.internal.routing.MethodSelectingRouter$4.apply(MethodSelectingRouter.java:673)
	at org.glassfish.jersey.server.internal.routing.MethodSelectingRouter.apply(MethodSelectingRouter.java:304)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 19:50:17,263] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:50:17 +0000] "DELETE /connectors/chat-connector/status HTTP/1.1" 405 58 "-" "PostmanRuntime/7.43.0" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:50:17,949] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:50:18,397] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:50:18,476] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:50:18,476] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:50:18,756] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:50:31,422] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:50:31 +0000] "GET /connectors/chat-connector/status HTTP/1.1" 200 1576 "-" "PostmanRuntime/7.43.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:50:45,456] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:50:45,502] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 19:51:54,567] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:51:54,567] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 19:51:54,568] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 19:51:54,569] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:51:54,569] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:51:54 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:51:54,569] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 19:51:54,571] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 19:51:54,572] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:51:54,572] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:51:54,579] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=136, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:51:54,581] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=136, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:51:54,582] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:51:54,582] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 19:51:54,582] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 19:51:54,582] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 19:51:54,583] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 19:51:54,585] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 19:51:54,586] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 136 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=182, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:51:54,587] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 182 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:51:54,588] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:51:54,588] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:51:54,588] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:51:54,593] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=137, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:51:54,596] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=137, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:51:54,596] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 137 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=182, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:51:54,597] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 182 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:51:54,597] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:52:17,143] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:52:17,145] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:52:17 +0000] "POST /connectors/ HTTP/1.1" 400 309 "-" "curl/8.9.1" 4 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:52:34,368] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:52:34,372] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 19:52:34,372] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:52:34,373] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:52:34,373] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:52:34 +0000] "POST /connectors/ HTTP/1.1" 201 228 "-" "curl/8.9.1" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:52:34,375] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=138, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:52:34,378] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=138, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:52:34,379] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 138 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=183, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:52:34,379] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 183 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:52:34,379] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 19:52:34,380] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 19:52:34,381] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:52:34,383] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:52:34,386] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 19:52:34,388] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 19:52:34,390] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:52:34,390] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:52:34,393] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:52:34,405] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 19:52:34,406] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:52:34,406] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:52:34,409] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=139, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:52:34,411] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=139, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:52:34,412] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 139 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=185, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:52:34,413] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 185 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:52:34,414] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 19:52:34,414] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 19:52:34,415] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 19:52:34,416] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:52:34,417] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 19:52:34,418] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 19:52:34,418] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:52:34,419] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 19:52:34,420] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:52:34,420] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 19:52:34,420] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 19:52:34,421] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 19:52:34,421] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:52:34,423] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:52:34,426] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:52:34,433] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:52:34,438] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:52:34,438] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:52:34,439] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:52:34,439] INFO [chat-connector|task-0] Kafka startTimeMs: 1738061554438 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:52:34,440] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:52:34,441] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 19:52:34,442] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 19:52:34,442] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 19:52:34,443] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 19:52:34,444] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:52:34,444] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:52:34,444] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:52:34,444] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:52:34,445] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:52:34,445] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:52:34,446] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:53:24,599] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:53:24,599] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 19:53:24,600] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 19:53:24,600] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:53:24,600] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 19:53:24,600] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:53:24 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:53:24,602] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 19:53:24,603] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:53:24,604] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:53:24,607] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=140, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:53:24,610] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=140, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:53:24,611] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:53:24,611] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 19:53:24,611] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 19:53:24,611] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 19:53:24,612] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 19:53:24,613] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 19:53:24,613] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 140 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=187, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:53:24,615] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 187 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:53:24,615] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:53:24,615] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:53:24,616] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:53:24,624] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=141, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:53:24,627] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=141, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:53:24,627] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 141 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=187, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:53:24,628] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 187 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:53:24,628] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:53:27,754] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:53:27,758] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 19:53:27,759] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:53:27,759] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:53:27,759] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:53:27 +0000] "POST /connectors/ HTTP/1.1" 201 228 "-" "curl/8.9.1" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:53:27,762] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=142, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:53:27,765] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=142, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:53:27,765] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 142 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=188, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:53:27,766] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 188 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:53:27,766] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 19:53:27,767] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 19:53:27,769] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:53:27,772] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:53:27,774] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 19:53:27,775] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 19:53:27,778] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:53:27,778] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:53:27,780] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:53:27,790] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 19:53:27,790] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:53:27,790] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:53:27,793] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=143, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:53:27,796] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=143, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:53:27,797] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 143 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=190, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:53:27,797] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 190 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:53:27,798] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 19:53:27,798] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 19:53:27,799] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 19:53:27,800] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:53:27,802] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 19:53:27,802] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 19:53:27,803] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:53:27,803] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 19:53:27,804] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:53:27,804] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 19:53:27,805] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 19:53:27,805] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 19:53:27,805] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:53:27,808] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:53:27,810] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:53:27,816] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:53:27,821] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:53:27,821] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:53:27,821] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:53:27,822] INFO [chat-connector|task-0] Kafka startTimeMs: 1738061607821 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:53:27,822] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:53:27,823] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 19:53:27,823] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 19:53:27,823] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 19:53:27,825] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 19:53:27,825] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:53:27,826] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:53:27,828] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:53:27,828] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:53:27,828] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:53:27,828] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:53:27,829] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:53:41,525] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:53:41 +0000] "GET /connectors/chat-connector/status HTTP/1.1" 200 1576 "-" "curl/8.9.1" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:53:56,179] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:53:56,179] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 19:53:56,180] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 19:53:56,180] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:53:56,180] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 19:53:56,180] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:53:56 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:53:56,181] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 19:53:56,182] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:53:56,182] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:53:56,184] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=144, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:53:56,189] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=144, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:53:56,190] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:53:56,190] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 19:53:56,190] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 19:53:56,191] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 19:53:56,191] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 19:53:56,192] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 19:53:56,192] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 144 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=192, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:53:56,194] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 192 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:53:56,195] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:53:56,196] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:53:56,196] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:53:56,205] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=145, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:53:56,213] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=145, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:53:56,214] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 145 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=192, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:53:56,214] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 192 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:53:56,214] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:57:43,665] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:57:43,669] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 19:57:43,670] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:57:43,670] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:57:43,672] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:57:43 +0000] "POST /connectors/ HTTP/1.1" 201 228 "-" "curl/8.9.1" 9 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:57:43,674] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=146, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:57:43,677] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=146, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:57:43,679] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 146 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=193, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:57:43,681] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 193 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:57:43,689] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 19:57:43,689] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 19:57:43,690] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:57:43,692] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:57:43,695] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 19:57:43,696] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 19:57:43,696] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:57:43,703] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:57:43,705] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:57:43,720] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 19:57:43,721] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:57:43,721] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:57:43,726] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=147, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:57:43,728] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=147, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:57:43,729] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 147 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=195, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:57:43,729] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 195 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:57:43,730] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 19:57:43,730] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 19:57:43,730] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 19:57:43,732] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:57:43,733] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 19:57:43,733] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 19:57:43,734] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:57:43,734] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 19:57:43,735] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:57:43,735] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 19:57:43,736] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 19:57:43,736] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 19:57:43,737] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:57:43,739] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:57:43,741] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:57:43,748] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:57:43,754] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:57:43,756] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:57:43,756] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:57:43,756] INFO [chat-connector|task-0] Kafka startTimeMs: 1738061863756 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:57:43,757] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:57:43,759] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 19:57:43,759] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 19:57:43,759] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 19:57:43,761] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 19:57:43,762] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:57:43,762] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:57:43,762] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:57:43,763] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:57:43,763] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:57:43,763] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:57:43,764] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:57:52,829] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:57:52,830] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 19:57:52,830] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 19:57:52,830] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:57:52,831] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 19:57:52,831] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:57:52 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:57:52,831] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 19:57:52,832] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:57:52,832] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:57:52,834] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=148, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:57:52,859] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=148, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:57:52,873] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:57:52,874] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 19:57:52,875] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 19:57:52,875] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 19:57:52,876] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 19:57:52,876] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 19:57:52,876] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 148 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=197, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:57:52,877] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 197 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:57:52,878] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:57:52,878] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:57:52,879] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:57:52,881] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=149, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:57:52,886] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=149, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:57:52,887] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 149 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=197, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:57:52,888] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 197 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:57:52,888] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:57:55,719] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:57:55,723] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 19:57:55,723] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:57:55,724] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:57:55,724] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:57:55 +0000] "POST /connectors/ HTTP/1.1" 201 228 "-" "curl/8.9.1" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:57:55,726] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=150, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:57:55,729] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=150, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:57:55,729] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 150 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=198, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:57:55,730] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 198 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:57:55,731] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 19:57:55,731] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 19:57:55,732] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:57:55,735] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:57:55,737] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 19:57:55,737] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 19:57:55,737] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:57:55,738] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:57:55,740] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:57:55,752] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 19:57:55,753] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:57:55,753] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:57:55,755] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=151, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:57:55,757] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=151, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:57:55,758] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 151 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=200, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:57:55,758] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 200 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:57:55,759] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 19:57:55,760] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 19:57:55,760] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 19:57:55,762] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:57:55,763] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 19:57:55,763] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 19:57:55,764] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:57:55,764] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 19:57:55,765] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:57:55,765] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 19:57:55,766] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 19:57:55,766] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 19:57:55,766] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:57:55,768] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:57:55,771] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:57:55,778] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:57:55,782] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:57:55,782] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:57:55,782] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:57:55,783] INFO [chat-connector|task-0] Kafka startTimeMs: 1738061875782 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:57:55,783] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:57:55,783] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 19:57:55,785] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 19:57:55,785] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 19:57:55,786] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 19:57:55,786] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:57:55,787] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:57:55,787] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:57:55,787] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:57:55,788] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:57:55,788] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:57:55,788] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:57:57,923] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:57:57 +0000] "GET /connectors/chat-connector/status HTTP/1.1" 200 1576 "-" "curl/8.9.1" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:58:19,029] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:58:19,030] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 19:58:19,030] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 19:58:19,030] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:58:19,031] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 19:58:19,031] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:58:19 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:58:19,032] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 19:58:19,033] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:58:19,033] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:58:19,037] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=152, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:58:19,040] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=152, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:58:19,041] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:58:19,041] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 19:58:19,041] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 19:58:19,041] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 19:58:19,044] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 19:58:19,045] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 19:58:19,045] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 152 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=202, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:58:19,046] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 202 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:58:19,046] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:58:19,046] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:58:19,047] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:58:19,049] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=153, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:58:19,060] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=153, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:58:19,060] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 153 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=202, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:58:19,061] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 202 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:58:19,061] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:58:21,579] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:58:21 +0000] "GET /connectors/chat-connector/status HTTP/1.1" 404 75 "-" "curl/8.9.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:58:23,892] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 19:58:23,896] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 19:58:23,896] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:58:23,896] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:58:23,897] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:58:23 +0000] "POST /connectors/ HTTP/1.1" 201 228 "-" "curl/8.9.1" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:58:23,898] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=154, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:58:23,900] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=154, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:58:23,900] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 154 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=203, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:58:23,901] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 203 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:58:23,901] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 19:58:23,902] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 19:58:23,902] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:58:23,905] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:58:23,906] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 19:58:23,907] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 19:58:23,907] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:58:23,908] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:58:23,910] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:58:23,918] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 19:58:23,919] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:58:23,920] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:58:23,922] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=155, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:58:23,924] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=155, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:58:23,925] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 155 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=205, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:58:23,925] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 205 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:58:23,926] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 19:58:23,926] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 19:58:23,927] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 19:58:23,928] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:58:23,929] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 19:58:23,929] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 19:58:23,930] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:58:23,930] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 19:58:23,930] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 19:58:23,931] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 19:58:23,931] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 19:58:23,932] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 19:58:23,932] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 19:58:23,934] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 19:58:23,937] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 19:58:23,944] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 19:58:23,948] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 19:58:23,948] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 19:58:23,948] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 19:58:23,949] INFO [chat-connector|task-0] Kafka startTimeMs: 1738061903948 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 19:58:23,949] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:58:23,949] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 19:58:23,950] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 19:58:23,950] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 19:58:23,952] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 19:58:23,952] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 19:58:23,953] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 19:58:23,953] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 19:58:23,953] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:58:23,954] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 19:58:23,954] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 19:58:23,955] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 19:58:25,911] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:58:25 +0000] "GET /connectors/chat-connector/status HTTP/1.1" 200 1576 "-" "curl/8.9.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:58:26,516] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2442)
[2025-01-28 19:58:34,373] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 19:58:34,373] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 19:58:34,373] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 19:58:34,374] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:58:34,374] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 19:58:34,374] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:10:58:34 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 19:58:34,375] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 19:58:34,376] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:58:34,376] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:58:34,379] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=156, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:58:34,383] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=156, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:58:34,383] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 19:58:34,383] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 19:58:34,384] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 19:58:34,389] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 19:58:34,392] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 19:58:34,392] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 19:58:34,393] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 156 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=208, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:58:34,394] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 208 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:58:34,395] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 19:58:34,396] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 19:58:34,396] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 19:58:34,401] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=157, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 19:58:34,409] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=157, memberId='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 19:58:34,410] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 157 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-cc5daa73-bbfc-40f0-9a0a-ba5e349fcde8', leaderUrl='http://121.178.140.30:8083/', offset=208, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 19:58:34,410] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 208 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 19:58:34,410] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
