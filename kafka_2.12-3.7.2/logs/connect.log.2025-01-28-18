[2025-01-28 18:08:55,031] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-01-28 18:08:55,070] INFO WorkerInfo values: 
	jvm.args = -Xmx256M, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2/logs, -Dlog4j.configuration=file:F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2/config/connect-log4j.properties
	jvm.spec = Eclipse Adoptium, OpenJDK 64-Bit Server VM, 17.0.12, 17.0.12+7
	jvm.classpath = F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\activation-1.1.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\aopalliance-repackaged-2.6.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\argparse4j-0.7.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\audience-annotations-0.12.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\caffeine-2.9.3.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\checker-qual-3.19.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-beanutils-1.9.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-cli-1.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-collections-3.2.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-digester-2.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-io-2.14.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-lang3-3.8.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-logging-1.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\commons-validator-1.7.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-api-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-basic-auth-extension-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-file-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-json-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-mirror-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-mirror-client-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-runtime-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\connect-transforms-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\error_prone_annotations-2.10.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-api-2.6.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-locator-2.6.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\hk2-utils-2.6.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-annotations-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-core-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-databind-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-dataformat-csv-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-datatype-jdk8-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-jaxrs-base-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-jaxrs-json-provider-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-module-jaxb-annotations-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jackson-module-scala_2.12-2.16.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.activation-api-1.2.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.annotation-api-1.3.5.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.inject-2.6.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.validation-api-2.0.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.ws.rs-api-2.1.6.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jakarta.xml.bind-api-2.3.3.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javassist-3.29.2-GA.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.activation-api-1.2.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.annotation-api-1.3.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.servlet-api-3.1.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\javax.ws.rs-api-2.1.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jaxb-api-2.3.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-client-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-common-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-container-servlet-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-container-servlet-core-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-hk2-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jersey-server-2.39.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-client-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-continuation-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-http-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-io-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-security-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-server-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-servlet-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-servlets-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-util-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jetty-util-ajax-9.4.56.v20240826.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jline-3.25.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jopt-simple-5.0.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jose4j-0.9.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\jsr305-3.0.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-clients-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-group-coordinator-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-log4j-appender-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-metadata-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-raft-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-server-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-server-common-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-shell-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-storage-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-storage-api-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-examples-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-scala_2.12-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-streams-test-utils-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-tools-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka-tools-api-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\kafka_2.12-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\lz4-java-1.8.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\maven-artifact-3.8.8.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\metrics-core-2.2.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\metrics-core-4.1.12.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-buffer-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-codec-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-common-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-handler-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-resolver-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-classes-epoll-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-native-epoll-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\netty-transport-native-unix-common-4.1.115.Final.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\opentelemetry-proto-1.0.0-alpha.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\osgi-resource-locator-1.0.3.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\paranamer-2.8.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\pcollections-4.0.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\plexus-utils-3.3.1.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\protobuf-java-3.25.5.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\reflections-0.10.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\reload4j-1.2.25.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\rocksdbjni-7.9.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-collection-compat_2.12-2.10.0.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-java8-compat_2.12-1.0.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-library-2.12.18.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-logging_2.12-3.9.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\scala-reflect-2.12.18.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\slf4j-api-1.7.36.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\slf4j-reload4j-1.7.36.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\snappy-java-1.1.10.5.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\swagger-annotations-2.2.8.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\trogdor-3.7.2.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zookeeper-3.8.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zookeeper-jute-3.8.4.jar;F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs\zstd-jni-1.5.6-4.jar;
	os.spec = Windows 10, amd64, 10.0
	os.vcpus = 6
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-01-28 18:08:55,092] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-01-28 18:08:55,881] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\bin (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 18:08:56,696] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/bin/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 18:08:56,700] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\config (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 18:08:56,712] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/config/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 18:08:56,713] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 18:08:58,382] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2025-01-28 18:08:59,675] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 18:08:59,675] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 18:08:59,895] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 18:08:59,895] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\licenses (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 18:08:59,900] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/licenses/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 18:08:59,901] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\logs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 18:08:59,907] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/logs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 18:08:59,908] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\site-docs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 18:08:59,914] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/site-docs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 18:08:59,915] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 18:08:59,923] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@66d3c617 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 18:08:59,926] INFO Scanning plugins with ServiceLoaderScanner took 4046 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-01-28 18:08:59,948] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\bin (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 18:09:00,053] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/bin/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 18:09:00,053] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\config (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 18:09:00,055] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/config/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 18:09:00,055] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\connector (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 18:09:01,455] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 18:09:01,456] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\libs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 18:09:07,650] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 18:09:07,651] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\licenses (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 18:09:07,653] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/licenses/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 18:09:07,653] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\logs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 18:09:07,654] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/logs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 18:09:07,655] INFO Loading plugin from: F:\GitHub\amazon-clone-msa\kafka_2.12-3.7.2\site-docs (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 18:09:07,657] INFO Registered loader: PluginClassLoader{pluginLocation=file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/site-docs/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 18:09:07,658] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-01-28 18:09:08,355] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@66d3c617 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-01-28 18:09:08,356] INFO Scanning plugins with ReflectionScanner took 8408 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-01-28 18:09:08,359] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/	io.debezium.connector.mongodb.MongoDbSinkConnector	sink	3.0.2.Final
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-01-28 18:09:08,362] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,363] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,363] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,364] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,364] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,365] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,365] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,365] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,366] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,366] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,367] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,368] INFO Added plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,368] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,368] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,369] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,369] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,370] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,371] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,372] INFO Added plugin 'io.debezium.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,372] INFO Added plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,372] INFO Added plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,373] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,373] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,373] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,373] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,374] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,374] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,374] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,375] INFO Added plugin 'io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,375] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,375] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,376] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,376] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,376] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,377] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,377] INFO Added plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,378] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,378] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,379] INFO Added plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,379] INFO Added plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,380] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,380] INFO Added plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,380] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,381] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,381] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,381] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,381] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,383] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,383] INFO Added plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,383] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,384] INFO Added plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,384] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,384] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,385] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,385] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,385] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,385] INFO Added plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,386] INFO Added plugin 'io.debezium.connector.mongodb.transforms.ExtractNewDocumentState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,386] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,387] INFO Added plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,387] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,387] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,388] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,388] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,390] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,390] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,391] INFO Added plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,391] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,392] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-28 18:09:08,393] INFO Added alias 'ExtractNewDocumentState' to plugin 'io.debezium.connector.mongodb.transforms.ExtractNewDocumentState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,395] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,395] INFO Added alias 'CloudEventsConverter' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,396] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,396] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,396] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,397] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,397] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,397] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,397] INFO Added alias 'HeaderToValue' to plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,398] INFO Added alias 'PartitionRouting' to plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,398] INFO Added alias 'MongoDbSink' to plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,398] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,399] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,399] INFO Added alias 'MongoDbConnector' to plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,399] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,400] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,400] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,400] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,401] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,401] INFO Added alias 'ExtractSchemaToNewRecord' to plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,401] INFO Added alias 'BinaryData' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,402] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,402] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,402] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,402] INFO Added alias 'CloudEvents' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,403] INFO Added alias 'TimezoneConverter' to plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,403] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,403] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,403] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,404] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,404] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,404] INFO Added alias 'DebeziumMongoDb' to plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,404] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,405] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,405] INFO Added alias 'DebeziumMongoDbConnectRestExtension' to plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,406] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,406] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,406] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,406] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,407] INFO Added alias 'ExtractChangedRecordState' to plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,407] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,408] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,409] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,409] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,410] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,410] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,411] INFO Added alias 'MongoDbSinkConnector' to plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,412] INFO Added alias 'MongoDb' to plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,412] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,413] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,413] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,414] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,414] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,415] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,415] INFO Added alias 'SchemaChangeEventFilter' to plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,416] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,416] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,416] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,417] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,417] INFO Added alias 'ActivateTracingSpan' to plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,417] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,418] INFO Added alias 'BinaryDataConverter' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,418] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,419] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,419] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,420] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,420] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,421] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,421] INFO Added alias 'MongoEventRouter' to plugin 'io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,422] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,423] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-28 18:09:08,487] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-01-28 18:09:08,497] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-01-28 18:09:08,499] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-01-28 18:09:08,593] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-01-28 18:09:08,593] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:09:08,594] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:09:08,594] INFO Kafka startTimeMs: 1738055348593 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:09:08,855] INFO Kafka cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-01-28 18:09:08,856] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 18:09:08,863] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 18:09:08,863] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 18:09:08,871] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 18:09:08,876] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-01-28 18:09:08,888] INFO Logging initialized @14857ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-01-28 18:09:08,923] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-01-28 18:09:08,924] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-01-28 18:09:08,941] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 17.0.12+7 (org.eclipse.jetty.server.Server:375)
[2025-01-28 18:09:08,971] INFO Started http_8083@26401eda{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-01-28 18:09:08,972] INFO Started @14941ms (org.eclipse.jetty.server.Server:415)
[2025-01-28 18:09:08,998] INFO Advertised URI: http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-01-28 18:09:08,998] INFO REST server listening at http://121.178.140.30:8083/, advertising URL http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-01-28 18:09:09,000] INFO Advertised URI: http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-01-28 18:09:09,000] INFO REST admin endpoints at http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-01-28 18:09:09,001] INFO Advertised URI: http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-01-28 18:09:09,001] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-01-28 18:09:09,006] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:09:09,018] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:09:09,019] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:09:09,019] INFO Kafka startTimeMs: 1738055349018 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:09:09,024] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:09:09,025] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:09:09,053] INFO Advertised URI: http://121.178.140.30:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-01-28 18:09:09,076] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:09:09,077] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:09:09,077] INFO Kafka startTimeMs: 1738055349076 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:09:09,079] INFO Kafka Connect worker initialization took 14045ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-01-28 18:09:09,080] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-01-28 18:09:09,082] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-01-28 18:09:09,083] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:369)
[2025-01-28 18:09:09,109] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:231)
[2025-01-28 18:09:09,124] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:240)
[2025-01-28 18:09:09,125] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-01-28 18:09:09,154] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-01-28 18:09:09,166] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-01-28 18:09:09,167] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:09:09,167] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:09:09,167] INFO Kafka startTimeMs: 1738055349167 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:09:09,199] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-01-28 18:09:09,219] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-01-28 18:09:09,240] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-01-28 18:09:09,241] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-01-28 18:09:09,242] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2025-01-28 18:09:09,255] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 18:09:09,274] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-01-28 18:09:09,275] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:09:09,276] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:09:09,276] INFO Kafka startTimeMs: 1738055349275 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:09:09,288] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 18:09:09,290] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 18:09:09,312] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 18:09:09,342] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 18:09:09,342] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:09:09,343] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:09:09,343] INFO Kafka startTimeMs: 1738055349342 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:09:09,354] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 18:09:09,360] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-01-28 18:09:09,371] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,372] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,373] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,373] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,373] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,374] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,374] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,374] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,374] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,375] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,375] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,375] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,376] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,376] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,376] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,377] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,378] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,378] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,379] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,380] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,380] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,383] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,383] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,384] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,385] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,426] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,431] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,431] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,433] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,434] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,434] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,435] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,435] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,436] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,436] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,436] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,437] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,437] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,438] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,438] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,439] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,439] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,439] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,440] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,440] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,441] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,442] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,443] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,445] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-01-28 18:09:09,446] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-01-28 18:09:09,447] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:257)
[2025-01-28 18:09:09,456] INFO Worker started (org.apache.kafka.connect.runtime.Worker:241)
[2025-01-28 18:09:09,457] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-01-28 18:09:09,466] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-01-28 18:09:09,475] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 18:09:09,483] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-01-28 18:09:09,484] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:09:09,485] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:09:09,486] INFO Kafka startTimeMs: 1738055349484 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:09:09,487] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 18:09:09,496] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 18:09:09,504] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 18:09:09,505] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:09:09,505] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:09:09,506] INFO Kafka startTimeMs: 1738055349505 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:09:09,512] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 18:09:09,521] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-01-28 18:09:09,521] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,522] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,524] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,524] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,525] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,525] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 18:09:09,538] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,539] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,539] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,540] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,541] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,618] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-01-28 18:09:09,619] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-01-28 18:09:09,623] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:379)
[2025-01-28 18:09:09,624] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:236)
[2025-01-28 18:09:09,641] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-01-28 18:09:09,652] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 18:09:09,663] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-01-28 18:09:09,675] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:09:09,707] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:09:09,712] INFO Kafka startTimeMs: 1738055349675 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:09:09,715] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 18:09:09,716] INFO [Producer clientId=connect-cluster-configs] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 18:09:09,723] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 18:09:09,735] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 18:09:09,736] INFO Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:09:09,736] INFO Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:09:09,737] INFO Kafka startTimeMs: 1738055349736 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:09:09,740] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 18:09:09,741] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2025-01-28 18:09:09,742] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2025-01-28 18:09:09,754] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[121.178.140.30:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2025-01-28 18:09:09,770] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:09:09,771] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:09:09,771] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:09:09,772] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:09:09,772] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:09:09,773] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:09:09,773] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:09:09,774] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:09:09,775] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:09:09,775] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:09:09,776] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:09:09,776] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:09:09,777] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:09:09,779] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:09:09,782] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:09:09,787] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:293)
[2025-01-28 18:09:09,787] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:295)
[2025-01-28 18:09:09,787] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:403)
[2025-01-28 18:09:09,788] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:376)
[2025-01-28 18:09:09,806] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Cluster ID: 8HYB7rDDQyCF5mINKWHRMg (org.apache.kafka.clients.Metadata:356)
[2025-01-28 18:09:09,808] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Discovered group coordinator 121.178.140.30:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-01-28 18:09:09,811] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:09:09,811] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:09:09,828] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:09:09,846] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=73, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:09:09,901] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=73, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:09:09,902] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 73 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=106, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:09:09,903] WARN [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1753)
[2025-01-28 18:09:09,903] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 106, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1826)
[2025-01-28 18:09:09,907] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 106 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1853)
[2025-01-28 18:09:09,908] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 106 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:09:09,908] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:09:09,926] INFO Started o.e.j.s.ServletContextHandler@38821ada{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-01-28 18:09:09,927] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-01-28 18:09:09,927] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-01-28 18:13:56,858] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 18:13:56,904] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 18:13:56,907] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:13:56,908] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:13:56,910] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=74, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:13:56,914] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=74, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:13:56,915] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 74 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=107, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:13:56,915] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 107 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:13:56,917] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 18:13:56,919] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 18:13:56,920] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:13:56,922] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:13:56,925] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 18:13:56,926] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 18:13:56,926] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:13:56,934] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:13:56,936] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:13:56,953] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 18:13:56,955] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:13:56,955] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:13:56,956] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:13:56 +0000] "POST /connectors/ HTTP/1.1" 201 282 "-" "curl/8.9.1" 207 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:13:56,958] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=75, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:13:56,964] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=75, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:13:56,964] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 75 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=109, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:13:56,966] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 109 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:13:56,967] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 18:13:56,969] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 18:13:56,970] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 18:13:56,971] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:13:56,973] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 18:13:56,973] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 18:13:56,974] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:13:56,974] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 18:13:56,975] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:13:56,975] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 18:13:56,975] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 18:13:56,978] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 18:13:56,978] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:13:56,980] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:13:56,984] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 18:13:56,991] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 18:13:56,998] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 18:13:57,003] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:13:57,004] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:13:57,004] INFO [chat-connector|task-0] Kafka startTimeMs: 1738055637003 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:13:57,013] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:13:57,016] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 18:13:57,017] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 18:13:57,017] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 18:13:57,021] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 18:13:57,022] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 18:13:57,022] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 18:13:57,025] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 18:13:57,025] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 18:13:57,025] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 18:13:57,025] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 18:13:57,027] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 18:14:09,180] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 18:17:21,857] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:17:21,858] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 18:17:21,861] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 18:17:21,863] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 18:17:21,865] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 18:17:21,862] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:17:21 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 17 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:17:21,868] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 18:17:21,869] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:17:21,869] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:17:21,883] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=76, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:17:21,888] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=76, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:17:21,890] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 18:17:21,890] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 18:17:21,891] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 18:17:21,891] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 18:17:21,892] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 18:17:21,893] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 18:17:21,894] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 76 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=111, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:17:21,895] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 111 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:17:21,895] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:17:21,895] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:17:21,896] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:17:21,901] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=77, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:17:21,904] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=77, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:17:21,905] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 77 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=111, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:17:21,905] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 111 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:17:21,905] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:18:09,370] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 18:18:09,558] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 18:18:09,839] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 18:18:09,870] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 18:18:09,901] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 18:18:21,872] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 18:18:21,919] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 18:20:38,049] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 18:20:38,053] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 18:20:38,054] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:20:38,055] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:20:38,055] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:20:38 +0000] "POST /connectors/ HTTP/1.1" 201 282 "-" "curl/8.9.1" 28 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:20:38,058] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=78, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:20:38,084] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=78, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:20:38,084] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 78 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=112, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:20:38,085] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 112 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:20:38,086] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 18:20:38,086] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 18:20:38,087] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:20:38,088] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:20:38,090] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 18:20:38,090] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 18:20:38,090] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:20:38,091] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:20:38,093] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:20:38,111] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 18:20:38,111] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:20:38,112] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:20:38,113] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=79, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:20:38,115] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=79, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:20:38,116] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 79 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=114, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:20:38,116] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 114 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:20:38,117] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 18:20:38,117] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 18:20:38,118] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 18:20:38,119] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:20:38,120] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 18:20:38,120] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 18:20:38,121] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:20:38,121] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 18:20:38,122] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:20:38,122] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 18:20:38,122] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 18:20:38,123] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 18:20:38,123] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:20:38,125] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:20:38,126] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 18:20:38,133] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 18:20:38,138] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 18:20:38,138] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:20:38,138] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:20:38,139] INFO [chat-connector|task-0] Kafka startTimeMs: 1738056038138 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:20:38,140] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:20:38,140] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 18:20:38,140] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 18:20:38,141] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 18:20:38,142] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 18:20:38,142] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 18:20:38,142] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 18:20:38,143] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 18:20:38,143] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 18:20:38,143] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 18:20:38,143] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 18:20:38,144] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 18:24:57,773] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:24:57,796] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 18:24:57,797] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 18:24:57,798] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 18:24:57,799] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 18:24:57,799] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:24:57 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 34 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:24:57,800] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 18:24:57,801] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:24:57,802] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:24:57,804] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=80, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:24:57,907] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=80, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:24:57,909] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 18:24:57,909] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 18:24:57,909] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 18:24:57,909] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 18:24:57,910] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 18:24:57,911] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 18:24:57,911] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 80 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=116, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:24:57,912] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 116 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:24:57,912] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:24:57,913] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:24:57,913] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:24:57,915] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=81, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:24:57,917] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=81, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:24:57,918] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 81 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=116, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:24:57,918] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 116 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:24:57,918] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:25:01,879] ERROR Uncaught exception in REST call to /connectors/ (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches com.mongodb.kafka.connect.MongoSinkConnector, available connectors are: PluginDesc{klass=class io.debezium.connector.mongodb.MongoDbConnector, name='io.debezium.connector.mongodb.MongoDbConnector', version='3.0.2.Final', encodedVersion=3.0.2.Final, type=source, typeName='source', location='file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/'}, PluginDesc{klass=class io.debezium.connector.mongodb.MongoDbSinkConnector, name='io.debezium.connector.mongodb.MongoDbSinkConnector', version='3.0.2.Final', encodedVersion=3.0.2.Final, type=sink, typeName='sink', location='file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/connector/'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.7.2', encodedVersion=3.7.2, type=sink, typeName='sink', location='file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.7.2', encodedVersion=3.7.2, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='file:/F:/GitHub/amazon-clone-msa/kafka_2.12-3.7.2/libs/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.7.2', encodedVersion=3.7.2, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:320)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:291)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$7(AbstractHerder.java:756)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1708)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:756)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:501)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$3(AbstractHerder.java:413)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 18:25:01,909] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:25:01 +0000] "POST /connectors/ HTTP/1.1" 500 3343 "-" "curl/8.9.1" 223 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:25:26,983] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 18:25:26,987] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 18:25:26,987] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:25:26,988] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:25:26,988] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:25:26 +0000] "POST /connectors/ HTTP/1.1" 201 282 "-" "curl/8.9.1" 8 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:25:26,991] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=82, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:25:26,995] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=82, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:25:26,995] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 82 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=117, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:25:26,996] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 117 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:25:26,998] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 18:25:26,998] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 18:25:26,999] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:25:27,001] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:25:27,004] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 18:25:27,005] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 18:25:27,006] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:25:27,007] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:25:27,010] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:25:27,024] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 18:25:27,025] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:25:27,026] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:25:27,030] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=83, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:25:27,037] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=83, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:25:27,038] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 83 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=119, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:25:27,039] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 119 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:25:27,040] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 18:25:27,040] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 18:25:27,041] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 18:25:27,042] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:25:27,045] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 18:25:27,047] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 18:25:27,050] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:25:27,052] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 18:25:27,052] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:25:27,053] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 18:25:27,054] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 18:25:27,054] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 18:25:27,056] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:25:27,062] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:25:27,064] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 18:25:27,074] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 18:25:27,080] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 18:25:27,081] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:25:27,081] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:25:27,081] INFO [chat-connector|task-0] Kafka startTimeMs: 1738056327081 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:25:27,082] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:25:27,083] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 18:25:27,083] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 18:25:27,084] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 18:25:27,087] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 18:25:27,087] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 18:25:27,087] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 18:25:27,088] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 18:25:27,089] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 18:25:27,091] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 18:25:27,092] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 18:25:27,093] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 18:26:42,188] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:26:42,189] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 18:26:42,189] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 18:26:42,189] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 18:26:42,190] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:26:42 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:26:42,190] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 18:26:42,191] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 18:26:42,191] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:26:42,191] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:26:42,194] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=84, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:26:42,198] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=84, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:26:42,199] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 18:26:42,200] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 18:26:42,200] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 18:26:42,199] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 18:26:42,201] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 18:26:42,202] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 18:26:42,202] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 84 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=121, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:26:42,204] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 121 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:26:42,204] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:26:42,204] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:26:42,204] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:26:42,206] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=85, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:26:42,208] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=85, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:26:42,209] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 85 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=121, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:26:42,210] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 121 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:26:42,211] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:28:09,775] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 18:28:09,836] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 18:34:09,231] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 18:39:04,243] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:39:04 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 404 65 "-" "PostmanRuntime/7.43.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:39:09,342] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 18:39:10,038] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 18:39:10,051] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 18:39:10,052] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:39:10,052] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:39:10,053] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:39:10 +0000] "POST /connectors/ HTTP/1.1" 201 282 "-" "curl/8.9.1" 17 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:39:10,055] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=86, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:39:10,058] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=86, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:39:10,059] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 86 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=122, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:39:10,060] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 122 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:39:10,060] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 18:39:10,061] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 18:39:10,062] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:39:10,064] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:39:10,066] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 18:39:10,066] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 18:39:10,067] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:39:10,073] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:39:10,075] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:39:10,084] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 18:39:10,084] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:39:10,085] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:39:10,087] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=87, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:39:10,090] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=87, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:39:10,091] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 87 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=124, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:39:10,091] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 124 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:39:10,092] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 18:39:10,093] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 18:39:10,093] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 18:39:10,095] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:39:10,096] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 18:39:10,096] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 18:39:10,097] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:39:10,097] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 18:39:10,098] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:39:10,098] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 18:39:10,098] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 18:39:10,099] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 18:39:10,099] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:39:10,101] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:39:10,112] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 18:39:10,119] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 18:39:10,124] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 18:39:10,124] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:39:10,125] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:39:10,125] INFO [chat-connector|task-0] Kafka startTimeMs: 1738057150124 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:39:10,126] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:39:10,126] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 18:39:10,126] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 18:39:10,126] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 18:39:10,128] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 18:39:10,128] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 18:39:10,129] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 18:39:10,129] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 18:39:10,129] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 18:39:10,129] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 18:39:10,130] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 18:39:10,131] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 18:39:53,359] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:39:53,359] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 18:39:53,360] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 18:39:53,360] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 18:39:53,360] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 18:39:53,360] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:39:53 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:39:53,361] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 18:39:53,361] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:39:53,361] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:39:53,363] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=88, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:39:53,365] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=88, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:39:53,366] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 18:39:53,367] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 18:39:53,367] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 18:39:53,366] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 18:39:53,369] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 18:39:53,370] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 18:39:53,371] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 88 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=126, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:39:53,372] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 126 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:39:53,373] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:39:53,374] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:39:53,374] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:39:53,376] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=89, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:39:53,380] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=89, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:39:53,380] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 89 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=126, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:39:53,381] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 126 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:39:53,381] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:43:05,149] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:43:05 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 404 65 "-" "PostmanRuntime/7.43.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:43:09,105] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 18:43:09,109] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 18:43:09,109] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:43:09,110] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:43:09,110] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:43:09 +0000] "POST /connectors/ HTTP/1.1" 201 266 "-" "curl/8.9.1" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:43:09,114] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=90, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:43:09,117] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=90, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:43:09,117] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 90 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=127, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:43:09,118] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 127 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:43:09,118] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 18:43:09,119] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 18:43:09,119] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:43:09,121] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:43:09,124] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 18:43:09,124] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 18:43:09,125] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:43:09,126] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:43:09,131] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:43:09,168] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 18:43:09,169] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:43:09,169] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:43:09,199] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=91, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:43:09,210] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=91, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:43:09,210] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 91 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=129, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:43:09,211] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 129 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:43:09,211] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 18:43:09,211] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 18:43:09,212] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 18:43:09,213] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:43:09,214] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 18:43:09,214] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 18:43:09,215] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:43:09,215] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 18:43:09,216] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:43:09,216] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 18:43:09,216] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 18:43:09,217] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 18:43:09,217] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:43:09,218] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:43:09,220] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 18:43:09,227] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 18:43:09,244] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 18:43:09,244] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:43:09,244] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:43:09,245] INFO [chat-connector|task-0] Kafka startTimeMs: 1738057389244 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:43:09,245] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:43:09,246] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 18:43:09,246] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 18:43:09,246] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 18:43:09,247] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 18:43:09,248] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 18:43:09,248] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 18:43:09,248] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 18:43:09,248] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 18:43:09,249] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 18:43:09,249] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 18:43:09,250] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 18:43:50,423] ERROR Uncaught exception in REST call to /connectors/ (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
com.fasterxml.jackson.databind.JsonMappingException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 169] (through reference chain: org.apache.kafka.connect.runtime.rest.entities.CreateConnectorRequest["config"])
	at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:402)
	at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:361)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.wrapAndThrow(BeanDeserializerBase.java:1937)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeWithErrorWrapping(BeanDeserializer.java:572)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeUsingPropertyBased(BeanDeserializer.java:440)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1493)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:348)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:185)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:342)
	at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:2099)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1249)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:801)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:919)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:290)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 169]
	at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:2481)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:752)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:676)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:1065)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer._readAndBindStringKeyMap(MapDeserializer.java:608)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:449)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:32)
	at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:545)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeWithErrorWrapping(BeanDeserializer.java:570)
	... 71 more
[2025-01-28 18:43:50,432] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:43:50 +0000] "POST /connectors/ HTTP/1.1" 500 329 "-" "curl/8.9.1" 34 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:44:11,036] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 18:44:11,039] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:44:11 +0000] "POST /connectors/ HTTP/1.1" 409 70 "-" "curl/8.9.1" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:44:14,535] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:44:14,536] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 18:44:14,536] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 18:44:14,536] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 18:44:14,537] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 18:44:14,537] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:44:14 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:44:14,537] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 18:44:14,538] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:44:14,539] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:44:14,541] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=92, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:44:14,544] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=92, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:44:14,545] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 18:44:14,545] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 18:44:14,545] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 18:44:14,545] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 18:44:14,546] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 18:44:14,546] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 18:44:14,547] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 92 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=131, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:44:14,547] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 131 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:44:14,548] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:44:14,549] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:44:14,549] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:44:14,551] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=93, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:44:14,557] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=93, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:44:14,558] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 93 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=131, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:44:14,559] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 131 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:44:14,559] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:44:17,091] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 18:44:17,095] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 18:44:17,095] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:44:17,096] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:44:17,096] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:44:17 +0000] "POST /connectors/ HTTP/1.1" 201 234 "-" "curl/8.9.1" 26 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:44:17,098] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=94, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:44:17,100] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=94, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:44:17,101] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 94 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=132, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:44:17,101] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 132 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:44:17,102] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 18:44:17,102] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 18:44:17,103] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:44:17,106] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:44:17,108] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 18:44:17,109] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 18:44:17,109] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:44:17,110] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:44:17,112] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:44:17,123] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 18:44:17,125] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:44:17,126] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:44:17,128] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=95, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:44:17,131] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=95, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:44:17,132] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 95 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=134, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:44:17,132] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 134 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:44:17,132] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 18:44:17,133] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 18:44:17,133] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 18:44:17,135] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:44:17,137] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 18:44:17,137] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 18:44:17,138] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:44:17,138] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 18:44:17,139] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:44:17,139] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 18:44:17,140] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 18:44:17,140] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 18:44:17,140] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:44:17,142] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:44:17,143] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 18:44:17,151] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 18:44:17,155] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 18:44:17,156] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:44:17,156] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:44:17,156] INFO [chat-connector|task-0] Kafka startTimeMs: 1738057457156 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:44:17,157] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:44:17,158] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 18:44:17,158] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 18:44:17,158] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 18:44:17,159] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 18:44:17,159] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 18:44:17,160] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 18:44:17,160] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 18:44:17,160] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 18:44:17,160] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 18:44:17,161] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 18:44:17,161] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 18:48:21,577] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 18:48:21,578] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:48:21 +0000] "POST /connectors/ HTTP/1.1" 409 70 "-" "curl/8.9.1" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:48:44,024] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 18:48:44,026] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:48:44 +0000] "POST /connectors/ HTTP/1.1" 409 70 "-" "curl/8.9.1" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:48:47,388] INFO Successfully processed removal of connector 'chat-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1014)
[2025-01-28 18:48:47,388] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2025-01-28 18:48:47,389] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2025-01-28 18:48:47,389] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 18:48:47,389] INFO [chat-connector|worker] Scheduled shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2025-01-28 18:48:47,389] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:48:47 +0000] "DELETE /connectors/chat-connector HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.0" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:48:47,390] INFO [chat-connector|worker] Completed shutdown for WorkerConnector{id=chat-connector} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2025-01-28 18:48:47,390] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:48:47,391] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:48:47,392] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=96, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:48:47,394] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=96, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:48:47,395] INFO [chat-connector|worker] Stopping connector chat-connector (org.apache.kafka.connect.runtime.Worker:420)
[2025-01-28 18:48:47,395] INFO [chat-connector|task-0] Stopping task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:1009)
[2025-01-28 18:48:47,395] WARN [chat-connector|worker] Ignoring stop request for unowned connector chat-connector (org.apache.kafka.connect.runtime.Worker:423)
[2025-01-28 18:48:47,395] WARN [chat-connector|worker] Ignoring await stop request for non-present connector chat-connector (org.apache.kafka.connect.runtime.Worker:444)
[2025-01-28 18:48:47,396] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2025-01-28 18:48:47,396] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2025-01-28 18:48:47,396] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 96 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=136, connectorIds=[], taskIds=[], revokedConnectorIds=[chat-connector], revokedTaskIds=[chat-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:48:47,397] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 136 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:48:47,397] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:48:47,397] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:48:47,398] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:48:47,399] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=97, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:48:47,401] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=97, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:48:47,402] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 97 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=136, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:48:47,402] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 136 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:48:47,402] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:48:50,503] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-01-28 18:48:50,506] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Connector chat-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2025-01-28 18:48:50,507] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:48:50,507] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:48:50,508] INFO [0:0:0:0:0:0:0:1] - - [28/1/2025:09:48:50 +0000] "POST /connectors/ HTTP/1.1" 201 266 "-" "curl/8.9.1" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-28 18:48:50,509] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=98, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:48:50,511] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=98, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:48:50,512] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 98 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=137, connectorIds=[chat-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:48:50,512] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 137 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:48:50,513] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connector chat-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2025-01-28 18:48:50,513] INFO [chat-connector|worker] Creating connector chat-connector of type io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:309)
[2025-01-28 18:48:50,514] INFO [chat-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:48:50,515] INFO [chat-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:48:50,517] INFO [chat-connector|worker] Instantiated connector chat-connector with version 3.0.2.Final of type class io.debezium.connector.mongodb.MongoDbSinkConnector (org.apache.kafka.connect.runtime.Worker:331)
[2025-01-28 18:48:50,517] INFO [chat-connector|worker] Finished creating connector chat-connector (org.apache.kafka.connect.runtime.Worker:352)
[2025-01-28 18:48:50,518] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:48:50,518] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:48:50,520] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:48:50,541] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Tasks [chat-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2399)
[2025-01-28 18:48:50,541] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-01-28 18:48:50,542] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-01-28 18:48:50,543] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=99, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-01-28 18:48:50,545] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=99, memberId='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-01-28 18:48:50,545] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Joined group at generation 99 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-121.178.140.30:8083-ed5d3b4c-cc7d-4ced-88cc-6dbe18060e4e', leaderUrl='http://121.178.140.30:8083/', offset=139, connectorIds=[chat-connector], taskIds=[chat-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2025-01-28 18:48:50,546] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 139 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2025-01-28 18:48:50,546] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Starting task chat-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1964)
[2025-01-28 18:48:50,546] INFO [chat-connector|task-0] Creating task chat-connector-0 (org.apache.kafka.connect.runtime.Worker:612)
[2025-01-28 18:48:50,547] INFO [chat-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-01-28 18:48:50,548] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:48:50,549] INFO [chat-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-01-28 18:48:50,549] INFO [chat-connector|task-0] Instantiated task chat-connector-0 with version 3.0.2.Final of type io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:626)
[2025-01-28 18:48:50,550] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:48:50,551] INFO [chat-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:639)
[2025-01-28 18:48:50,551] INFO [chat-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-01-28 18:48:50,552] INFO [chat-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:645)
[2025-01-28 18:48:50,552] INFO [chat-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task chat-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:652)
[2025-01-28 18:48:50,552] INFO [chat-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1799)
[2025-01-28 18:48:50,553] INFO [chat-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-01-28 18:48:50,555] INFO [chat-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = chat-connector
	predicates = []
	tasks.max = 1
	topics = [chat]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-01-28 18:48:50,557] INFO [chat-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-chat-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-chat-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-01-28 18:48:50,563] INFO [chat-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2025-01-28 18:48:50,568] INFO [chat-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-01-28 18:48:50,569] INFO [chat-connector|task-0] Kafka version: 3.7.2 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-01-28 18:48:50,569] INFO [chat-connector|task-0] Kafka commitId: 79a8f2b5f44f9d5a (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-28 18:48:50,569] INFO [chat-connector|task-0] Kafka startTimeMs: 1738057730569 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-28 18:48:50,570] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2025-01-28 18:48:50,570] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Subscribed to topic(s): chat (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:475)
[2025-01-28 18:48:50,570] INFO [chat-connector|task-0] Starting MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:48)
[2025-01-28 18:48:50,571] ERROR [chat-connector|task-0] WorkerSinkTask{id=chat-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:212)
java.lang.NullPointerException: Cannot invoke "String.startsWith(String)" because "connectionString" is null
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:337)
	at com.mongodb.ConnectionString.<init>(ConnectionString.java:321)
	at io.debezium.connector.mongodb.shared.SharedMongoDbConnectorConfig.resolveConnectionString(SharedMongoDbConnectorConfig.java:47)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorConfig.<init>(MongoDbSinkConnectorConfig.java:95)
	at io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask.start(MongoDbSinkConnectorTask.java:50)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:202)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:259)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-01-28 18:48:50,572] INFO [chat-connector|task-0] Stopping MongoDB sink task (io.debezium.connector.mongodb.sink.MongoDbSinkConnectorTask:110)
[2025-01-28 18:48:50,572] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-01-28 18:48:50,573] INFO [chat-connector|task-0] [Consumer clientId=connector-consumer-chat-connector-0, groupId=connect-chat-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-01-28 18:48:50,573] INFO [chat-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-01-28 18:48:50,573] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 18:48:50,573] INFO [chat-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-01-28 18:48:50,574] INFO [chat-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-01-28 18:48:50,589] INFO [chat-connector|task-0] App info kafka.consumer for connector-consumer-chat-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-01-28 18:54:09,475] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2025-01-28 18:58:26,548] INFO [Worker clientId=connect-121.178.140.30:8083, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2442)
